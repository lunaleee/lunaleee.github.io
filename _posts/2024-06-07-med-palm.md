---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Med-PaLM M, Towards Generalist Biomedical AI"
author: lunalee
date: 2024-06-07 19:41:12 +0900
categories: [AI, Paper Review]
tags: [Medical, LLM, Multi-modal, Multi-task]
pin: false
math: true
---

<br/><br/>
`Google Research` `Google DeepMind`  `NEJM AI 2024`

- Paper: [https://arxiv.org/abs/2307.14334](https://arxiv.org/abs/2307.14334)
- Git: [https://github.com/kyegomez/Med-PaLM](https://github.com/kyegomez/Med-PaLM)
- Page: [https://sites.research.google/med-palm/](https://sites.research.google/med-palm/)
<br/><br/><br/>

#### ğŸ“– í•µì‹¬ í›‘ì–´ë³´ê¸° !!

- MultiMedBench: ì˜ë£Œ ì˜ìƒ, ì„ìƒ í…ìŠ¤íŠ¸, ìœ ì „ì²´í•™ì„ í¬í•¨í•œ ì—¬ëŸ¬ modalityì— ê±¸ì³ ìˆëŠ” multimodal biomedical ë²¤ì¹˜ë§ˆí¬ë¥¼ íë ˆì´ì…˜. ë‹¤ì–‘í•œ modality ë¿ ì•„ë‹ˆë¼ 14ê°€ì§€ ë‹¤ì–‘í•œ taskë¥¼ í¬í•¨.
- Med-PaLM M: LLM ê¸°ë°˜ multimodal ëª¨ë¸ PaLM-Eë¥¼ í™œìš©, Instruction Tuningì„ í†µí•´ ëª¨ë¸ tuning. Generalist biomedical AI system êµ¬ì¶•.
<br/><br/><br/><br/>

# Introduction

---

ì˜í•™ì€ multimodal í•™ë¬¸ì´ë‹¤. Text, imaging, genomic ë“± ë‹¤ì–‘í•œ data modalityë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ Biomedical AIì˜ ìƒë‹¹í•œ ë°œì „ì—ë„ ë¶ˆêµ¬í•˜ê³  ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ unimodal single task ì‹œìŠ¤í…œì´ë‹¤. ì´ëŸ¬í•œ single-task, unimodal AI ì‹œìŠ¤í…œì€ real-world applicationì—ì„œ ë§¤ìš° ì œí•œì ì´ë‹¤.
<br/><br/>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì—¬ëŸ¬ biomedical data modalityë¥¼ í•´ì„í•˜ê³  ë™ì¼í•œ ëª¨ë¸ weight setìœ¼ë¡œ ë‹¤ì–‘í•œ downstream taskë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í†µí•© ëª¨ë¸(foundation model)ì„ ê°œë°œí•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤. ë¨¼ì € ì´ëŸ¬í•œ ì—°êµ¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ multimodal ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ MultiMedBenchë¥¼ íë ˆì´ì…˜ í—€ë‹¤. **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>MultiMedBench</span></mark>**ëŠ” ì–¸ì–´, ì˜ë£Œ ì˜ìƒ ë° ìœ ì „ì²´í•™(genomics) modalityë¥¼ ì•„ìš°ë¥´ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ multimodal ë²¤ì¹˜ë§ˆí¬ë¡œì„œ ì§ˆë¬¸ ë‹µë³€, ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€, ì˜ë£Œ ì˜ìƒ ë¶„ë¥˜, ë°©ì‚¬ì„  ë³´ê³ ì„œ ìƒì„± ë° ìš”ì•½, ìœ ì „ì²´ ë³€ì´ í˜¸ì¶œì„ í¬í•¨í•œ 14ê°€ì§€ ë‹¤ì–‘í•œ biomedical ì‘ì—…ì´ í¬í•¨ëœë‹¤.
<br/>

![Med-PaLM_1.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/5c4934bb-0b59-416b-88b9-5559b4ff813f){: width="1100px"}

MultiMedBenchë¥¼ í™œìš©í•˜ì—¬ ìµœê·¼ì˜ LLM, multimodal foundation modelì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” large-scale generalist biomedical AI ì‹œìŠ¤í…œ, Med-PaLM Multimodal (Med-PaLM M)ì„ ê°œë°œí•˜ì˜€ë‹¤. Med-PaLM Mì€ ë‹¤ì–‘í•œ ìœ í˜•ì˜ multimodal biomedical ì •ë³´ë¥¼ í†µí•©í•˜í•˜ëŠ” ìœ í˜„í•œ sequence-to-sequence êµ¬ì¡°ì´ë‹¤. ë˜í•œ modality-agnosticí•œ language decoderë¥¼ ì‚¬ìš©í•˜ì—¬, í†µí•©ëœ í•™ìŠµ ì „ëµìœ¼ë¡œ ë‹¤ì–‘í•œ biomedical taskë¥¼ ìˆ˜í–‰í•œë‹¤.
<br/><br/>

ìš”ì•½í•˜ë©´, ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

- **Curation of MultiMedBench**: ì˜ë£Œ ì˜ìƒ, ì„ìƒ í…ìŠ¤íŠ¸, ìœ ì „ì²´í•™ì„ í¬í•¨í•œ ì—¬ëŸ¬ modalityì— ê±¸ì³ ìˆëŠ” multimodal biomedical ë²¤ì¹˜ë§ˆí¬ë¥¼ ìƒì„±. ì¼ë°˜ biomedical AI ì‹œìŠ¤í…œì„ í•™ìŠµí•˜ê³  í‰ê°€í•˜ê¸° ìœ„í•œ 14ê°€ì§€ ë‹¤ì–‘í•œ taskë¥¼ í¬í•¨.
- **Med-PaLM M, the first demonstration of a generalist biomedical AI system**: ë™ì¼í•œ weight setìœ¼ë¡œ ë‹¤ì–‘í•œ taskë¥¼ ìˆ˜í–‰í•˜ëŠ” multitask, multimodal biomedical AI ì‹œìŠ¤í…œ. Task-specific customization ì—†ì´ ì—¬ëŸ¬ taskì—ì„œ SOTA ëª¨ë¸ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ ë‹¬ì„±.
- **Evidence of novel emergent capabilities in Med-PaLM M**: ì •ëŸ‰ì ì¸ ìˆ˜ì¹˜ì  í‰ê°€ë¥¼ ë„˜ì–´, zero-shot ì˜í•™ ì¶”ë¡ , ìƒˆë¡œìš´ ì˜í•™ì  conceptì— ëŒ€í•œ ì¼ë°˜í™”, task transferì— ëŒ€í•œ ê¸ì •ì ì¸ ì¦ê±°ë¥¼ ê´€ì°°í•¨.
- **Human evaluation of Med-PaLM M outputs**: ëª¨ë¸ì— ëŒ€í•œ ì •ëŸ‰ì  metricì„ ë„˜ì–´ radiologist í‰ê°€ë¥¼ ì§„í–‰.
<br/><br/><br/><br/><br/><br/>

# MultiMedBench: A Benchmark for Generalist Biomedical AI

---

ë…¼ë¬¸ì—ì„œëŠ” multi-task, multimodal ë°ì´í„°ì…‹ MultiMedBenchë¥¼ íë ˆì´ì…˜ í–ˆë‹¤. MultiMedBenchëŠ” 12ê°œì˜ ìµëª…í™”ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ë°ì´í„° ì„¸íŠ¸ì™€ 14ê°œì˜ ê°œë³„ taskë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. 
<br/><br/>

- Task type: question answering, report generation / summarization, visual question answering, medical image classification, genomic variant calling.
- Modality: text, radiology(CT, MRI, and X-ray), pathology(ë³‘ë¦¬í•™), dermatology(í”¼ë¶€ê³¼), mammography(ìœ ë°©ì¡°ì˜ìˆ ), genomics(ìœ ì „ì²´í•™).
- Output format: classificationì„ í¬í•¨í•œ ëª¨ë“  taskì— ëŒ€í•œ open-ended generation.
<br/><br/>

![Med-PaLM_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/329ff96c-7770-49bd-b971-833e65bbe604){: width="1100px"}
<br/><br/>

- Language-only task: medical question answering, radiology report summarization
- Multimodal task: medical visual question answering (VQA), medical image classification, chest X-ray report generation, genomic variant calling
<br/><br/><br/><br/><br/><br/>

# Med-PaLM M: A Proof of Concept for Generalist Biomedical AI

---

## 1. Model preliminaries

#### Pathways Language Model (PaLM)

PaLMì€ 2022ë…„ Googleì´ ë°œí‘œí•œ autoregressive transformer êµ¬ì¡°ì˜ LLMìœ¼ë¡œ, Pathwaysë¼ê³  í•˜ëŠ” ìƒˆë¡œìš´  ML ì‹œìŠ¤í…œì„ ì´ìš©í•´ ë‘ ëŒ€ì˜ TPU Podsì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤. ëŒ€í‘œì ì¸ íŠ¹ì§•ì€ ì•„ë˜ì™€ ê°™ë‹¤.

- 540B parameter, pipeline-free training (cf. GPT3:175B / GPT4: 1.76T)
- 780B tokenìœ¼ë¡œ êµ¬ì„±: ì›¹ í˜ì´ì§€, ìœ„í‚¤í”¼ë””ì•„ ê¸°ì‚¬, ì†ŒìŠ¤ ì½”ë“œ, ì†Œì…œ ë¯¸ë””ì–´ ëŒ€í™”, ë‰´ìŠ¤ ê¸°ì‚¬, ì±…ì—ì„œ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
- GPTì™€ ë™ì¼í•˜ê²Œ transformer decoder êµ¬ì¡°
- 3ê°€ì§€ PaLM ëª¨ë¸ variant
<br/><br/><br/>

#### Vision Transformer (ViT)

ViTëŠ” 2021 Googleì´ ë°œí‘œí•œ ë…¼ë¬¸ìœ¼ë¡œ Transformer êµ¬ì¡°ë¥¼ Imageì— ë„ì…í•˜ì—¬ í˜„ì¬ê¹Œì§€ë„ ë§ì€ ë…¼ë¬¸ë“¤ì˜ baseline êµ¬ì¡°ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ” ëª¨ë¸ì´ë‹¤. 

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” 4B paremeter, 22B paremeterë¡œ pre-trainëœ ë‘ ê°€ì§€ ViT ëª¨ë¸ì„ vision encoderë¡œ ì‚¬ìš©í•œë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ 4B ì´ë¯¸ì§€ classification ë°ì´í„°ì…‹(JFT-300M ë“±)ì— ëŒ€í•´ supervised learningìœ¼ë¡œ pre-train ë˜ì—ˆë‹¤.
<br/><br/><br/>

#### PaLM-E

PaLM-EëŠ” 2023 Googleì—ì„œ ë°œí‘œëœ ë…¼ë¬¸ìœ¼ë¡œ, text, vision, sensor signal ë“±ì˜ multimodal input sequenceë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” multimodal language ëª¨ë¸ì´ë‹¤. ê¸°ë³¸ PaLM-E ëª¨ë¸ì€ pre-trainëœ PaLMê³¼ ViTë¥¼ ì‚¬ìš©í•˜ë©°, ë‹¨ì¼ promptì—ì„œ ì´ë¯¸ì§€, text ë° sensor ì‹ í˜¸ë¥¼ ì„ì–´ ë„£ì„ ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ ì™„ì „íˆ multimodal contextì—ì„œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
<br/><br/>

ìì„¸í•œ ë…¼ë¬¸ ë‚´ìš©ì€ [PaLM-E ë…¼ë¬¸ ë¦¬ë·°](https://lunaleee.github.io/posts/palm-e/)ë¥¼ ì°¸ì¡°í•˜ì.
<br/><br/><br/><br/><br/>

## 2. Putting it all together: Med-PaLM M

#### Dataset and preprocessing

- MultiMedBenchì˜ ëª¨ë“  imageëŠ” 224Ã—224Ã—3ìœ¼ë¡œ resize ë¨. W,H ë¹„ìœ¨ ìœ ì§€ë¥¼ ìœ„í•´ padding ì‚¬ìš©.
- Gray-scale ì´ë¯¸ì§€ëŠ” channel ì°¨ì›ìœ¼ë¡œ ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ 3-channelë¡œ ìŒ“ì•„ì„œ ì‚¬ìš©.
- Task-specific prepossessing ì ìš©(class balancing, image data augmentation ë“±)
<br/><br/><br/><br/>

#### Instruction task prompting and one-shot exemplar

![Med-PaLM_3.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/a1f10db3-9cb5-4b99-a4a0-bb9da855b020){: width="1200px"}

Multimodal ì…ë ¥ì— ëŒ€í•´ ë‹¤ì–‘í•œ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” generalist biomedical AI ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ **instruction tuning***ì„ ì‚¬ìš©í–ˆë‹¤. ëª¨ë¸ì´ ë‹¤ì–‘í•œ ìœ í˜•ì˜ taskë¥¼ ìˆ˜í–‰í•˜ë„ë¡ task-specificí•œ instructionì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í–ˆë‹¤. 

êµ¬ì²´ì ìœ¼ë¡œ task promptëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>instruction, ê´€ë ¨ context information, question</span></mark>**ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ì˜ˆì‹œëŠ” ìœ„ì™€ ê°™ë‹¤. ì²«ë²ˆì§¸ chest X-ray report generation taskì—ì„œëŠ” ì´ë¯¸ì§€ ë°©í–¥ ì •ë³´ì™€ ì—°êµ¬ì˜ ëª©ì ì„, ë‘ ë²ˆì§¸ í”¼ë¶€ ì§ˆí™˜ classification taskì— ëŒ€í•´ì„œëŠ” í™˜ìì˜ ë³‘ë ¥ì„ ì¶”ê°€ context informationìœ¼ë¡œ í¬í•¨í–ˆë‹¤. Classification taskì˜ ê²½ìš°ëŠ” ë‹µë³€ ì˜µì…˜ì´ ì œê³µë˜ëŠ” ê°ê´€ì‹ ì§ˆë¬¸ìœ¼ë¡œ ê³µì‹í™”í–ˆë‹¤. 
<br/><br/>

ëª¨ë¸ì´ instructionì„ ë” ì˜ ë”°ë¥¼ ìˆ˜ ìˆë„ë¡ task promptì— **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>one-shot exemplar</span></mark>**ë¥¼ ì¶”ê°€í–ˆë‹¤. One-shot exemplerëŠ” ëª¨ë¸ì´ ì›í•˜ëŠ” í˜•ì‹ì˜ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ promptí•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤. ì´ ë•Œ multimodal taskì˜ ê²½ìš° ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì§€ ì•Šê³  text placeholder(text ë¬¸ìì—´ \<img\>)ë¡œ ëŒ€ì²´í–ˆë‹¤. ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ì˜ˆì‹œë¡œ ë„£ì§€ ì•Šì•„ ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ì˜€ë‹¤.
<br/><br/><br/>

> **In-Context Learning vs Fine-tuning**<br/>
> In-Context Learning ì´ë€,  Meta Learningì˜ ì¼ì¢…ìœ¼ë¡œ, ë³„ë„ì˜ ëª¨ë¸ì„ í•™ìŠµì„ ê±°ì¹˜ì§€ ì•Šê³ (weight ë³€ê²½ ì—†ìŒ), inference ë‹¨ê³„ì—ì„œ promptë¥¼ ì˜ ìƒì„±í•˜ì—¬ì¤Œìœ¼ë¡œì„œ ë§¥ë½ì ì¸ ì˜ë¯¸ë¥¼ ëª¨ë¸ì´ íŒŒì•…í•˜ê²Œ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ëª¨ë¸ì˜ ê¸°ì¡´ ì§€ì‹ê³¼ generalization ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì£¼ì–´ì§„ ë§¥ë½ì  ë‹¨ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • taskì„ ì´í•´í•˜ê³  ìˆ˜í–‰í•œë‹¤.<br/>
> ë°˜ë©´ Fine-tuningì€ pre-trainëœ ëª¨ë¸ì„ íŠ¹ì • taskë‚˜ domainì— ëŒ€í•´ ì¶”ê°€ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤. ëª¨ë¸ì˜ weightì„ ë°ì´í„°ì— ë” ì˜ ë§ê²Œ ì¡°ì •í•˜ì—¬ íŠ¹ì • task ë˜ëŠ” domainì— ëŒ€í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.<br/>
> ë‘ ë°©ë²•ì— ëŒ€í•œ ë¹„êµëŠ” ì•„ë˜ì™€ ê°™ë‹¤.<br/>
>
> ![Med-PaLM_4.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/175c0f1d-d733-4633-9bfc-6d19de1b9013){: width="1100px"}
>

> **Instruction Tuning (Instruction Finetuning)***<br/>
> Instruction Tuningì€ ìœ„ì˜ ë‘ ë°©ë²•ì„ ê²°í•©í•˜ì—¬ ëª¨ë¸ì˜ ìœ ì—°ì„±ì„ í‚¤ìš°ê³  ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°©ë²•ì´ë‹¤. Fine-tuning ì²˜ëŸ¼ ì¶”ê°€ì ì¸ í•™ìŠµì„ ì§„í–‰í•˜ëŠ”ë° ì´ ë•Œ í•™ìŠµí•˜ëŠ” ë°ì´í„°ì…‹ì´ ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ì§€ì‹œ(instruction)ì™€ ì´ì— ëŒ€í•œ ì‘ë‹µ(output)ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ì´ëŸ¬í•œ pair datasetì„ í†µí•´ ëª¨ë¸ì€ ì§ˆë¬¸ì— ëŒ€í•´ ë” ìœ ì—°í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ë„ì¶œí•˜ë„ë¡ í•™ìŠµëœë‹¤. <br/>
> Datasetì—ì„œ ì§€ì‹œ ë‚´ìš©ì— ì¶”ê°€ì ì¸ ì„¤ëª…ì´ í•„ìš”í•˜ë‹¤ë©´ In-Context learningì—ì„œ few-shot ì˜ˆì‹œë¥¼ ì£¼ëŠ” ê²ƒ ì²˜ëŸ¼ Instructionì— ë§ë¶™ì—¬ ì¤„ ìˆ˜ë„ ìˆë‹¤.<br/>
> ì°¸ê³ : [https://devocean.sk.com/blog/techBoardDetail.do?ID=165806&boardType=techBlog](https://devocean.sk.com/blog/techBoardDetail.do?ID=165806&boardType=techBlog)
> 

<br/><br/><br/><br/>

#### Model training

- Pretrainëœ 12B, 84B, 562B parameter PaLM-Eì— ëŒ€í•´ fine-tuning ë¨
- ì „ì²´ MultiMedBench taskì— ëŒ€í•´ ì•„ë˜ì˜ í‘œì™€ ê°™ì€ ë¹„ìœ¨ë¡œ í˜¼í•©í•˜ì—¬ í•™ìŠµë¨
- ì „ì²´ ëª¨ë¸ì— ëŒ€í•´ End-to-End training ì§„í–‰
- ViTëŠ” JFT-300Mì— ëŒ€í•´ supervised ë°©ì‹ìœ¼ë¡œ pre-train ë¨

![Med-PaLM_5.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/ef220c5a-503e-43a5-a0c8-c0e7cbb61458){: width="1000px"}
<br/><br/><br/><br/><br/><br/>

# Experiments

---

### 1. Med-PaLM M performs near or exceeding SOTA on all MultiMedBench tasks

ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë¹„êµ í‰ê°€ë¥¼ ìˆ˜í–‰í–ˆë‹¤. 

- MultiMedBench taskì— ëŒ€í•´ SOTA ëª¨ë¸ê³¼ ë¹„êµ(ë‹¨ì¼ task)
- MultiMedBench dataì— ëŒ€í•´ fine-tuningì„ ì§„í–‰í•˜ì§€ ì•Šì€ generalist ëª¨ë¸ (PaLM-E)
<br/><br/>

ê²°ê³¼ëŠ” ì•„ë˜ í‘œì™€ ê°™ë‹¤. Med-PaLM Mì€ SOTA ëª¨ë¸ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. 

![Med-PaLM_6.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/43332fec-1ca6-41e6-8624-6445cec53dff){: width="800px"}
<br/><br/><br/><br/>

### 2. Med-PaLM M demonstrates zero-shot generalization to novel medical tasks and concepts

ì €ìëŠ” ìƒˆë¡œìš´ conceptì— ëŒ€í•œ generalization ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ Montgomery County(MC) ë°ì´í„°ì…‹ì˜ chest X-ray ì´ë¯¸ì§€ì—ì„œ ê²°í•µ(TB) ì´ìƒ ê°ì§€ì— ëŒ€í•´ í‰ê°€ë¥¼ ì§„í–‰í–ˆë‹¤. ì•„ë˜ í‘œë¥¼ í™•ì¸í•´ë³´ë©´, unseen ë°ì´í„°ì— ëŒ€í•œ zero-shot generalization ê¸°ëŠ¥ì´ í•´ë‹¹ ë°ì´í„°ì…‹ì— ìµœì í™”ëœ SOTAì™€ ë¹„êµí•˜ì—¬ ê²½ìŸë ¥ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![Med-PaLM_7.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/36bd360e-d9b8-4538-b3c9-d3ea435a9668){: width="1100px"}
<br/><br/><br/><br/>

### 3. Med-PaLM M performs encouragingly on radiology report generation across model scales

4ëª…ì˜ ì„ìƒì˜ í‰ê°€ìê°€ ë³´ê³ ì„œì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•´, MIMIC-CXR ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë°©ì‚¬ì„ ê³¼ ì˜ì‚¬ê°€ ì œê³µí•œ reference reportë¥¼ ë‹¤ë¥¸ Med-PaLM M ëª¨ë¸ scale(12B, 84B ë° 562B)ì—ì„œ ìƒì„±ëœ ë³´ê³ ì„œì™€ ë¹„êµí–ˆë‹¤.
<br/><br/>

ê·¸ë¦¼ 4aëŠ” ê° í‰ê°€ìê°€ 3ê°œì˜ Med-PaLM M variant ì¤‘ í•˜ë‚˜ì—ì„œ ìƒì„±ëœ ë³´ê³ ì„œ ë˜ëŠ” reference report ì¤‘ì—ì„œ ê°€ì¥ ì¢‹ë‹¤ê³  í‰ê°€í•œ ë¹ˆë„ë¥¼ ìš”ì•½í•œ ê²ƒì´ë‹¤. ë˜í•œ ê° Med-PaLM M ëª¨ë¸ì—ì„œ ìƒì„±ëœ ë³´ê³ ì„œë¥¼ ë°©ì‚¬ì„ ê³¼ ì˜ì‚¬ê°€ ì œê³µí•œ  reference reportì™€ ì§ì ‘ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ 1:1 ë¹„êµë¥¼ ìˆ˜í–‰í–ˆë‹¤. ê²°ê³¼ëŠ” ê·¸ë¦¼ 4bì™€ ê°™ë‹¤.

![Med-PaLM_8.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/dde6870e-fb59-4e88-9bc7-fefea1f19e1e){: width="1200px"}
<br/><br/><br/>

ë˜í•œ Human evaluation(ë°©ì‚¬ì„ ê³¼ ì˜ì‚¬ í™•ì¸)ì„ í†µí•´ ëˆ„ë½ ë° ì˜¤ë¥˜ìœ¨ì— ëŒ€í•´ ì¡°ì‚¬í–ˆë‹¤. ê·¸ë¦¼ 5ëŠ” ëª¨ë¸ variant(12B, 84B, 562B)ì— ë”°ë¥¸ ê²°ê³¼ì´ë‹¤. ì£¼ëª©í•  ì ì€ ì´ ì˜¤ë¥˜ìœ¨ì´ ì´ì „ ì—°êµ¬ì—ì„œ MIMIC-CXR ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì¸ê°„ ë°©ì‚¬ì„ ê³¼ ì˜ì‚¬ baselineìœ¼ë¡œ ë³´ê³ ëœ ì˜¤ë¥˜ìœ¨ê³¼ ë¹„ìŠ·í•˜ë‹¤ëŠ” ì ì´ë¼ê³  í•œë‹¤. 

![Med-PaLM_9.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/5ddda004-d9fe-41af-8e8f-65df5a315074){: width="1200px"}

<br/><br/><br/><br/>
