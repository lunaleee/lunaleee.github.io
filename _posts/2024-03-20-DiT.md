---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Scalable Diffusion Models with Transformers (DiT)"
author: lunalee
date: 2024-03-20 19:37:23 +0800
categories: [AI, Paper Review]
tags: [Image, Generation, Diffusion, Transformer]
pin: false
math: true
---

<br/><br/>
`ICCV 2023`

- Paper: [https://arxiv.org/abs/2212.09748](https://arxiv.org/abs/2212.09748)
- Git: [https://github.com/facebookresearch/DiT](https://github.com/facebookresearch/DiT)
- Page: [https://www.wpeebles.com/DiT](https://www.wpeebles.com/DiT)
<br/><br/><br/><br/><br/>

# Introduction

---

![DiT_1.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/001867e6-162a-4259-b941-2326eeff43ed){: width="700px"}

ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ Neural architectureëŠ” Transformer ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆë‹¤. Image Generationì˜ ê²½ìš°, Autoregressive modelì—ì„œëŠ” transformerê°€ í¼ì ¸ìˆì§€ë§Œ ë‹¤ë¥¸ Generative modeling frameworkì—ì„œëŠ” ë§ì´ ì‚¬ìš©ë˜ê³  ìˆì§€ ì•Šë‹¤. íŠ¹íˆ Diffusion modelì€ ìµœê·¼ ì´ë¯¸ì§€ ìƒì„±ì— ìˆì–´ ì„ ë‘ì— ìˆë‹¤ê³  í•  ìˆ˜ ìˆì§€ë§Œ, backboneìœ¼ë¡œëŠ” Convolutional U-Net êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤.

ë‹¤ì–‘í•œ U-Net ê¸°ë°˜ diffusion backbone ì—°êµ¬ë¥¼ í†µí•´ architecture ì„ íƒì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹«ê³ , ì €ìëŠ” generative modeling ì—°êµ¬ì— ëŒ€í•œ baselineì„ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. Diffusion modelì—ì„œ U-Netì˜ inductive biasê°€ ì„±ëŠ¥ì— ì¤‘ìš”í•˜ì§€ ì•Šìœ¼ë©°, transformer ì„¤ê³„ë¡œ ëŒ€ì²´ë  ìˆ˜ ìˆìŒì„ ì¦ëª…í•œë‹¤. 
<br/><br/>

ë…¼ë¬¸ì—ì„œëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Transformer ê¸°ë°˜ Diffusion modelì„ ì œì•ˆ</span></mark>**í•˜ê³ , ì´ë¥¼ Diffusion Transformer(DiT)ë¼ê³  í•œë‹¤. ViTì˜ êµ¬ì¡°ë¥¼ ì‘ìš©í–ˆìœ¼ë©°, network complexityì™€  sample quality ì¸¡ë©´ì—ì„œ transformerì˜ scalingì— ëŒ€í•´ ì—°êµ¬í•œë‹¤. ë˜í•œ VAE Latent spaceì—ì„œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” LDM(Latent Diffusion Model) frameworkì—ì„œ DiTë¥¼ ì„¤ê³„í•¨ìœ¼ë¡œì¨ U-Net backboneì„ transformerë¡œ ì„±ê³µì ìœ¼ë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆìŒì„ ì¦ëª…í–ˆë‹¤.
<br/><br/><br/><br/><br/><br/>

# Method

---

## 1. Preliminaries

#### Diffusion formulation.

ë…¼ë¬¸ì—ì„œëŠ” Diffusion Model(DDPM)ì— ê´€í•œ ê¸°ë³¸ ì§€ì‹ì„ ì„¤ëª…í•˜ê³  ìˆë‹¤. ì´ ë¶€ë¶„ì€ ì•„ë˜ ê·¸ë¦¼ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¸”ë¡œê·¸ ë‚´ [[Generative model ê¸°ì´ˆ 3. Diffusion ì •ë¦¬](https://lunaleee.github.io/posts/Diffusion/)] ë¥¼ ì°¸ì¡°ë°”ë€ë‹¤.

![DiT_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/f0fe9d9a-5dce-48ac-a468-ce94e4253419){: width="1100px"}
<br/><br/><br/>

#### Classifier-free guidance.

Conditional diffusion modelì€ class labelì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ì´ ê²½ìš° Reverse processëŠ” $p_\theta(x_{t-1}âˆ£x_t, c)$ì™€ ê°™ì´ ìˆ˜ì •ë˜ê³ , ë…¸ì´ì¦ˆ $\epsilon_{\theta}$ì™€ $\Sigma_\theta$ëŠ” cì— ë”°ë¼ conditionì´ ì§€ì •ëœë‹¤. ì´ ë•Œ classifier-free guidanceë¥¼ ì‚¬ìš©í•˜ì—¬ $\log(câˆ£x)$ê°€ ë†’ì€ $x$ë¥¼ ì°¾ë„ë¡ ì¥ë ¤í•  ìˆ˜ ìˆë‹¤. classifier-free guidanceëŠ” ì¼ë°˜ì ì¸ sampling ê¸°ìˆ ì— ë¹„í•´ í¬ê²Œ í–¥ìƒëœ sampleì„ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, DiT ëª¨ë¸ì—ì„œë„ ì´ëŸ¬í•œ ë°©ë²•ì„ ì ìš©í•œë‹¤.
<br/><br/><br/>

#### Latent diffusion models.

High-resolution Pixel spaceì—ì„œ Diffusion modelì„ ì§ì ‘ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì€ ê³„ì‚°ì ìœ¼ë¡œ ì‰½ì§€ ì•Šë‹¤. LDMì—ì„œëŠ” 2-stage ë°©ì‹ìœ¼ë¡œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í–ˆë‹¤.

(1) í•™ìŠµëœ **autoencoder**ë¥¼ ì‚¬ìš©í•˜ì—¬ imageë¥¼ ë” ì‘ì€ ì°¨ì›ì˜ representationìœ¼ë¡œ ë³€í™˜<br/>
(2) encoderì—ì„œ ì••ì¶•ëœ representationì„ ë””ì½”ë”©í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” **diffusion model** í•™ìŠµ
<br/><br/>

ë³¸ ë…¼ë¬¸ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [[Stable Diffusion ë¦¬ë·°](https://lunaleee.github.io/posts/StableDiffusion/)] ê²Œì‹œë¬¼ì„ ì°¸ê³ í•˜ê¸¸ ë°”ë€ë‹¤. 
<br/><br/><br/><br/><br/>

## 2. Diffusion Transformer Design Space

ë³¸ ë…¼ë¬¸ì—ì„œ ì¤‘ì ì€ DDPMì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ë¯€ë¡œ transformer êµ¬ì¡°ëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ViT(Vision Transformer) architectureë¥¼ ê¸°ë°˜</span></mark>**ìœ¼ë¡œ í•œë‹¤. 
<br/><br/>

#### Patchify.
![DiT_3.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/a582da5e-cdb1-4fea-8acd-273a0bdbabcd){: width="500px"}

DiTì˜ ì…ë ¥ì€ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>spatial representation(VAEì—ì„œ ë‚˜ì˜¨ noised latent) $z$</span></mark>**ì´ë‹¤(image: 256 Ã— 256 Ã— 3 â†’ $z$: 32 Ã— 32 Ã— 4). DiTì˜ ì²«ë²ˆì§¸ layerì—ì„œ spatial inputì„ patchë¡œ ë‚˜ëˆ„ê³ , patchë“¤ì€ ê°ê° linearly embeddingë˜ì–´ $T$ê°œ token sequenceë¡œ patchify ëœë‹¤. Patchify ì´í›„ ViTì˜ frequency-based positional embedding(sine-cosine version)ì„ ëª¨ë“  ì…ë ¥ tokenì— ì ìš©í•œë‹¤(imageê°€ latent featureë¡œ ë³€ê²½ëœ ì ë§Œ ì œì™¸í•˜ê³  ì—¬ê¸°ê¹Œì§€ ViTì™€ ë™ì¼í•˜ë‹¤). 

Patchifyì— ì˜í•´ ìƒì„±ëœ token $T$ì˜ ìˆ˜ëŠ” patch size í•˜ì´í¼íŒŒë¼ë¯¸í„° $p$ì— ì˜í•´ ê²°ì •ëœë‹¤(patch sizeê°€ ì‘ì•„ì§€ë©´ ê·¸ë§Œí¼ tokenì˜ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚œë‹¤). $p$ê°€ ì‘ì•„ì§€ë©´ $T$ê°€ ì»¤ì§€ê³  ì´ì—ë”°ë¼ GFlopsê°€ ì¦ê°€í•œë‹¤.
<br/><br/><br/>

#### DiT block design.

![DiT_4.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/f25f0836-7ddf-4be2-b685-9d9bbebab57d){: width="1400px"}

Patchify ë‹¨ê³„ë¥¼ ì§€ë‚˜ ì…ë ¥ tokenë“¤ì€ transfomer ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤. í•˜ì§€ë§Œ Diffusion modelì€ noised ì´ë¯¸ì§€ input ì™¸ì—ë„ noise timestep $t$, class label $c$, natural language ë“±ê³¼ ê°™ì€ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ì¶”ê°€ conditionì •ë³´ë¥¼ ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬</span></mark>**í•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì €ìëŠ” conditional inputì„ ë‹¤ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ” transformer blockì˜ ë„¤ê°€ì§€ ë³€í˜•ì„ ì œì‹œí•œë‹¤. 
<br/><br/>

**1) In-context conditioning**

ë‹¨ìˆœíˆ $t$ì™€ $c$ì˜ vector ì„ë² ë”©ì„ ì…ë ¥ ì‹œí€€ìŠ¤ì— ë‘ ê°œì˜ ì¶”ê°€ tokenìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ tokenê³¼ ë‹¤ë¥´ì§€ ì•Šê²Œ ì²˜ë¦¬í•œë‹¤(ViTì˜ cls tokenê³¼ ìœ ì‚¬). ì´ ë°©ë²•ì€ ViT blockì„ ë³„ë„ë¡œ ìˆ˜ì •í•  í•„ìš” ì—†ë‹¤. ë§ˆì§€ë§‰ block ì´í›„ì— output ì‹œí€€ìŠ¤ì—ì„œ conditioning tokenì„ ì œê±°í•œë‹¤.
<br/><br/>

**2) Cross-attention block**

$t$ì™€ $c$ ì„ë² ë”©ì„ ì´ë¯¸ì§€ tokenê³¼ ë³„ë„ë¡œ ë¶„ë¦¬í•œë‹¤. $t$ì™€ $c$ëŠ” concatí•˜ì—¬ ê¸¸ì´ê°€ 2ì¸ ì‹œí€€ìŠ¤ë¡œ ë§Œë“ ë‹¤. Transformer blockì€ multi-head self-attention block ì´í›„ multi-head cross-attention layerê°€ ì¶”ê°€ëœë‹¤. ì´ ë°©ë²•ì€ class labelì„ conditionìœ¼ë¡œ ì£¼ê¸° ìœ„í•´ LDMì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬í•œ ë°©ì‹ì´ë‹¤.
<br/><br/>

**3) Adaptive layer norm (adaLN) block**

GANê³¼ U-Net backboneì„ ê°€ì§„ Diffusion modelì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” Adaptive normalization layerë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ì„œ, Transformerì—ì„œ ì‚¬ìš©í•˜ëŠ” standard layer normì„ adaptive layer norm (adaLN)ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤.  dimension-wise scale/shift parameter $\gamma$ì™€ $\beta$ë¥¼ ì§ì ‘ í•™ìŠµí•˜ëŠ” ëŒ€ì‹  $t$ì™€ $c$ì˜ ì„ë² ë”© vectorë¥¼ ì´ìš©í•´ì„œ regressioní•˜ê²Œ ëœë‹¤(ìì„¸í•œ ë°©ë²• ì•„ë˜ ì°¸ì¡°). ìœ„ì˜ ë°©ë²•ë“¤ ì¤‘ adaLNì€ Gflopsê°€ ê°€ì¥ ì ìœ¼ë¯€ë¡œ ê³„ì‚° íš¨ìœ¨ì„±ì´ ê°€ì¥ ë†’ë‹¤. ë˜í•œ ëª¨ë“  tokenì— ë™ì¼í•œ featureë¥¼ ì ìš©í•˜ëŠ” conditioning ë°©ë²•ì´ë‹¤.
<br/><br/>

> **Layer Normalization**<br/>
> 
> $$
> \text{LN}(x)\; = \; \gamma\bigg(\frac{x-\mu(x)}{\sigma(x)}\bigg) \; + \; \beta
> $$
> 
<br/>

> **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>FiLM</span></mark>([FiLM: Visual Reasoning with a General Conditioning LayerğŸ“„](https://arxiv.org/abs/1709.07871))**<br/>
> 
FiLM ë…¼ë¬¸ì€ conditioningì„ ìœ„í•œ ë°©ë²•ì„ ì œì‹œí•œ ë…¼ë¬¸ì´ë‹¤. í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ì…ë ¥ ì´ë¯¸ì§€ì™€ ê´€ë ¨í•´ì„œ conditioningí•  ì •ë³´ë¥¼ ì¸ì½”ë”©í•œ ë’¤, ë„¤íŠ¸ì›Œí¬ì—ì„œ ì´ë¯¸ì§€ feature mapì— affine transformation í•´ì¤Œìœ¼ë¡œì„œ adaptively ì ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. <br/>
ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. Condition input(ex. caption)ì„ ì„ì˜ì˜ function(neural networkë¡œ êµ¬í˜„ë¨)ì„ ì´ìš©í•´ scale vector $\gamma_{i,c}$, shift vetor $\beta_{i,c}$ë¡œ ì¸ì½”ë”©í•œë‹¤. ê·¸ ë’¤ì— ì´ **vectorë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ featureì— affine transformì„ ì§„í–‰**í•œë‹¤.
> 
> 
> ![DiT_5.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/e8f06818-3663-4250-bc23-19c461d71554){: width="700px"}
> 
<br/>

> ë³¸ ë…¼ë¬¸ì—ì„œ ìˆ˜í–‰í•œ **adaLN**ì€ ì´ëŸ¬í•œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>affine transformì˜ í˜•íƒœë¥¼ Layer Noramlizationì— ì ìš©í•œ í˜•íƒœ</span></mark>**ë¼ê³  í•  ìˆ˜ ìˆë‹¤.<br/>
> ë¨¼ì € ê¸°ì¡´ì˜ Layer Normalizationê³¼ ê°™ì´ Data sample ë‹¨ìœ„ë¡œ í‰ê· ê³¼ ë¶„ì‚°ì„ êµ¬í•œë‹¤. ì—¬ê¸°ì„œ learnable scale/shift parameter $\gamma, \beta$ë¥¼ í•™ìŠµí•˜ëŠ” ëŒ€ì‹  timestep $t$ì™€ class label $c$ë¥¼ shift, scale ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
> 
> 
> ![DiT_6.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/974a1380-c144-4d45-9f66-e5854a56c6a0){: width="500px"}

<br/><br/>

**4) adaLN-Zero block**

ResNetì—ì„œ Residual blockì€ ì¼ë°˜ì ìœ¼ë¡œ identity functionë¡œ ì´ˆê¸°í™”ëœë‹¤. Diffusion U-Net ëª¨ë¸ì—ì„œë„ ì´ì™€ ìœ ì‚¬í•œ ì´ˆê¸°í™” ì „ëµì„ ì‚¬ìš©í•˜ì—¬ residual connection ì´ì „ ë§ˆì§€ë§‰ conv layerì— zero-initializingì„ ì ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ìœ ì‚¬í•œ ì‘ì—…ì„ ìœ„í•´ ì €ìëŠ” adaLNì„ ìœ„í•œ $\gamma, \beta$ ì´ì™¸ì— DiT block ë‚´ì˜ residual connection ì „ì— ì ìš©ë˜ëŠ” dimension-wise scaling parameters $\alpha$ë¥¼ ë„ì…í–ˆë‹¤. 

ëª¨ë“   $\alpha$ì— ëŒ€í•´ Zero-vectorë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ MLPë¥¼ ì´ˆê¸°í™”í•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ DiT blockì„ identity functionìœ¼ë¡œ ì´ˆê¸°í™”í•œë‹¤. 

![DiT_7.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/46ea9a27-b134-4a82-8b97-8c780efc409c){: width="500px"}
<br/><br/><br/><br/>

#### Model size.

ê°ê°ì˜ hidden dimension sizeê°€ dê°œì¸ Nê°œì˜ DiT blockì„ ì ìš©í–ˆë‹¤. ViTì™€ ê°™ì´ í‘œì¤€ transformer êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆë‹¤. ëª¨ë¸ êµ¬ì„±ì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ëŠ” ì•„ë˜ í‘œì™€ ê°™ë‹¤.

![DiT_8.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/0bf2233e-f230-4179-8197-7b4e412a766c){: width="550px"}
<br/><br/><br/><br/>

#### Transformer decoder.
![DiT_9.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/297aae5a-f27b-4f5e-80eb-1df21c7a5c1d){: width="350px"}

DiT block ì´í›„ ë‚˜ì˜¨ ì´ë¯¸ì§€ token sequenceë¥¼ output noise prediction()ê³¼ output diagonal covariance predictionìœ¼ë¡œ ë””ì½”ë”©í•´ì•¼í•œë‹¤. ì´ë¥¼ ìœ„í•´ linear decoderë¥¼ ì‚¬ìš©í•œë‹¤. ë§ˆì§€ë§‰ layer normì„ ì ìš©í•˜ê³  ê° tokenì„ $p\times p \times C  â†’ p\times p \times 2C$ tensorë¡œ ë””ì½”ë”©í•˜ê³  reshapeí•œë‹¤.
<br/><br/><br/><br/><br/>

## 3. Experimental Setup

**Training.**

- ImageNet datasetì˜ 256 Ã— 256, 512 Ã— 512 resolution ì´ë¯¸ì§€ ì‚¬ìš©
- Data augmentation: horizontal flips
- ViTì™€ ë‹¬ë¦¬ learning rate warmup, regularization ì—†ì´ë„ ì•ˆì •ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•¨
- EMA model(exponential moving average): decay 0.9999
<br/><br/><br/>

**Diffusion.**

- Encoder: Stable Diffusionì˜ pretrained VAE ì‚¬ìš©
- VAE ì…ë ¥ RGB ì´ë¯¸ì§€ëŠ” 256Ã—256Ã—3, $z = E(x)$ëŠ” 32 Ã— 32 Ã— 4
- Diffusion ëª¨ë¸ì—ì„œ ìƒˆë¡œìš´ latentë¥¼ ìƒì„±í•œ í›„ VAE Decoder$(x=D(z))$ë¥¼ ì‚¬ìš©í•˜ì—¬ pixel ì´ë¯¸ì§€ë¡œ ë””ì½”ë”©
<br/><br/><br/>

**Evaluation metrics.**

- FIDë¥¼ ì‚¬ìš©í•˜ì—¬ scaling performanceë¥¼ ì¸¡ì •í•¨
- Inception Score, sFID ë° Precision/Recallì„ ë³´ì¡° ì¸¡ì •í•­ëª©ìœ¼ë¡œ ì‚¬ìš©í•¨
<br/><br/><br/><br/><br/><br/>

# Experiments

---

**DiT block design.**

ë‹¤ì–‘í•œ DiT block designì— ëŒ€í•´ FID ì„±ëŠ¥ì„ ë¹„êµí–ˆë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤.<br/>
![DiT_10.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/752c3a66-bef6-452a-8d48-a52e7240b88c){: width="500px"}
<br/><br/><br/><br/>

**Scaling model size and patch size.**

ë‹¤ì–‘í•œ ëª¨ë¸ config(S, B, L, XL)ì™€ patch size(8, 4, 2)ì— ëŒ€í•œ FID ë¹„êµ ê²°ê³¼ì´ë‹¤.<br/>
![DiT_11.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/991f2c8e-c4ab-4687-8b5c-eb7ab5179b01){: width="500px"}
<br/><br/><br/>

ë‹¤ìŒì€ DiT ëª¨ë¸ì˜ ë‹¤ì–‘í•œ ì „ëµì— ëŒ€í•œ ì‹¤í—˜ì— ëŒ€í•œ ê²°ê³¼ì´ë‹¤.<br/>
![DiT_12.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/5c25ae13-528d-4826-b5fa-0dd868be421e){: width="1200px"}
<br/><br/><br/><br/>

### 5.1. State-of-the-Art Diffusion Models

ë‹¤ìŒìœ¼ë¡œ ë‹¤ì–‘í•œ SOTA class-conditional generative modelê³¼ ë¹„êµí–ˆë‹¤. Bubble areaëŠ” diffusion ëª¨ë¸ì˜ flopsë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ê³  í•œë‹¤.<br/>
![DiT_13.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/ebcfc096-bfee-4acf-9b8e-2839f02bdbe2){: width="500px"}
<br/><br/><br/>

256Ã—256 ImageNet, 512Ã—512 ImageNetì—ì„œ SOTA class-conditional generative modelê³¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë¹„êµí–ˆë‹¤.<br/>
![DiT_14.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/4aee7cd1-3856-42be-885d-53399ebce00e){: width="500px"}

![DiT_15.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/84c5e0d1-2993-4a3b-ba50-c7c5a167bba2){: width="500px"}
<br/><br/><br/><br/>

### 5.2. Scaling Model vs. Sampling Compute

![DiT_16.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/1f5f9e74-d3a3-4f2d-aedc-1b4898181fe6){: width="500px"}
<br/><br/><br/><br/><br/>
