---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Generative Image Dynamics"
author: lunalee
date: 2024-07-11 19:43:12 +0900
categories: [AI, Paper Review]
tags: [Video, Generative, Diffusion]
pin: false
math: true
---

<br/><br/>
`Google Research`  `CVPR 2024` `Best paper`

- Paper: [https://arxiv.org/abs/2309.07906](https://arxiv.org/abs/2309.07906)
- Page: [https://generative-dynamics.github.io](https://generative-dynamics.github.io/)
<br/><br/><br/>

#### ğŸ“– í•µì‹¬ í›‘ì–´ë³´ê¸° !!
- 

<br/><br/><br/><br/>

# Introduction

---

Natural worldì˜ ì¥ë©´ë“¤ì€ ê²‰ë³´ê¸°ì— ì •ì ì¸ ì¥ë©´ì—ë„ ë°”ëŒ, ë¬¼ì˜ íë¦„, í˜¸í¡ê³¼ ê°™ì€ ìì—°ì ì¸ ë¦¬ë“¬ìœ¼ë¡œ ì¸í•´ ë¯¸ë¬˜í•œ ì§„ë™ì„ í¬í•¨í•˜ê³  ìˆë‹¤. ì‚¬ëŒì€ ì´ëŸ¬í•œ ë¯¸ë¬˜í•œ ì§„ë™, ì¦‰ ì›€ì§ì„(motion)ì„ ì‰½ê²Œ ìƒìƒí•  ìˆ˜ ìˆì§€ë§Œ, motionì„ ë§Œë“¤ì–´ë‚´ë„ë¡ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ì–´ë–¨ê¹Œ?<br/>
ì´ëŸ¬í•œ motionì€ ë¬¼ë¦¬ì ì¸ ì—­í•™(dynamic)ì— ì˜í•´ ì ìš©ëœë‹¤. ë¬¼ì²´ì˜ ì§ˆëŸ‰, íƒ„ì„± ë“±ì˜ í˜ì´ ë¬¼ì²´ì— ì ìš©ë˜ëŠ” ê²°ê³¼ì´ë¯€ë¡œ, ì¸¡ì •ì´ ì‰½ì§€ ì•Šë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ ëª¨ë¸ë§ì ì¸ ì¸¡ë©´ì—ì„œ ì ‘ê·¼í•˜ë©´ ì¢‹ì„ê¹Œ?
<br/><br/>

íŠ¹ì • applicationì—ì„œëŠ” ì´ëŸ¬í•œ ì–‘ì„ ì •í™•íˆ ì¸¡ì •í•˜ì§€ ì•Šì•„ë„, ë¬¼ì²´ì—ì„œ ì§ì ‘ **ê´€ì°°ëœ 2D motionì„ ë¶„ì„**í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì—­í•™ì„ ì‹œë®¬ë ˆì´ì…˜ í•  ìˆ˜ ìˆë‹¤. ê´€ì°°ëœ motionì´ ì¼ì¢…ì˜ ê°ë… ì‹ í˜¸ ì—­í• ì„ í•˜ì—¬, í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì´ë‹¤. ë¹„ë¡ ê´€ì°°ëœ motionì€ ë³µì¡í•œ ë¬¼ë¦¬ì  íš¨ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì§€ë§Œ ì¢…ì¢… ì˜ˆì¸¡ê°€ëŠ¥í•˜ê¸°ë„ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. (e.g.ì´›ë¶ˆì€ íŠ¹ì • ë°©ì‹ìœ¼ë¡œ ê¹œë¹¡ê±°ë¦¬ê³ , ë‚˜ë¬´ëŠ” í”ë“¤ë¦¬ê³ , ìì€ ë°”ìŠ¤ë½ê±°ë¦°ë‹¤.) 
<br/><br/>

![GID_1.png](https://github.com/user-attachments/assets/50a458a3-84de-4daf-ad3e-7898ce85a99d){: width="900px"}

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **image-space scene motion**, ì¦‰ ì´ë¯¸ì§€ì˜ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ëª¨ë“  í”½ì…€ì˜ motionì— ëŒ€í•œ generative priorë¥¼ ëª¨ë¸ë§</span></mark>**í•œë‹¤. ì´ ëª¨ë¸ì€ ê±°ëŒ€í•œ real video sequence ëª¨ìŒì—ì„œ ìë™ìœ¼ë¡œ ì¶”ì¶œëœ motion trajectoryì— ëŒ€í•´ í•™ìŠµí•œë‹¤. íŠ¹íˆ ê° training videoì—ì„œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>spectral volumeì´ë¼ëŠ”</span></mark>** í˜•íƒœë¡œ motionì„ ê³„ì‚°í•œë‹¤. Spectral volumeì€ denseí•œ, long-range pixel trajectoryë¥¼ ì˜ë¯¸í•˜ëŠ” **frequency-domain representation**ì´ë‹¤. ë°”ëŒì— í”ë“¤ë¦¬ëŠ” ê½ƒê³¼ ë‚˜ë¬´ì™€ ê°™ì€ ì§„ë™ ì—­í•™(oscillatory dynamics)ì— ì í•©í•˜ë‹¤. 
<br/><br/>

ë˜í•œ ì €ìëŠ” spectral volumeì´ **diffusion output**ìœ¼ë¡œ ìƒì„±í•˜ê¸° íš¨ê³¼ì ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í–ˆë‹¤. ë”°ë¼ì„œ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ conditionìœ¼ë¡œ, í•™ìŠµëœ distributionì—ì„œ spectral volumeì„ ìƒ˜í”Œë§í•  ìˆ˜ ìˆëŠ” generative modelì„ í•™ìŠµ</span></mark>**í•œë‹¤. Predicted spectral volumeì€ **motion texture**(long-range, per-pixel motion trajectory ì§‘í•©)ë¡œ ë³€í™˜í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì• ë‹ˆë©”ì´ì…˜í™” í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì¦‰, ì˜ˆì¸¡ëœ motionì€ ë¯¸ë˜ í”„ë ˆì„ì„ í•©ì„±í•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤.
<br/><br/>

ë°”ë¡œ RGB ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ”, RGB í”½ì…€ì— ëŒ€í•œ priorì™€ ë¹„êµí•  ë•Œ, **motionì— ëŒ€í•œ priorëŠ” ë” ê¸°ë³¸ì ì´ê³  lower-dimensional structureë¥¼ ìº¡ì²˜**í•˜ì—¬ í”½ì…€ ê°’ì˜ long-range variationì„ íš¨ìœ¨ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤ê³ í•œë‹¤. ë”°ë¼ì„œ í”„ë ˆì„(ê° ì´ë¯¸ì§€) ì‚¬ì´ì˜ ì¤‘ê°„ motionì„ ìƒì„±í•˜ë©´ ë³´ë‹¤ ì¼ê´€ëœ long-term generationê³¼ ì• ë‹ˆë©”ì´ì…˜ì— ëŒ€í•œ ë³´ë‹¤ ì„¸ë°€í•œ ì œì–´ê°€ ê°€ëŠ¥í•˜ë‹¤.
<br/><br/><br/><br/><br/><br/><br/>

# Overview

---

ë…¼ë¬¸ì˜ ëª©í‘œëŠ” single picture $I_0$ê°€ ì£¼ì–´ì§€ë©´ ë‚˜ë¬´, ê½ƒ ë˜ëŠ” ë°”ëŒì— í”ë“¤ë¦¬ëŠ” ì´›ë¶ˆê³¼ ê°™ì€ ì§„ë™ ìš´ë™ì„ ë‹´ê³  ìˆëŠ” ë¹„ë””ì˜¤ $\lbrace \hat I_1, \hat I_2, â€¦ , \hat I_T \rbrace$ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. ì „ì²´ ì‹œìŠ¤í…œì€ ë‘ ê°œì˜ ëª¨ë“ˆ(**<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Motion prediction module</span></mark>**, **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Image-based rendering module</span></mark>**)ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ì „ì²´ì ì¸ pipelineì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
<br/><br/>

1. Latent diffusion model (LDM) ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ Iì— ëŒ€í•œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>spectral volume</span></mark>** $\mathcal S = (S_{F_0}, S_{F_1}, â€¦ , S_{F_{K-1}})$ì„ ì˜ˆì¸¡í•œë‹¤.
2. ì˜ˆì¸¡ëœ spectral volumeì€ **inverse discrete Fourier transform**ì„ í†µí•´ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>motion texture</span></mark>** $\mathcal F = (F_1, F_2, â€¦, F_T)$ë¡œ ë³€í™˜ëœë‹¤. ì´ motionì€ ëª¨ë“  future time stepì—ì„œ ê° ì…ë ¥ í”½ì…€ì˜ ìœ„ì¹˜ë¥¼ ê²°ì •í•œë‹¤.
3. Motion textureê°€ ì£¼ì–´ì§€ë©´, **image-based rendering technique**ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ RGB ì´ë¯¸ì§€ì— **ì• ë‹ˆë©”ì´ì…˜ì„ ì ìš©**í•œë‹¤.
<br/><br/><br/><br/><br/><br/><br/>  

# Predicting Motion

---

## 1. Motion representation

ë¨¼ì € Motion representationì— ëŒ€í•´ ì •ì˜í•´ë³´ì. Motionì€ ë‘ í”„ë ˆì„ ì‚¬ì´ì˜ ì›€ì§ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ, ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ì˜ ì£¼ëœ ì°¨ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ì„¸ë¶€ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ì •ì˜í–ˆë‹¤. 
<br/><br/>

**[Motionì´ë€?]**<br/>
![GID_2.png](https://github.com/user-attachments/assets/0b1cd29f-3f44-4863-9c73-43ff977d6e98){: width="1100px"}

- **Motion texture**: time-varying **2D displacement map**ì˜ sequence. $\mathcal F = \lbrace F_tâˆ£t = 1,...,T \rbrace$
- ì—¬ê¸°ì„œ, ì…ë ¥ ì´ë¯¸ì§€ $I_0$ì˜ í”½ì…€ ì¢Œí‘œ $\mathbf p$ì—ì„œì˜ **2D displacement vector** $F_t(\mathbf p)$ëŠ” ë¯¸ë˜ ì‹œê°„ $t$ì—ì„œ í•´ë‹¹ í”½ì…€ì˜ ìœ„ì¹˜ë¥¼ ì •ì˜í•œë‹¤.
- ì‹œê°„ tì—ì„œ ë¯¸ë˜ í”„ë ˆì„ì„ ìƒì„±í•˜ë ¤ë©´ í•´ë‹¹ displacement map $D_t$ë¥¼ ì‚¬ìš©í•˜ì—¬ $I_0$ì˜ í”½ì…€ì„ ì´ë™ì‹œì¼œ forward-warpëœ ì´ë¯¸ì§€ $I'_t$ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

$$
I'_t(\mathbf p + F_t(\mathbf p)) = I_0(\mathbf p).
$$

<br/><br/><br/>

**[ì™œ spectral volume ì„ ì‚¬ìš©í–ˆì„ê¹Œ?]**

Motion textureë¥¼ í†µí•´ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ì„œ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ê³§ë°”ë¡œ time-domain motion textureë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ë„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ motion textureëŠ” ë¹„ë””ì˜¤ ê¸¸ì´ë§Œí¼ ìƒì„±ë˜ì–´ì•¼í•˜ê¸° ë•Œë¬¸ì—, $T$ê°œì˜ ì¶œë ¥ í”„ë ˆì„ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” $T$ê°œì˜ displacement fieldë¥¼ ì˜ˆì¸¡í•´ì•¼í•œë‹¤. ê¸´ ë¹„ë””ì˜¤ì— ëŒ€í•´, ì´ë ‡ê²Œ í° ì¶œë ¥ representationì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ ê²°êµ­ ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ long-term temporal consistencyë¥¼ ìƒì–´ë²„ë¦¬ëŠ” ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ê²Œ ëœë‹¤.
<br/><br/><br/>

![GID_3.png](https://github.com/user-attachments/assets/fae2a151-58e1-4c96-a54e-ced340f84ad1){: width="700px"}

ë°˜ë©´ì—, ë§ì€ natural motionì€ ì—¬ëŸ¬ ê°œì˜ ê°ê° ë‹¤ë¥¸ ì£¼íŒŒìˆ˜(frequency), ì§„í­(amplitude), ìœ„ìƒ(phase)ì„ ê°€ì§€ëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ì§„ë™(harmonic oscillation)ì˜ ì¤‘ì²©</span></mark>**ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ motionì€ quasi-periodic, ì¦‰ ì¤€ì£¼ê¸°ì ì´ë¯€ë¡œ **frequency domainì—ì„œ ëª¨ë¸ë§**í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•˜ë‹¤.
<br/><br/>

ë”°ë¼ì„œ ì €ìëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>spectral volume</span></mark>**ì´ë¼ëŠ” ë¹„ë””ì˜¤ì˜ motionì— ëŒ€í•œ íš¨ìœ¨ì ì¸ frequency space representationì„ ì±„íƒí–ˆë‹¤.

Spectral volumeì€ **ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œëœ per-pixel trajectoryì— ëŒ€í•´ temporal Fourier transformì„ ìˆ˜í–‰í•œ ê²°ê³¼**ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
<br/><br/>

> **[Visual Vibration AnalysisğŸ“„](https://www.abedavis.com/thesis.pdf)**<br/>
> Spectral volume ë³€í™˜ ê³¼ì •. Motion textureì—ì„œ frequency domainìœ¼ë¡œì˜ ë³€í™˜ì„ ìœ„í•´ Temporal Fourier Transformì„ ê±°ì³, specral volumeì„ ì–»ëŠ”ë‹¤.<br/>
> *** Fourier Transform â†’ ì…ë ¥ ì‹ í˜¸(ì´ë¯¸ì§€)ë¥¼ ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜(frequency)ë¥¼ ê°–ëŠ” ì£¼ê¸°í•¨ìˆ˜ë“¤ì˜ í•©ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ í‘œí˜„í•˜ê²Œ ë¨<br/>
> ![GID_4.png](https://github.com/user-attachments/assets/a9c07b3a-a931-4099-b9e3-3d9a26fdfe34){: width="700px"}

<br/><br/><br/><br/>

**[Spectral volumeì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ LDM ì„¤ê³„]**

Spectral volumeì„ motion representationìœ¼ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ì œ motion ì˜ˆì¸¡ ë¬¸ì œë¥¼ **multi-modal image-to-image translation task**ë¡œ ê³µì‹í™”í•œë‹¤(ì…ë ¥: ì´ë¯¸ì§€ â†’ ì¶œë ¥: motion spectral volume). 

- **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Latent diffusion model (LDM)</span></mark>**ì„ ì‚¬ìš©í•˜ì—¬ 4$K$-channel 2D motion spectrum mapìœ¼ë¡œ êµ¬ì„±ëœ spectral volumeì„ ìƒì„±í•œë‹¤.
- ì—¬ê¸°ì„œ K << TëŠ” ëª¨ë¸ë§ëœ frequencyì˜ ìˆ˜ ì´ê³ , ê° frequencyì—ì„œ 4ê°œì˜ scalarê°€ í•„ìš”í•œë°, ê°ê°  x- , y-ì°¨ì›ì˜ **ë³µì†Œìˆ˜ Fourier coefficient**ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
- ë¯¸ë˜ time step ì—ì„œ í”½ì…€ì˜ motion trajectory $\mathcal F(\mathbf p) = \lbrace F_t (\mathbf p)âˆ£t = 1, 2, ...T \rbrace$ ëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Fast Fourier Transform (FFT)</span></mark>**ì— ì˜í•´ ê·¸ì— í•´ë‹¹í•˜ëŠ” spectral volume $\mathcal S(\mathbf p) = \lbrace S_{f_k}(\mathbf p) âˆ£ k = 0, 1, .. \frac{T}{2} âˆ’ 1\rbrace$ ë¡œ ë³€í™˜ëœë‹¤.
    
    $$
    \mathcal S(\mathbf p) = \text{FFT}(\mathcal F (\mathbf p))
    $$
  
<br/><br/><br/>  

**[Frequency space representationì„ ìœ„í•œ ì¶”ê°€ì ì¸ ë¬¸ì œ]**<br/>
![GID_5.png](https://github.com/user-attachments/assets/7e2d572d-3822-48a7-aee8-0ae461e479b1){: width="500px"}

ì´ì œ **K ì¶œë ¥ frequency ìˆ˜ë¥¼ ì–´ë–»ê²Œ ì„ íƒ**í•´ì•¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ë¬¸ì œê°€ ë‚¨ì•„ìˆë‹¤. ì €ìëŠ” ì´ì „ ì—°êµ¬ë“¤ì„ í†µí•´ real-time animationì—ì„œ ëŒ€ë¶€ë¶„ì˜ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ìì—°ìŠ¤ëŸ¬ìš´ ì§„ë™ motionì´ ì£¼ë¡œ low-frequency ì„±ë¶„ìœ¼ë¡œ êµ¬ì„±</span></mark>**ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. ì´ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•´ randomìœ¼ë¡œ ìƒ˜í”Œë§í•œ 1000ê°œì˜ 5ì´ˆì§œë¦¬ ë¹„ë””ì˜¤ í´ë¦½ì—ì„œ ì¶”ì¶œí•œ motionì˜ í‰ê·  power spectrumì„ ê³„ì‚°í–ˆì„ ë•Œ, ìœ„ í”Œë¡¯ê³¼ ê°™ì´ high-frequencyì— ëŒ€í•´ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ì˜€ë‹¤.

ì´ëŠ” ëŒ€ë¶€ë¶„ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì§„ë™(natural oscillation) motionì´ ì‹¤ì œë¡œ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>low-frequency term</span></mark>**ìœ¼ë¡œ ì˜ í‘œí˜„ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê³ , ì‹¤ì œë¡œ $K = 16$ Fourier coefficientë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë‹¤ì–‘í•œ ì‹¤ì œ ë¹„ë””ì˜¤ì—ì„œ ì›ë˜ì˜ motionì„ ì‚¬ì‹¤ì ìœ¼ë¡œ ì¬í˜„í•˜ê¸°ì— ì¶©ë¶„í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤.
<br/><br/><br/><br/><br/>

## 2. Predicting motion with a diffusion model

Motion ì˜ˆì¸¡ì„ ìœ„í•´ í‘œì¤€ Latent diffusion model (LDM)ì„ backboneìœ¼ë¡œ ì‚¬ìš©í–ˆë‹¤. í‘œì¤€ LDMì€ ë‘ ê°€ì§€ ëª¨ë“ˆë¡œ êµ¬ì„±ëœë‹¤.

1. Variational autoencoder (VAE): Encoder $z = E(I)$ë¥¼ í†µí•´ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ latent spaceë¡œ ì••ì¶•, Decoder $I = D(z)$ë¥¼ í†µí•´ latent featureë¡œ ë¶€í„° ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¬êµ¬ì„±
2. U-Net based Diffusion model: Gaussian noiseì—ì„œ ì‹œì‘í•˜ì—¬ denoising processë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì ìš©í•˜ëŠ” í•™ìŠµ ë°©ë²• ì‚¬ìš©
<br/><br/>

![GID_6.png](https://github.com/user-attachments/assets/ca0e7756-2f92-4dc8-8151-8346cf1c9e47){: width="1300px"}

ë…¼ë¬¸ì—ì„œëŠ” ì´ processë¥¼ RGB ì´ë¯¸ì§€ê°€ ì•„ë‹Œ spectral volumeì— ì ìš©í•œë‹¤. Spectral volumeì€ ë§ˆì°¬ê°€ì§€ë¡œ encodingë˜ê³ , 2D U-Netì„ í†µí•´ noise $\epsilon_\theta(z^n; n, c)$ ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì œê±°í•˜ë„ë¡ í•™ìŠµëœë‹¤. ì´ ë•Œ **condition** $c$ëŠ” training video sequenceì˜ ì²« ë²ˆì§¸ í”„ë ˆì„ì¸ $I_0$ì´ë‹¤. ê·¸ ë‹¤ìŒ denoising ë‹¨ê³„ë¥¼ ê±°ì¹œ latent features $z^0$ì„ decoderì— ë„£ì–´ spectral volumeì„ ë³µêµ¬í•œë‹¤.
<br/><br/><br/><br/>

#### Frequency adaptive normalization.

![GID_7.png](https://github.com/user-attachments/assets/c7eb0b33-f02b-403a-807c-a62fd214e728){: width="600px"}

ì´ë ‡ê²Œ ëª¨ë¸ì„ ì„¤ê³„í•  ë•Œ í•œ ê°€ì§€ ê³ ë ¤í•´ì•¼í•  ë¬¸ì œëŠ”, motion textureê°€ frequencyì— ë”°ë¼ íŠ¹ì • ë¶„í¬ ì„±ì§ˆì„ ê°€ì§„ë‹¤ëŠ” ê²ƒì´ë‹¤. <span style='color: var(--txt-gray)'>~~(frequencyì™€ amplitudeëŠ” ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë…ë¦½ì ì¸ íŠ¹ì„±ì¸ë°, motion textureì— ëŒ€í•´ ë¶„ì„í–ˆì„ ë•Œ íŠ¹ì • ì—°ê´€ì„±? ê²½í–¥ì„±?ì„ ê°€ì§„ë‹¤ëŠ” ëœ»ì¸ ê²ƒ ê°™ë‹¤.)~~</span>

ìœ„ ê·¸ë¦¼ì˜ ì™¼ìª½ í”Œë¡¯ê³¼ ê°™ì´ spectral volumeì˜ amplitudeëŠ” 0~100ì˜ ë²”ìœ„ì— ë¶„í¬í•˜ê³  ìˆë‹¤. ì´ ë•Œ í•™ìŠµì„ ìœ„í•´ Normalizationì„ ì ìš©í•  ë•Œ, ì´ë¯¸ì§€ì™€ ë§ˆì°¬ê°€ì§€ë¡œ [0, 1]ì˜ ë²”ìœ„ë¡œ normalization í•˜ê²Œ ë˜ë©´ ìœ„ ê·¸ë¦¼ì˜ ì˜¤ë¥¸ìª½ í”Œë¡¯ê³¼ ê°™ì´ ë†’ì€ frequencyì˜ ê±°ì˜ ëª¨ë“  coefficientê°€ 0ì— ê°€ê¹Œì›Œì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ê²Œ ëœë‹¤. 
<br/><br/><br/>

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë…¼ë¬¸ì—ì„œëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>frequency adaptive normalization ë°©ë²•</span></mark>**ì„ ì ìš©í–ˆë‹¤. ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

1. Training setì—ì„œ ê³„ì‚°ëœ í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° frequencyì—ì„œ Fourier coefficientë¥¼ ë…ë¦½ì ìœ¼ë¡œ normalizeí•œë‹¤.
ì¦‰, ê° ê°œë³„ ì£¼íŒŒìˆ˜ $f_j$ì— ëŒ€í•´, ëª¨ë“  ì…ë ¥ ìƒ˜í”Œì— ëŒ€í•œ Fourier coefficient í¬ê¸°ì˜ 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , í•´ë‹¹ ê°’ì„ per-frequency scaling factor $s_{f_j}$ë¡œ ì‚¬ìš©í•œë‹¤.
2. ê·¸ ë‹¤ìŒ scalingëœ Fourier coefficientì— power transformationì„ ì ìš©í•˜ì—¬ ê·¹í•œê°’ì—ì„œ ë²—ì–´ë‚˜ë„ë¡ í•œë‹¤.
<br/><br/><br/>

ìœ„ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ë¡œê·¸ë‚˜ ì œê³±ê·¼ê³¼ ê°™ì€ nonlinear transformationë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ê³  í•œë‹¤. ìš”ì•½í•˜ë©´, frequency $f_j$ì—ì„œ spectral volume $\mathcal S(\mathbf p)$ì˜ ìµœì¢… coefficient value(í•™ìŠµí•˜ëŠ”ë° ì‚¬ìš©)ëŠ” ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°ëœë‹¤. ìœ„ ê·¸ë¦¼ì˜ ì˜¤ë¥¸ìª½ í”Œë¡¯ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯, í•´ë‹¹ ë°©ë²•ì„ ì ìš©í•œ í›„ spectral volume coefficientëŠ” ë” ê³ ë¥´ê²Œ ë¶„í¬í•œë‹¤.

$$
S'_{f_j}(\mathbf p) = \text{sign} (S_{f_j}) \sqrt{\bigg \lvert \frac{S_{f_j}(\mathbf p)}{s_{f_j}}\bigg \rvert}.
$$

<br/><br/><br/><br/>

#### Frequency-coordinated denoising.

$K$ frequency bandì˜ spectral volume $\mathcal S$ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•˜ë‚˜ì˜ diffusion U-Netìœ¼ë¡œ 4$K$ channelì˜ tensorë¥¼ ì¶œë ¥í•˜ë„ë¡ í•˜ë©´ ê°„ë‹¨í•˜ì§€ë§Œ, ë„ˆë¬´ ë§ì€ ìˆ˜ì˜ channelì„ ìƒì„±í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ ì§€ë‚˜ì¹˜ê²Œ ë§¤ë„ëŸ½ê³  ë¶€ì •í™•í•œ ê²°ê³¼ë¬¼ì„ ìƒì„±í•œë‹¤ëŠ” ì´ì „ì˜ ì—°êµ¬ ê²°ê³¼ë“¤ì´ ìˆì—ˆë‹¤. ê·¸ë ‡ë‹¤ê³  ë…ë¦½ì ìœ¼ë¡œ frequencyë¥¼ ì˜ˆì¸¡í•˜ê²Œ ë˜ë©´ ì„œë¡œ ìƒê´€ ê´€ê³„ê°€ ì—†ëŠ” ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ì—¬ ë¹„í˜„ì‹¤ì ì¸ motionìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì œê°€ ìˆë‹¤ê³  í•œë‹¤.
<br/><br/>

![GID_6.png](https://github.com/user-attachments/assets/ca0e7756-2f92-4dc8-8151-8346cf1c9e47){: width="1300px"}

ë”°ë¼ì„œ ì €ìëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>frequency-coordinated denoising strategy</span></mark>**ë¥¼ ì œì•ˆí•œë‹¤. ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 

1. ì…ë ¥ ì´ë¯¸ì§€ $I_0$ê°€ ì£¼ì–´ì§€ë©´, spectral volume $S_{f_j}$ì˜ **í•˜ë‚˜ì˜ 4-channel frequency sliceë¥¼ ì˜ˆì¸¡**í•˜ê¸° ìœ„í•œ LDM $\epsilon_\theta$ í•™ìŠµì„ ì§„í–‰í•œë‹¤. ì´ ë•Œ, time stampì™€ í•¨ê»˜ ì¶”ê°€ì ì¸ **frequency embedding**ì„ LDMì— ì…ë ¥í•œë‹¤.
2. ê·¸ ë‹¤ìŒ ì´ LDM $\epsilon_\theta$ì˜ parameterë¥¼ freezeí•œë‹¤.
3. LDM $\epsilon_\theta$ì— 2D spatial layerì™€ attention layerë¥¼ ë„ì…í•˜ê³ ($K$-frequency bandì— ê±¸ì³ì„œ), fine-tuning í•œë‹¤.
    1. ì¦‰ batch size $B$ì¼ ë•Œ, $\epsilon_\theta$ì˜ 2D spatial layerì—ì„œ ì±„ë„ í¬ê¸°ê°€ $C$ì¸ $B \cdot K$ê°œì˜ noisy latent featureì— ëŒ€í•´ shape $\mathcal R^{(B \cdot K)Ã—CÃ—HÃ—W}$ì„ ê°€ì§„ ë…ë¦½ì ‘ì¸ ìƒ˜í”Œë¡œ ì²˜ë¦¬í•œë‹¤.
    2. ê·¸ ë‹¤ìŒ attention layerì—ì„œ ìœ„ì˜ ê²°ê³¼ë¥¼ frequency ì¶•ì— ê±¸ì³ ìˆëŠ” ì—°ì†ëœ featureë¡œ í•´ì„í•œë‹¤. ì´ë¥¼ ìœ„í•´ attention layerì— ë„£ê¸° ì „ì— 2D spatial layerì˜ latent featureë¥¼ $\mathcal R^{BÃ—KÃ—CÃ—HÃ—W}$ë¡œ reshapeí•œë‹¤.
    (ì¦‰, frequency attention layerëŠ” **ëª¨ë“  frequency sliceë¥¼ ì¡°ì •í•˜ì—¬ ì¼ê´€ëœ spectral volumeì„ ìƒì„±í•˜ë„ë¡ fine-tune**ëœë‹¤.)
<br/><br/><br/><br/><br/><br/>
   
# Image-based rendering

---

ì´ì œ ì…ë ¥ì´ë¯¸ì§€ $I_0$ì—ì„œ ì˜ˆì¸¡ëœ spectral volume $\mathcal S$ë¥¼ ê°€ì§€ê³  ì‹œê°„ $t$ì—ì„œ ë¯¸ë˜ í”„ë ˆì„ $I_t$ë¥¼ ë Œë”ë§í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì‚´í´ë³´ì. í¬ê²ŒëŠ” ì•„ë˜ì™€ ê°™ì´ ë‘ ë‹¨ê³„ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.

1. ê° í”½ì…€ $\mathcal F(\mathbf p) = \text {FFT}^{âˆ’1}(\mathcal S(\mathbf p))$ì— inverse temporal FFTì„ ì ìš©í•˜ì—¬ time domain motion textureë¥¼ ì–»ëŠ”ë‹¤.
2. ë¯¸ë˜ í”„ë ˆì„ $\hat I_t$ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ deep timage-based renderingì„ ì‚¬ìš©í•œë‹¤. ì˜ˆì¸¡ëœ motion field $F_t$ë¥¼ ì‚¬ìš©(splatting)í•˜ì—¬ $I_0$ì— ëŒ€í•´ forward-warpë¥¼ ìˆ˜í–‰í•œë‹¤. ì´ ë•Œ, **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>feature pyramid softmax splatting ë°©ë²•</span></mark>**ì„ ì ìš©í•œë‹¤.
<br/><br/>

> Forward-warpping ê³¼ì •ì—ì„œ ì…ë ¥ $I_0$ì˜ ì—¬ëŸ¬ source í”½ì…€ì´ warpingë  ë•Œ, í•˜ë‚˜ì˜ output target í”½ì…€ ìœ„ì¹˜ì— ë§¤í•‘ë  ìˆ˜ë„ ìˆë‹¤(ì…ì¶œë ¥ì— ëŒ€í•´ 1:1 ë§¤í•‘ì´ ì•„ë‹˜). ë”°ë¼ì„œ output ì´ë¯¸ì§€ì— ë§¤í•‘ë˜ì§€ ì•Šì€ í”½ì…€ì— ëŒ€í•´ í™€(hole)ì´ ìƒê²¨ ì •ë³´ê°€ ì†ì‹¤ë˜ê±°ë‚˜ artifactê°€ ìƒì„±ë˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´ feature pyramid softmax splatting ë°©ë²•ì„ ì‚¬ìš©í–ˆë‹¤. <br/>
> Softmax í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ ì…ë ¥ê°’ ì¤‘ì—ì„œ ê°€ì¥ í° ê°’ì„ ë¶€ê°ì‹œí‚¤ë©´ì„œë„ ë‹¤ë¥¸ ê°’ë“¤ë„ ì¼ì • ì •ë„ ë°˜ì˜ë˜ê²Œ í•˜ëŠ” ì¼ì¢…ì˜ ì •ê·œí™” í•¨ìˆ˜ì´ë‹¤. Softmax Splattingì—ì„œëŠ” ê° source pixelì´ target pixel(ì¤‘ê°„ í”„ë ˆì„ì˜ í”½ì…€)ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ softmax í•¨ìˆ˜ë¥¼ í†µí•´ ê³„ì‚°í•˜ì—¬, ê²¹ì¹˜ëŠ” ê°’ì„ í•©ì¹  ë•Œ ê° í”½ì…€ì˜ ê¸°ì—¬ë„ë¥¼ ê³ ë ¤í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë§¤í•‘ ìœ„ì¹˜ê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•œë‹¤.<br/>
> (ì°¸ê³ : [https://kycu-sb.tistory.com/241](https://kycu-sb.tistory.com/241))<br/>
> ![GID_8.png](https://github.com/user-attachments/assets/541c4d54-c6b1-4d4d-a2d0-87284b4d451b){: width="450px"}

<br/><br/>
ê·¸ëŸ¼ êµ¬ì²´ì ì¸ ë°©ë²•ì„ í•˜ë‚˜ì”© ì‚´í´ë³´ì.<br/>
![GID_9.png](https://github.com/user-attachments/assets/acfc4e25-9ce1-49fe-bbe5-8d8d14df5aeb){: width="600px"}

1. ë¨¼ì €, feature extractorë¥¼ ì‚¬ìš©í•˜ì—¬ I_0ë¥¼ ì¸ì½”ë”©, multi-scale feature mapì„ ìƒì„±í•œë‹¤.
2. ì˜ˆì¸¡í•œ 2D motion field $F_t$ë¥¼ 1ë²ˆì—ì„œ ìƒì„±í•œ feature mapì˜ ê°ê°ì˜ scale $j$ì— ë§ê²Œ resizeí•œë‹¤.
3. ì˜ˆì¸¡ëœ flow magnitudeë¥¼ depthì˜ proxyë¡œ ì‚¬ìš©í•˜ì—¬ ëª©ì ì§€ ìœ„ì¹˜ì— ë§¤í•‘ëœ ê° source í”½ì…€ì˜ ê¸°ì—¬ weightë¥¼ ê²°ì •í•œë‹¤. íŠ¹íˆ, ì˜ˆì¸¡ëœ motion textureì˜ í‰ê·  magnitudeë¡œ per-pixel weight $W(\mathbf p) = \frac{1}{T} \sum_t âˆ£âˆ£F_t(\mathbf p)âˆ£âˆ£_2$ ì„ ê³„ì‚°í•œë‹¤. ì¦‰, í° motionì´ ì›€ì§ì´ëŠ” foreground ê°ì²´ì— í•´ë‹¹í•˜ê³  ì‘ê±°ë‚˜ 0ì¸ motionì´ backgroundì— í•´ë‹¹í•œë‹¤ê³  ê°€ì •í•œë‹¤.<br/>
    <span style='color: var(--txt-gray)'>â†’ ~~ì´ ë•Œ í•™ìŠµ ê°€ëŠ¥í•œ weight ëŒ€ì‹  motion-derived weightì„ ì‚¬ìš©í•œë‹¤. Single-viewì˜ ê²½ìš° í•™ìŠµ ê°€ëŠ¥í•œ weightì€ disocclusion ambiguities, ì¦‰ ë¶„ë¦¬ ëª¨í˜¸ì„±ì„ í•´ê²°í•˜ëŠ”ë° íš¨ê³¼ì ì´ì§€ ì•Šê¸° ë•Œë¬¸ì´ë¼ê³  í•œë‹¤.~~</span>
4. Motion field $F_t$ì™€ weight $W$ê°€ ì£¼ì–´ì§€ë©´, ê° scaleì˜ feature mapì— soft-max splattingì„ ì ìš©í•˜ì—¬ warped featureë¥¼ ì–»ëŠ”ë‹¤.
5. Warped featureë¥¼ image synthesis decoderì˜ ëŒ€ì‘í•˜ëŠ” scaleì— ë„£ì–´ ìµœì¢… ë Œë”ë§ëœ ì´ë¯¸ì§€ $\hat I_t$ë¥¼ ìƒì„±í•œë‹¤.
<br/><br/><br/>

ë…¼ë¬¸ì—ì„œëŠ” ì‹¤ì œ ë¹„ë””ì˜¤ì—ì„œ randomí•˜ê²Œ ìƒ˜í”Œë§ëœ ì‹œì‘ í”„ë ˆì„ê³¼ target í”„ë ˆì„$(I_0, I_t)$ì„ ì‚¬ìš©í•˜ì—¬ feature extractor, synthesis ë„¤íŠ¸ì›Œí¬ë¥¼ ê³µë™ìœ¼ë¡œ í•™ìŠµì‹œí‚¨ë‹¤. $I_0$ì—ì„œ $I_t$ìœ¼ë¡œ ìƒì„±í•œ flow fieldë¥¼ ì‚¬ìš©í•˜ì—¬ $I_0$ì—ì„œ ì¸ì½”ë”©ëœ featureë¥¼ warpí•˜ê³ , VGG perceptual lossë¥¼ ì‚¬ìš©í•˜ì—¬ supervised ë°©ì‹ìœ¼ë¡œ  ì‹¤ì œ í”„ë ˆì„ $I_t$ì™€ ìƒì„±í•œ $\hat I_t$ì— ëŒ€í•´ lossë¥¼ ê³„ì‚°í•œë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Experiments

---

## 1. Quantitative results

![GID_10.png](https://github.com/user-attachments/assets/b6840921-247b-4019-ac11-d4abd4671f70){: width="500px"}

ìœ„ì˜ í‘œëŠ” baselineê³¼ì˜ ì–‘ì  ë¹„êµë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´, ë‚®ì€ FVDì™€ DT-FVD distanceëŠ” ë…¼ë¬¸ì˜ ë°©ë²•ìœ¼ë¡œ ìƒì„±ëœ ë¹„ë””ì˜¤ê°€ ë” í˜„ì‹¤ì ì´ê³  ì‹œê°„ì ìœ¼ë¡œ ë” ì¼ê´€ì„±ì´ ìˆìŒì„ ë‚˜íƒ€ë‚¸ë‹¤. 
<br/><br/><br/>

![GID_11.png](https://github.com/user-attachments/assets/d22aa300-0589-4fae-a925-0ab616a6e0ec){: width="600px"}

ìœ„ì˜ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ sliding window FIDì™€ sliding window DT-FVD distanceë¥¼ ë³´ì—¬ì¤€ë‹¤. global spectral volume representation ë•ë¶„ì— ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ ë°©ë²•ìœ¼ë¡œ ìƒì„±ëœ ë¹„ë””ì˜¤ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ degradation ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/>

## 2. Qualitative results

![GID_12.png](https://github.com/user-attachments/assets/04f37010-828e-4341-8ba1-939515b03f6b){: width="1100px"}

ë¹„ë””ì˜¤ì˜ ì§ˆì  ë¹„êµë¥¼ ìœ„í•´ ìƒì„±ëœ ë¹„ë””ì˜¤ë¥¼ spatio-temporal X-t sliceë¡œ ì‹œê°í™”í–ˆë‹¤. ì´ëŠ” ë¹„ë””ì˜¤ì—ì„œ ì‘ì€ motionì„ ì‹œê°í™”í•˜ëŠ” í‘œì¤€ì ì¸ ë°©ë²•ì´ë‹¤. ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ìƒì„±ëœ ë¹„ë””ì˜¤ ì—­í•™ì€ ë‹¤ë¥¸ ë°©ë²•ì— ë¹„í•´ ì‹¤ì œ reference ë¹„ë””ì˜¤(ë‘ ë²ˆì§¸ ì—´)ì—ì„œ ê´€ì°°ëœ motion íŒ¨í„´ê³¼ ë” ìœ ì‚¬í•˜ë‹¤.
<br/><br/><br/><br/>

## 3. Ablation study

![GID_13.png](https://github.com/user-attachments/assets/218b8870-9ce8-43f3-ab9a-17ef338b9114){: width="600px"}

ë…¼ë¬¸ì˜ motion prediction, rendering moduleì— ëŒ€í•œ ê²€ì¦ì„ ìœ„í•´ ablation studyë¥¼ ìˆ˜í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ë³€í˜•ì— ëŒ€í•´ ë¹„êµí–ˆë‹¤. 

1. ë‹¤ì–‘í•œ frequency band K = 4, 8, 16, 24ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµë¥¼ ìˆ˜í–‰í–ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, frequency bandì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ë¹„ë””ì˜¤ ì˜ˆì¸¡ í’ˆì§ˆì´ í–¥ìƒë˜ì§€ë§Œ 16ê°œ ì´ìƒì˜ frequencyì—ì„œëŠ” ê°œì„ ì´ ë¯¸ë¯¸í•˜ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. 
2. Ground truth spectral volumeì—ì„œ adaptive frequency normalizationì„ ì œê±°í•˜ê³  ëŒ€ì‹  ì…ë ¥ ì´ë¯¸ì§€ì˜ width, heightì— ë”°ë¼ scaleì„ ì§„í–‰í–ˆë‹¤. 
3. Frequency coordinated-denoising moduledì„ ì œê±°í•˜ê±°ë‚˜ ê°„ë‹¨í•œ ë²„ì „ìœ¼ë¡œ ëŒ€ì²´í•œ ê²°ê³¼ì— ëŒ€í•´ ì¡°ì‚¬í–ˆë‹¤.
4. í•™ìŠµ ê°€ëŠ¥í•œ weightì— ë”°ë¼ single-scale featureì— softmax splattingì„ ì ìš©í•˜ëŠ” baseline rendering ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí–ˆë‹¤.
<br/><br/><br/><br/>

## 4. Comparing to large video models

![GID_14.png](https://github.com/user-attachments/assets/f996cb3e-c44c-41fc-b1ed-81201c3097f9){: width="600px"}

ë§ˆì§€ë§‰ìœ¼ë¡œ, user studyë¥¼ ìˆ˜í–‰í•˜ê³ , ë¹„ë””ì˜¤ volumeì„ ì§ì ‘ ì˜ˆì¸¡í•˜ëŠ” ìµœê·¼ì˜  large video diffusion ëª¨ë¸ì¸ AnimateDiff, ModelScope ë° Gen-2ì˜ ì• ë‹ˆë©”ì´ì…˜ ê²°ê³¼ì™€ ë¹„êµí–ˆë‹¤. Testsetì—ì„œ randomí•˜ê²Œ ì„ íƒí•œ 30ê°œ ë¹„ë””ì˜¤ì—ì„œ userì—ê²Œ "ì–´ë–¤ ë¹„ë””ì˜¤ê°€ ë” ì‚¬ì‹¤ì ì…ë‹ˆê¹Œ?"ë¼ê³  ë¬¼ì—ˆì„ ë•Œ, ë‹¤ë¥¸ ë°©ë²•ë³´ë‹¤ ë…¼ë¬¸ì˜ ë°©ë²•ìœ¼ë¡œ ìƒì„±í•œ ê²°ê³¼ë¥¼ 80.9%ë¡œ ì„ í˜¸í–ˆë‹¤. 

ë˜í•œ ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ baselineì—ì„œ ìƒì„±ëœ ë¹„ë””ì˜¤ëŠ” ì…ë ¥ ì´ë¯¸ì§€ ì½˜í…ì¸ ë¥¼ ìœ ì§€í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì ì§„ì ì¸ color drift ë° ì™œê³¡ì„ ë³´ì¸ë‹¤.
<br/><br/><br/><br/>
