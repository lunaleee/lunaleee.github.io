---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Prompt-to-Prompt Image Editing with Cross Attention Control"
author: lunalee
date: 2024-06-21 21:19:35 +0900
categories: [AI, Paper Review]
tags: [Diffusion, Generation]
pin: false
math: true
---

<br/><br/>
`Google Research` `arXiv 2022`

- Paper: [https://arxiv.org/abs/2208.01626](https://arxiv.org/abs/2208.01626)
- Git: [https://github.com/google/prompt-to-prompt/](https://github.com/google/prompt-to-prompt/)
- Page: [https://prompt-to-prompt.github.io](https://prompt-to-prompt.github.io/)
<br/><br/><br/>

#### ğŸ“– í•µì‹¬ í›‘ì–´ë³´ê¸° !!

- Prompt ì¡°ì‘ë§Œìœ¼ë¡œ **ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ ì›ë˜ êµ¬ì¡°ë¥¼ ìœ ì§€**í•˜ë©´ì„œ í¸ì§‘í•  ìˆ˜ ìˆëŠ” textual editing ë°©ë²• ì œì•ˆ
- ìƒì„±ëœ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ì™€ ëª¨ì–‘ì€ **Diffusion process ê³¼ì •ì—ì„œ pixelê³¼ text embedding ê°„ì˜ interactionì— ì˜ì¡´**í•œë‹¤ëŠ” ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬, **Cross-attention layerì—ì„œ ë°œìƒí•˜ëŠ” pixel-to-text interactionì„ ìˆ˜ì •**í•˜ëŠ” ë°©ë²• ì œì•ˆ
- ìˆ˜ì •ëœ promptì—ì„œ ìƒì„±ëœ cross attention mapì— ì›ë˜ promptì—ì„œ ìƒì„±ëœ attention mapì„ **ë‹¨ê³„ë³„ë¡œ injection** í•˜ì—¬ ì›ë³¸ì˜ êµ¬ì¡°ëŠ” ìœ ì§€í•˜ë©´ì„œë„ ìˆ˜ì •ëœ promptë¥¼ ë°˜ì˜í•˜ëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±
<br/><br/><br/><br/>

# Introduction

---

LLI(large-scale language-image)ëŠ” ë›°ì–´ë‚œ image generation ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. í•˜ì§€ë§Œ **image editing** ì¸¡ë©´ì—ì„œ, ê°„ë‹¨í•˜ê²Œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ìˆ˜ë‹¨ì´ ì—†ì„ ë¿ ì•„ë‹ˆë¼ íŠ¹ì • semantic regionì— ëŒ€í•œ ì»¨íŠ¸ë¡¤ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤. Text promptë¥¼ ì•½ê°„ë§Œ ë³€ê²½í•˜ë”ë¼ë„ ì™„ì „íˆ ë‹¤ë¥¸ ì¶œë ¥ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ê¸° ì‰½ë‹¤.

ê¸°ì¡´ì—ëŠ” ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ì—ì„œ ì¼ë¶€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ **masking**í•˜ê³  í•´ë‹¹ ë¶€ë¶„ë§Œ ë³€ê²½ë˜ë„ë¡ í•˜ëŠ” ë°©ë²•ì´ ì œì•ˆë˜ì—ˆë‹¤. í•˜ì§€ë§Œ masking ì ˆì°¨ê°€ ë²ˆê±°ë¡­ê³  ì¤‘ìš”í•œ êµ¬ì¡°ì  ì •ë³´ê°€ ì œê±°ë˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.
<br/><br/>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Prompt-to-Prompt ì¡°ì‘</span></mark>**ì„ í†µí•´ pre-trained text conditioned diffusion ëª¨ë¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•˜ëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>textual editing</span></mark>** ë°©ë²•ì„ ì†Œê°œí•œë‹¤. ì´ë¥¼ ìœ„í•´ cross-attention mapì„ ì¡°ì‘í•˜ì—¬ diffusion processì— ì£¼ì…í•¨ìœ¼ë¡œì„œ ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•œë‹¤. íŠ¹íˆ, diffusion process ì¤‘ì— ì–´ë–¤ pixelì´ prompt textì˜ ì–´ë–¤ tokenì— attentioní•˜ëŠ”ì§€ ì œì–´í•  ìˆ˜ ìˆë‹¤.
<br/><br/>

![P2P_1.png](https://github.com/user-attachments/assets/b0920e57-9d09-4202-8cff-45b5534fe36f){: width="1000px"}

ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ë…¼ë¬¸ì—ì„œ cross-attentionì„ ì œì–´í•˜ëŠ” ì—¬ëŸ¬ ë°©ì‹ì´ ìˆë‹¤.

1. promptì—ì„œ í•˜ë‚˜ì˜ tokenì„ ë³€ê²½ (e.g. ê°œ â†’ ê³ ì–‘ì´)
2. ì´ì „ì˜ tokenì€ freezeí•˜ê³  ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ì „ë°˜ì ì¸ ì´ë¯¸ì§€ ìˆ˜ì • (e.g. style ë³€ê²½)
3. ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ ë‹¨ì–´ì˜ ì˜ë¯¸ì  íš¨ê³¼ë¥¼ ì¦í­í•˜ê±°ë‚˜ ì•½í™”ì‹œí‚´
<br/><br/>

ë…¼ë¬¸ì˜ ë°©ë²•ì€ textual promptë§Œì„ í¸ì§‘í•˜ë¯€ë¡œ, ë¹ ë¥´ê³  ì§ê´€ì ì¸ í¸ì§‘ì´ ê°€ëŠ¥í•¨ê³¼ ë™ì‹œì— ì¶”ê°€ì ì¸ í•™ìŠµ, ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ ì•Šì€ ì¥ì ì´ ìˆë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Method

---

ë¨¼ì € notationê³¼ ëª©í‘œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•˜ì.

- $\mathcal{I}$ : text prompt $\mathcal P$ì™€ random seed $s$ë¥¼ ì‚¬ìš©í•˜ì—¬ text-guided diffusion ëª¨ë¸ì„ í†µí•´ ìƒì„±ëœ ì´ë¯¸ì§€
- Goal:  í¸ì§‘ëœ text prompt $\mathcal P^\ast$ë¥¼ ì´ìš©í•˜ì—¬ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>í¸ì§‘ëœ ì´ë¯¸ì§€ $\mathcal I^\ast$ë¥¼ ìƒì„±</span></mark>**í•˜ëŠ” ê²ƒ
<br/><br/>

ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ **ì›ë˜ì˜ ì´ë¯¸ì§€ì˜ ëª¨ì–‘ê³¼ êµ¬ì¡°ë¥¼ ìœ ì§€**í•˜ë©´ì„œ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¶„ì„ ìˆ˜ì •í•˜ë ¤ê³  í•  ë•Œ, (e.g. â€œmy new bicycleâ€ ì´ë¼ëŠ” promptì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ ìì „ê±°ë¥¼ ìŠ¤ì¿ í„°ë¡œ ë³€ê²½í•œë‹¤ë˜ì§€, ìì „ê±°ì˜ ìƒ‰ìƒì„ ë³€ê²½) ìƒê°í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ë‹¨ìˆœí•œ ë°©ë²•ìœ¼ë¡œ diffusion processì˜ **random seedë¥¼ ê³ ì •**í•˜ê³  **ì…ë ¥ promptë¥¼ ìˆ˜ì •**í•˜ëŠ” ë°©ë²•ì´ë‹¤. 
<br/><br/>

![P2P_2.png](https://github.com/user-attachments/assets/60d4544d-b062-4ba3-a357-f11015e91ae8){: width="1200px"}

ì´ì™€ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ìœ„ì™€ ê°™ì´ êµ¬ì¡°ì™€ êµ¬ì„±ì´ ì™„ì „íˆ ë‹¤ë¥¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆë‹¤. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ë¬¸ì œëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ì™€ ëª¨ì–‘ì€ random seed ë¿ ì•„ë‹ˆë¼ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>diffusion processë¥¼ í†µí•œ pixelê³¼ text embedding ê°„ì˜ interactionì— ì˜ì¡´</span></mark>**í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Cross-attention layerì—ì„œ ë°œìƒí•˜ëŠ” pixel-to-text interactionì„ ìˆ˜ì •</span></mark>**í•˜ì—¬ **Prompt-to-Prompt image editing**ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ë³¸ ë…¼ë¬¸ì˜ ì ‘ê·¼ ë°©ë²•ì´ë‹¤.
<br/><br/><br/><br/><br/>

## 1. Cross-attention in text-conditioned Diffusion Models

ë¨¼ì €, ë…¼ë¬¸ì—ì„œëŠ” backbone ëª¨ë¸ë¡œ Imagenì„ ì‚¬ìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ë…¼ë¬¸ì˜ ë°©ë²•ì€ ì¼ë°˜ì ì¸ diffusion ëª¨ë¸ì´ ì ìš© ê°€ëŠ¥í•˜ë‹¤ê³  í•œë‹¤.
<br/><br/>

> **Imagen** ([Photorealistic Text-to-Image Diffusion Models with Deep Language UnderstandingğŸ“„](https://arxiv.org/abs/2205.11487) )
> 
> ![P2P_3.png](https://github.com/user-attachments/assets/1a371d99-55c7-49e4-bac4-ac7a227d74a8){: width="600px"} <br/>
>
> Imagenì€ í¬ê²Œ ì„¸ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœ Diffusion ëª¨ë¸ì´ë‹¤. <br/>
> **1. Pre-trained Text Encoder**: text embedding ìƒì„± <br/>
> **2. Diffusion model** (Classifier-free guidance): text embeddingì„ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± <br/>
> **3. Cascaded Diffusion model** (Super resolution): high-resolution imageë¡œ upscale <br/>
> 

<span style='color: var(--txt-gray)'>(ìœ„ ëª¨ë¸ êµ¬ì¡°ì—ì„œ ì´ë¯¸ì§€ì˜ êµ¬ì„±, geometry ë“±ì€ 64 X 64 text-to-image diffusion ëª¨ë¸(2ë²ˆì§¸ ëª¨ë¸)ì—ì„œ ê²°ì •ë˜ë¯€ë¡œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Diffusion ëª¨ë¸ì—ë§Œ ë°©ë²•ì„ ì ìš©í•˜ê³  SR ëª¨ë¸ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤.)</span>
<br/><br/><br/>

ì¼ë°˜ì ìœ¼ë¡œ ê° diffusion step $t$ì—ì„œ U-net ê¸°ë°˜ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ noisyí•œ ì´ë¯¸ì§€ $z_t$, text embedding $\psi (\mathcal P)$ë¡œë¶€í„° noise $\epsilon$ì„ ì˜ˆì¸¡í•œë‹¤. ëª¨ë“  stepì´ ì§„í–‰ë˜ë©´ ë§ˆì§€ë§‰ì—ì„œ ì´ë¯¸ì§€ $\mathcal I = z_0$ê°€ ìƒì„±ëœë‹¤. ì¤‘ìš”í•œ ì ì€ ë‘ modality ì‚¬ì´ì˜ interactionì´ noise prediction ê³¼ì • ì¤‘ ë°œìƒí•œë‹¤. ì´ ë•Œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Cross-attention layer</span></mark>**ì—ì„œ visual, textual feature fusionì´ ë°œìƒí•˜ê³  **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>ê° textual tokenì— ëŒ€í•œ spatial attention mapì´ ìƒì„±</span></mark>**ëœë‹¤.
<br/><br/><br/><br/><br/>

![P2P_4.png](https://github.com/user-attachments/assets/4045d34f-465f-4c5c-8d9e-6838f60fd303){: width="1100px"}

í•™ìŠµëœ linear projection $\ell_Q,\ell_K, \ell_V$ ë¥¼ ì‚¬ìš©í•˜ì—¬, ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ noisy ì´ë¯¸ì§€ì˜ spatial feature $\phi (z_t)$ëŠ” query matrix $Q = \ell_Q(\phi(z_t))$ë¡œ project ë˜ê³ , textual embeddingì€ key matrix $K = \ell_K(\psi(\mathcal P))$ì™€ value matrix $V = \ell_V (\psi(\mathcal P))$ë¡œ project ëœë‹¤. ì´ ë•Œì˜ attention mapì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
M = \text{Softmax} \bigg(\frac{QK^T}{\sqrt{d}}\bigg)
$$

ì—¬ê¸°ì„œ cell $M_{ij}$ëŠ” pixel $i$ì™€ $j$ë²ˆì§¸ tokenì— ëŒ€í•œ ê°€ì¤‘ì¹˜ì´ê³ , $d$ëŠ” $Q$ì™€ $K$ì˜ latent projection dimensionì´ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ cross-attentionì˜ ì¶œë ¥ì€ $\hat \phi (z_t) = MV$ ê°€ ë˜ê³ , spatial feature $\phi (z_t)$ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.
<br/><br/><br/>

ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì§ê´€ì ìœ¼ë¡œ cross-attention output $MV$ëŠ” attention map $M$ì„ ê°€ì¤‘ì¹˜ë¡œ í•˜ëŠ” $V$ì˜ **weighted average**ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤(Mì€ Qì™€ Kì˜ similarityì™€ ìƒê´€ê´€ê³„ì„). ì¶”ê°€ì ìœ¼ë¡œ í‘œí˜„ë ¥ì„ ë†’ì´ê¸° ìœ„í•´ multi-head attentionì„ ì‚¬ìš©í–ˆë‹¤.
<br/><br/><br/><br/><br/>

## 2. Controlling the Cross-attention

ì•ì—ì„œ ì¼ë°˜ì ì¸ cross-attention layerë¥¼ ì‚´í´ë´¤ë‹¤ë©´, ì´ì œ **ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ê³µê°„ì  layoutê³¼ geometryê°€ cross-attention mapì— ë‹¬ë ¤ìˆë‹¤**ëŠ” key pointë¡œ ë„˜ì–´ì˜¤ì. 
<br/><br/>

ì•„ë˜ ê·¸ë¦¼ì€ visualizationì„ ìœ„í•´ **average attention map**ì„ êµ¬í•œ ê²ƒì´ë‹¤. ê·¸ë¦¼ì„ í†µí•´ pixelê³¼ textê°„ì˜ interactionì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Attention mapì€ ê°ê° instanceì— ëŒ€í•´ ë¶„ë¦¬ëœ í˜•íƒœë¡œ ìœ ì§€ëœë‹¤(ê³° â†” ìƒˆ). <br/>
ì´ë¯¸ì§€ì˜ êµ¬ì¡°ê°€ diffusion processì˜ ì´ˆê¸° stepì— ì´ë¯¸ ê²°ì •ë˜ëŠ” ê²ƒ ë˜í•œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![P2P_5.png](https://github.com/user-attachments/assets/538c774d-d9cf-441a-9a17-60b81233fb50){: width="1200px"}
<br/><br/><br/>

Attentionì€ ì „ì²´ compositionì„ ë°˜ì˜í•˜ë¯€ë¡œ, original prompt $\mathcal P$ë¡œ ìƒì„±í•œ attention map $M$ì„ modified prompt $\mathcal P^\ast$ë¡œ ìƒì„±í•˜ëŠ” ê³¼ì •ì— ì£¼ì…í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í†µí•´ input image $\mathcal I$ì˜ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ë©´ì„œë„ ìˆ˜ì •ëœ promptë¥¼ ë°˜ì˜í•˜ëŠ” edited image $\mathcal I^\ast$ë¥¼ í•©ì„±í•  ìˆ˜ ìˆë‹¤. 
<br/><br/><br/>

ë¨¼ì € controlled image generationì„ ìœ„í•œ general frameworkë¥¼ ì‚´í´ë³´ì. 

- $DM(z_t, \mathcal P, t, s)$ : single step tì˜ diffusoin process ì—°ì‚°. noisy image z_{tâˆ’1}ì™€ attention map M_të¥¼ outputìœ¼ë¡œ ìƒì„±í•¨.
- $DM(z_t, \mathcal P, t, s)\lbrace M \gets \widehat M \rbrace$ : ë³´ì¶©ëœ promptì˜ value $V$ë¥¼ ìœ ì§€í•˜ë©´ì„œ, attention map $M$ì„ ìƒˆë¡œìš´ map $\widehat M$ ìœ¼ë¡œ overrideí•˜ëŠ” diffusion step.
- $M^\ast_t$ :í¸ì§‘ëœ prompt $\mathcal P^*$ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ attention map.
- $Edit(M_t, M_t^âˆ—, t)$ : $t$ë²ˆì§¸ attention mapì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” general edit function.
<br/><br/><br/>

ë‘ promptì— ëŒ€í•´ ë™ì‹œì— iterative diffusion processë¥¼ ì§„í–‰í•œë‹¤. ì´ ë•Œ ê°™ì€ promptë¼ë„ random seedê°€ ë‹¤ë¥¸ ê²½ìš° ì™„ì „íˆ ë‹¤ë¥¸ ì¶œë ¥ì´ ìƒì„±ë˜ëŠ” diffusion ëª¨ë¸ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬, randomnessë¥¼ ê³ ì •í–ˆë‹¤. General algorithmì€ ì•„ë˜ì™€ ê°™ì´ ì§„í–‰ëœë‹¤.

![P2P_6.png](https://github.com/user-attachments/assets/42e997b1-fe52-48dc-a8a4-596b0efe3921){: width="1200px"}

- (line 3,4): random seed së¡œ Gaussian random variable $z_T (= z^*_T)$ìƒì„±
- (line 6,7): ì›ë³¸ promptì™€ í¸ì§‘ëœ promptë¥¼ ì‚¬ìš©í•˜ì—¬ random variableë¡œë¶€í„° ê°ê° diffusion process ì§„í–‰, attention map $M_t, M^*_t$ ìƒì„±
- (line 8): ì›ë³¸ promptë¡œ ìƒì„±ëœ attention map $M_t$ì™€ ìˆ˜ì •ëœ promptë¡œ ìƒì„±ëœ $M^*_t$ë¥¼ ì‚¬ìš©í•˜ì—¬ $Edit(\cdot)$ê³¼ì •ì„ ê±°ì³ ìˆ˜ì •ëœ attention map $\widehat M_t$ ìƒì„±
- (line 9): ìˆ˜ì •ëœ attention map $\widehat M_t$ë¥¼ ì´ìš©í•˜ì—¬ $z^*_{t-1}$ ìƒì„±
<br/><br/>

ë‹¤ìŒìœ¼ë¡œëŠ” ë¹„ì–´ìˆëŠ” $Edit(M_t,M_t^âˆ—,t)$ ë¶€ë¶„ì„ ì •ì˜í•˜ê¸° ìœ„í•œ 3ê°€ì§€ specific editing operationì— ëŒ€í•´ ì•Œì•„ë³´ì. 
<br/><br/><br/><br/><br/>

#### 1. Word Swap.

Word swapì€ ë§ ê·¸ëŒ€ë¡œ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ì›ë˜ promptì˜ tokenì„ ë‹¤ë¥¸ tokenê³¼ ë°”ê¾¸ëŠ” ê²ƒ</span></mark>**ì„ ë§í•œë‹¤(e.g. $\mathcal P$ = "a big red **bicycle**"ì—ì„œ $\mathcal P^âˆ—$ = "a big red **car**").

ì›ë˜ì˜ êµ¬ì„±ì„ ë³´ì¡´í•˜ëŠ” ë™ì‹œì— ìƒˆ promptì˜ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´, ìˆ˜ì •ëœ promptë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ **ì›ë˜ ì´ë¯¸ì§€ì˜ attention mapì„ ì£¼ì…**í•œë‹¤. ê·¸ëŸ¬ë‚˜ â€œbicycleâ€ì—ì„œ â€œcarâ€ë¡œì˜ ë³€ê²½ê³¼ ê°™ì´ í° êµ¬ì¡°ì  ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš° geometryë¥¼ ê³¼ë„í•˜ê²Œ ì œì•½í•˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>softer attention constrain</span></mark>**ì„ ì‚¬ìš©í–ˆë‹¤. 

$$
Edit(M_t, M^*_t, t):= \begin{cases} 
M^*_t \qquad  \text{if} \; t < \tau \\ M_t \qquad \text{otherwise.}
\end{cases}
$$

ì—¬ê¸°ì„œ $\tau$ëŠ” injectionì´ ì ìš©ë˜ëŠ” stepì„ ê²°ì •í•˜ëŠ” timestamp parameterì´ë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ êµ¬ì„±ì€ diffusion process ì´ˆê¸°ì— ê²°ì •ë˜ë¯€ë¡œ, injection stepì˜ ìˆ˜ë¥¼ ì œí•œí•¨ìœ¼ë¡œì¨ ìƒˆë¡œìš´ promptì— ì ì‘í•˜ëŠ”ë° í•„ìš”í•œ **geometry freedom**ì„ í—ˆìš©í•  ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/><br/>

#### 2. Adding a New Phrase.

![P2P_7.png](https://github.com/user-attachments/assets/88cf50ea-50d8-497b-a94d-edbf8ede365b){: width="900px"}

ë‹¤ìŒìœ¼ë¡œëŠ” promptì— **ìƒˆ tokenì„ ì¶”ê°€**í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì($\mathcal P$ = "a castle next to a river"ì—ì„œ $\mathcal P^âˆ—$ = "**children drawing of** a castle next to a river") 

ê³µí†µì ì¸ detailì„ ë³´ì¡´í•˜ê¸° ìœ„í•´ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ë‘ promptì˜ ê³µí†µëœ tokenì—ë§Œ attention injectionì„ ì ìš©</span></mark>**í•œë‹¤. ë¨¼ì € **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>alignment function $A$</span></mark>**ë¥¼ ì‚¬ìš©í•œë‹¤. ì´ functionì€ target prompt $\mathcal P^*$ì˜ token indexë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ **ì›ë˜ prompt $\mathcal P$ì—ì„œ ëŒ€ì‘í•˜ëŠ” token index**(ë˜ëŠ” $None$)ë¥¼ ì¶œë ¥í•œë‹¤. 

$$
Edit(M_t, M^*_t, t):= \begin{cases} 
(M^*_t)_{i,j} \quad \qquad  \text{if} \; A(j) = None \\ (M_t)_{i, A(j)} \qquad \text{otherwise.}
\end{cases}
$$

ì´ ë•Œ $None$ì´ë©´(ì¦‰, ëŒ€ì‘í•˜ëŠ” ë¶€ë¶„ì´ ì—†ìœ¼ë©´) $M^*_t$ë¥¼ ì¶œë ¥í•˜ê³  ì•„ë‹ˆë©´(ëŒ€ì‘í•˜ëŠ” ë¶€ë¶„ì´ ìˆìœ¼ë©´) $M_t$ë¥¼ ì¶œë ¥í•œë‹¤. ì‹ì—ì„œ index $i$ëŠ” pixel value, $j$ëŠ” ì´ì— ëŒ€ì‘í•˜ëŠ” text tokenì„ ë‚˜íƒ€ë‚¸ë‹¤.
<br/><br/><br/><br/><br/>

#### 3. Attention Reâ€“weighting.

ë§ˆì§€ë§‰ìœ¼ë¡œ **ê° tokenì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê°•í™”í•˜ê±°ë‚˜ ì•½í™”**ì‹œí‚¤ê³ ì í•˜ëŠ” ê²½ìš°ë¥¼ ì‚´í´ë³´ì(e.g. $\mathcal P$ = â€œa **fluffy** red ballâ€ì„ ë”, í˜¹ì€ ëœ fluffyí•˜ê²Œ).

ì´ ê²½ìš°ì—ëŠ” parameter $c \in [âˆ’2, 2]$ ë¥¼ ì‚¬ìš©í•˜ì—¬ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>íŠ¹ì • token $j^*$ì˜ attention mapì„ scaleí•˜ì—¬ ì¡°ì ˆ</span></mark>**í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤. ë‚˜ë¨¸ì§€ attention mapì€ ë³€ê²½ë˜ì§€ ì•ŠëŠ”ë‹¤.

$$
(Edit(M_t, M^*_t, t))_{i,j}:= \begin{cases} 
c \cdot (M_t)_{i,j} \qquad  \text{if} \; j = j^* \\ (M_t)_{i,j} \qquad \quad \text{otherwise.}
\end{cases}
$$

<br/><br/><br/><br/><br/>

# Experiments

---

### 1. Text-Only Localized Editing.

![P2P_8.png](https://github.com/user-attachments/assets/72b31655-9229-4da6-9c88-3e17021acfcd){: width="800px"}

ë¨¼ì € local í¸ì§‘ì— ëŒ€í•œ ê²°ê³¼ì´ë‹¤. ê·¸ë¦¼ì˜ ìœ—ë¶€ë¶„ê³¼ ê°™ì´ ë°°ê²½ì´ ì˜ ë³´ì¡´ë¨ê³¼ ë™ì‹œì— ìˆ˜ì •ëœ promptë¥¼ ì˜ ë°˜ì˜í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë°˜ë©´ì— ë…¼ë¬¸ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¨ìˆœí•˜ê²Œ random seedë§Œì„ ê³ ì •í•œ ì•„ë˜ ë¶€ë¶„ì˜ ê²°ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ geometryì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. 
<br/><br/><br/>

![P2P_9.png](https://github.com/user-attachments/assets/4372bc22-cf75-4b27-9fe7-24234f7c18c6){: width="800px"}

ë˜í•œ texture í¸ì§‘ ë¿ ì•„ë‹ˆë¼ êµ¬ì¡°ì ì¸ ìˆ˜ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ cross attention injectionì„ ì ìš©í•˜ëŠ” diffusion stepì„ ë³€ê²½í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ë¥¼ ì œì–´í•  ìˆ˜ ìˆë‹¤. Injectionì„ ìˆ˜í–‰í•˜ëŠ” stepdl ë§ì„ìˆ˜ë¡ ì›ë˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ê°€ ë†’ì•„ì§„ë‹¤.
<br/><br/><br/><br/>

### 2. Global editing.

![P2P_10.png](https://github.com/user-attachments/assets/7a103923-4db1-4529-a1d8-adf5e9d0e6a2){: width="800px"}

ê¸°ì¡´ì˜ promptì— ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ë°°ê²½ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ê°€ ì„¸ë¶€ ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

ë¿ë§Œ ì•„ë‹ˆë¼ ì•„ë˜ë¶€ë¶„ ì´ë¯¸ì§€ì²˜ëŸ¼ Globalí•œ ë¶€ë¶„ì„ ë³€ê²½í•˜ë©´ì„œë„ ì›ë˜ì˜ ì´ë¯¸ì§€ contentë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.
ë˜í•œ texture í¸ì§‘ ë¿ ì•„ë‹ˆë¼ êµ¬ì¡°ì ì¸ ìˆ˜ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ cross attention injectionì„ ì ìš©í•˜ëŠ” diffusion stepì„ ë³€ê²½í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ë¥¼ ì œì–´í•  ìˆ˜ ìˆë‹¤. Injectionì„ ìˆ˜í–‰í•˜ëŠ” stepdl ë§ì„ìˆ˜ë¡ ì›ë˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ê°€ ë†’ì•„ì§„ë‹¤.
<br/><br/><br/><br/>

### 3. Fader Control using Attention Re-weighting.

![P2P_11.png](https://github.com/user-attachments/assets/460e8fb2-41e6-461e-bf4d-6110d551b24e){: width="800px"}

Promptë¥¼ í¸ì§‘í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì œì–´í•  ìˆ˜ ìˆì§€ë§Œ ë‹¨ì–´ì˜ ì •ë„ë¥¼ ì œì–´í•˜ê¸°ëŠ” ì–´ë µë‹¤. ì˜ˆë¥¼ ë“¤ì–´ â€œsnowy mountainâ€ì—ì„œ ëˆˆ ë®ì¸ ì •ë„ë¥¼ ì œì–´í•˜ê³  ì‹¶ì„ ìˆ˜ë„ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ ì €ìëŠ” íŠ¹ì • ë‹¨ì–´ë¡œ ìœ ë„ë˜ëŠ” íš¨ê³¼ì˜ í¬ê¸°ë¥¼ ì œì–´í•˜ëŠ” fader controlì„ ì œì•ˆí–ˆë‹¤. ì§€ì •ëœ ë‹¨ì–´ì˜ attentionì„ re-scalingí•˜ì—¬ ì´ëŸ¬í•œ ì œì–´ë¥¼ ìˆ˜í–‰í–ˆë‹¤.
ë˜í•œ texture í¸ì§‘ ë¿ ì•„ë‹ˆë¼ êµ¬ì¡°ì ì¸ ìˆ˜ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ cross attention injectionì„ ì ìš©í•˜ëŠ” diffusion stepì„ ë³€ê²½í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ë¥¼ ì œì–´í•  ìˆ˜ ìˆë‹¤. Injectionì„ ìˆ˜í–‰í•˜ëŠ” stepdl ë§ì„ìˆ˜ë¡ ì›ë˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶©ì‹¤ë„ê°€ ë†’ì•„ì§„ë‹¤.
<br/><br/><br/><br/>

### 4. Real Image Editing.

![P2P_12.png](https://github.com/user-attachments/assets/eb90091a-3b98-4542-9936-d306c6827c24){: width="1000px"}

ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•˜ê¸° ìœ„í•´ì„œëŠ” diffusion processì— ì…ë ¥ë˜ë©´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì´ˆê¸° noise vectorë¥¼ ì°¾ì•„ì•¼í•œë‹¤. ì´ë¥¼ ìœ„í•´ inversionì´ë¼ê³  ì•Œë ¤ì§„ processë¥¼ ì ìš©í–ˆë‹¤. í•´ë‹¹ processëŠ” í˜„ì¬ text-guided diffusion ëª¨ë¸ì—ì„œì˜ ì—°êµ¬ëŠ” ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì— ì¶©ë¶„íˆ ì •í™•í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/>
