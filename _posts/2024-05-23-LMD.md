---
title: "[ë…¼ë¬¸ ë¦¬ë·°] LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models (LMD)"
author: lunalee
date: 2024-05-23 20:33:21 +0900
categories: [AI, Paper Review]
tags: [LLM, Diffusion, Generation]
pin: false
math: true
---

<br/><br/>
`TMLR 2024`

- Paper: [https://arxiv.org/abs/2305.13655](https://arxiv.org/abs/2305.13655)
- Git: [https://github.com/TonyLianLong/LLM-groundedDiffusion](https://github.com/TonyLianLong/LLM-groundedDiffusion)
- Page: [https://llm-grounded-diffusion.github.io](https://llm-grounded-diffusion.github.io/)
<br/><br/><br/>

#### ğŸ“– í•µì‹¬ í›‘ì–´ë³´ê¸° !!

- Text-to-Image generationì—ì„œ ë³µì¡í•œ text prompt(e.g. ê°œì²´ ìˆ˜, ê³µê°„ì  ì†ì„±) ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ìƒì„±í•´ë‚´ê¸° ìœ„í•´ 2-stage generation ë°©ë²•ì„ ë„ì…í•˜ì˜€ë‹¤.
    1. **Text-grounded layout generation**: in-context learningì„ í™œìš©í•˜ì—¬ promptì— ë§ëŠ” ì´ë¯¸ì§€ layoutì„ ë¨¼ì € ìƒì„±
    2. **Layout-grounded image generation**: 1 ë‹¨ê³„ì—ì„œ ìƒì„±í•œ layoutì„ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
- Layout-grounded image generation ë‹¨ê³„ì—ì„œ ê¸°ì¡´ì˜ diffusion ëª¨ë¸ì„ í™œìš©í•˜ëŠ” **training-free ë°©ë²•** ì œì•ˆ. Denoising processì—ì„œ cross-attention mapì„ í™œìš©í•˜ì—¬ layoutì— ë§ëŠ” ìœ„ì¹˜ì— objectë¥¼ ìƒì„±í•˜ë„ë¡ ê°€ì´ë“œë¥¼ ì£¼ëŠ” ë°©ì‹ì„ ì‚¬ìš©.
<br/><br/><br/><br/>

# Introduction

---

Text-to-Image generationì€ Diffusion ëª¨ë¸ì˜ ë“±ì¥ ì´í›„ í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë‚´ë©° ë§ì€ ë°œì „ì„ ì´ë£¨ì—ˆë‹¤. í•˜ì§€ë§Œ diffusion ëª¨ë¸ì€ ë³µì¡í•œ text promptì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ìƒì„±í•´ë‚´ëŠ”ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´, ì•„ë˜ ê·¸ë¦¼ì„ ì‚´í´ë³´ì. ë°”ë‚˜ë‚˜ ì—†ëŠ” í…Œì´ë¸”ì„ ìƒì„±í•˜ë¼ê³  í–ˆì§€ë§Œ í…Œì´ë¸” ìœ„ì˜ ë°”ë‚˜ë‚˜ ê·¸ë¦¼ì„ ìƒì„±í–ˆê³ , ê³ ì–‘ì´ 3ë§ˆë¦¬ë¥¼ ìƒì„±í•˜ë¼ê³  í–ˆì§€ë§Œ 4ë§ˆë¦¬ì˜ ê³ ì–‘ì´ë¥¼ ìƒì„±í–ˆë‹¤. ì´ì™€ ê°™ì´ ëª¨ë¸ì˜ ê²°ê³¼ê°€ íŠ¹ì • ìˆ˜ì˜ ê°ì²´ ìƒì„±ì— ì‹¤íŒ¨í–ˆê³ , â€˜withoutâ€™ê³¼ ê°™ì€ ë¶€ì • ì–´íœ˜ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆë‹¤. ì´ ì™¸ì—ë„ ê³µê°„ì ì¸ ì†ì„±ì„ ê°ì²´ì™€ ì˜¬ë°”ë¥´ê²Œ ì—°ê´€ì§“ëŠ”ë° ì‹¤íŒ¨í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. 

![LMD_1.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/7f3fc350-f472-463e-9625-8e8e04834556){: width="1100px"}
<br/><br/>

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë³µì¡í•œ ìº¡ì…˜ì„ í¬í•¨í•˜ëŠ” multimodal ë°ì´í„°ì…‹ì„ ìˆ˜ì§‘í•˜ê³  ëŒ€ìš©ëŸ‰ text-image ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì´ ìˆì§€ë§Œ, ì´ëŸ¬í•œ ë°©ë²•ì„ ìœ„í•´ì„œëŠ” ë°ì´í„°ì…‹ì„ íë ˆì´ì…˜ í•˜ëŠ”ë° ìƒë‹¹í•œ ì‹œê°„ê³¼ ìì›ì´ í•„ìš”í•˜ë‹¤. 
<br/><br/>

![LMD_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/b6212f4a-10e6-4faf-96ff-539ae8f86a36){: width="1100px"}

ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë” ë†’ì€ ìˆ˜ì¤€ì˜ prompt ì´í•´ë¥¼ ìœ„í•œ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>grounding</span></mark>**ì„ ì œê³µí•˜ëŠ” LLMì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´  training-free ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. ì´ ë°©ë²•ì€ **L**L**M**-grounded **D**iffusion (LMD) ì´ë¼ê³  í•˜ë©°, 2-stage generation processë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤.

1. **Text-grounded layout generation:** in-context learningì„ í†µí•´ LLMì„ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>text-grounded layout generator</span></mark>**ë¡œ í•™ìŠµí•˜ëŠ” ê³¼ì •. ì´ë¯¸ì§€ì— ê´€í•œ promptê°€ ì£¼ì–´ì§€ë©´ LLMì´ ì´ë¥¼ ê³ ë ¤í•˜ì—¬ bbox í˜•íƒœë¡œ scene ë ˆì´ì•„ì›ƒì„ ìƒì„±í•¨
2. **Layout-grounded image generation**: ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>grounding ë ˆì´ì•„ì›ƒì„ ë”°ë¼ diffusion ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„±</span></mark>**í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>controller</span></mark>** ë„ì…
<br/><br/><br/>

íŠ¹íˆ ìœ„ì˜ ë‘ ë‹¨ê³„ëŠ” ëª¨ë‘ ê¸°ì¡´ì— í•™ìŠµëœ frozen pretrained ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, LLMê³¼ diffusion ëª¨ë¸ ì¬í•™ìŠµ ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµëœ ê°ê°ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì ìš©í•  ìˆ˜ ìˆë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Method (LLM-grounded Diffusion)

---

## 1. LLM-based Layout Generation

![LMD_3.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/008d9884-b62c-4eaf-9839-e9365ada9e5f){: width="1300px"}

ë…¼ë¬¸ì—ì„œëŠ” ì´ë¯¸ì§€ ë ˆì´ì•„ì›ƒì„ ìƒì„±í•˜ê¸° ìœ„í•´ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>In-Context Learning</span></mark>***ì„ í™œìš©í•œë‹¤. ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ì…ë ¥ caption(prompt)ì„ íŠ¹ì •í•œ templeteì— ë§ê²Œ ë°”ê¿”ì¤€ ë’¤, LLMì—ê²Œ queryí•˜ì—¬ LLM Completionì„ íšë“í•œë‹¤. ì´ ë•Œ LLMì— queryí•˜ëŠ” ë‚´ìš©ì€ prompt ë¬¸ì¥ì„ ë³´ê³  **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Layout representation</span></mark>**ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. Layout representationì€ ë‹¤ìŒê³¼ ê°™ì´ 2ê°œ(ë˜ëŠ” 3ê°œ)ì˜ ìš”ì†Œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. 

1. captionì— í¬í•¨ë˜ì–´ ìˆëŠ” ê°ê°ì˜ foreground objectì— ëŒ€í•œ bounding box: (x, y, width, height) **formatìœ¼ë¡œ êµ¬ì„±ëœ coordinate ì •ë³´.
2. ì´ë¯¸ì§€ backgroundë¥¼ ì„¤ëª…í•˜ëŠ” ê°„ê²°í•œ caption.

(3. negative prompt: ìƒì„±ëœ ì´ë¯¸ì§€ì— í¬í•¨ë˜ì§€ ë§ì•„ì•¼í•  ê²ƒ. ì„ íƒì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ. ì´ì™¸ì—ëŠ” ë¹„ì›Œë‘”ë‹¤.)
<br/><br/>

> **In-Context Learning*** <br/>
> In-Context Learningì€ Meta Learningì˜ ì¼ì¢…ìœ¼ë¡œ, fine-tuningê³¼ ê°™ì€ ë³„ë„ì˜ ëª¨ë¸ì„ í•™ìŠµì„ ê±°ì¹˜ì§€ ì•Šê³ , inference ë‹¨ê³„ì—ì„œ promptë¥¼ ì˜ ìƒì„±í•˜ì—¬ì¤Œìœ¼ë¡œì„œ ë§¥ë½ì ì¸ ì˜ë¯¸ë¥¼ ëª¨ë¸ì´ íŒŒì•…í•˜ê²Œ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
> 

<br/><br/><br/>

LLMì— queryí•˜ê¸° ìœ„í•´ captionì„ íŠ¹ì • templeteìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³´ì. Templeteì—ëŠ” ëª‡ê°€ì§€ ì§€ì‹œì‚¬í•­(instruction)ì„ ì¶”ê°€í•œë‹¤. Instructionì€ ë‘ê°œì˜ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤.<br/>
![LMD_4.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/0068a4e4-4bc0-44c9-9611-aa751a0cd700){: width="1300px"}<br/>
1. Task specification: Taskì— ëŒ€í•œ ì„¤ëª…
2. Supporting details: ì´ë¯¸ì§€ í˜•ì‹ ë“±ì˜ ìƒì„¸ ì •ë³´
<br/><br/><br/><br/>

#### In-Context Learning.

ì €ìëŠ” ìœ„ì˜ task description ë’¤ì— ì•„ë˜ì™€ ê°™ì´ ìˆ˜ë™ìœ¼ë¡œ íë ˆì´ì…˜í•œ ì˜ˆì œë¥¼ ì¶”ê°€í•˜ì—¬ LLMì— ì œê³µí•œë‹¤. ì´ë¥¼ í†µí•´ LLMì´ ëª¨í˜¸í•¨ì„ ê·¹ë³µí•˜ë„ë¡ í•˜ê³  ëª…í™•í•œ ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•œë‹¤.<br/>
![LMD_5.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/b96cda2d-541f-49b2-9ce4-e2daff83d9e8){: width="1200px"}
<br/><br/><br/>

ì—¬ê¸°ì— ë³´ë‹¤ ì •í™•í•œ layout controlì„ ìœ„í•´, ì €ìëŠ” 2ê°€ì§€ ì›ì¹™ì„ ì¶”ê°€í•˜ì˜€ë‹¤. 

1. ê°ê°ì˜ object instanceëŠ” ë‹¨ì¼ bounding boxë¡œ í‘œí˜„ëœë‹¤.
(e.g. promptì— ì‚¬ê³¼ 4ê°œê°€ ì–¸ê¸‰ë˜ë©´ â€œì‚¬ê³¼â€ captionì´ ìˆëŠ” bbox 4ê°œë¥¼ ìƒì„±í•œë‹¤.)
2. ëª¨ë“  foreground objectê°€ ë ˆì´ì•„ì›ƒì— í¬í•¨ë˜ë„ë¡ í•˜ê³  background captionì— ë‚¨ê²¨ë‘ì§€ ì•ŠëŠ”ë‹¤.
<br/><br/><br/>

â‡’ ì´ë ‡ê²Œ ìƒì„±ëœ full promptì— ëŒ€í•œ ì˜ˆì‹œ (LLM input)<br/>
![LMD_6.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/36ba9513-20bb-4678-8ba3-fc739a0db082){: width="1000px"}<br/>
ìœ„ì™€ ê°™ì€ promptë¥¼ ì œê³µí•˜ë©´ LLMì€ â€œObjects:â€ ë¶€í„° Completionì„ ì‹œì‘í•œë‹¤.
<br/><br/><br/><br/>

#### LLM Completion.

in-context ì˜ˆì œê°€ ì œê³µëœ í›„, LLM Completionì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‹œì‘ëœë‹¤.<br/>
![LMD_7.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/5c6188ae-9571-4f6d-a885-2b4346723e64){: width="1300px"}<br/>
LLM Completionì˜ ê²°ê³¼ ë ˆì´ì•„ì›ƒì€ parsingë˜ê³  í›„ì† ì´ë¯¸ì§€ ìƒì„± í”„ë¡œì„¸ìŠ¤ì— ì‚¬ìš©ëœë‹¤.
<br/><br/><br/>

â‡’ In-context ê²°ê³¼ ì˜ˆì‹œ (LLM Completion)<br/>
![LMD_8.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/81639c38-8e3f-4130-a8b6-5681fd706c93){: width="1000px"}
<br/><br/><br/><br/><br/>

## 2. Layout-grounded Stable Diffusion

ë¨¼ì €, LDMì˜ generation ë°©ë²•ì„ ì‚´í´ë³´ê¸° ì „ì—, 2023ë…„ ë°œí‘œëœ BoxDiff ë…¼ë¬¸ì˜ ì¼ë¶€ë¥¼ ì‚´í´ë³´ì.
<br/><br/>

> [**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion**ğŸ“„](https://arxiv.org/abs/2307.10816)<br/>
> í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” Boxì™€ ê°™ì€ ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ì¡°ê±´ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ì£¼ì–´ì§„ spatial conditionì„ ì¤€ìˆ˜í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´, í•©ì„± ì´ë¯¸ì§€ì—ì„œ objectì™€ contextë¥¼ ì œì–´í•˜ëŠ” training-free methodë¥¼ ì œì•ˆí•œë‹¤.<br/>
> ![LMD_9.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/ec7f2dea-e8aa-4001-8560-ea912fb62676){: width="600px"}
>
> ë¨¼ì €, box conditionì„ constraintë¡œ ì£¼ê¸° ìœ„í•´, í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” textì™€ image featureì˜ cross-attention mapì— ì£¼ëª©í•œë‹¤. <br/>
> ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ Stable Diffusion ëª¨ë¸ì˜ denoising stepì—ì„œ, cross-attention mapì˜ ë†’ì€ response regionì˜ ìœ„ì¹˜ì™€ í¬ê¸°ëŠ” ë””ì½”ë”©ëœ ì´ë¯¸ì§€ $x$ì˜ object(panda, snowboard)ì™€ ì§€ê°ì ìœ¼ë¡œ ë™ì¼í•˜ë‹¤. ì´ëŠ” ì´ë¯¸ì§€ $x$ì—ì„œ ëŒ€ìƒ objectì˜ ìƒì„±ì„ ì œì–´í•˜ê¸° ìœ„í•´ cross-attentionì— ì œì•½ ì¡°ê±´ì„ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤ëŠ” ë™ê¸°ë¥¼ ë¶€ì—¬í•œë‹¤.
> 
> <br/>
> ![LMD_10.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/165a6566-7db1-40dc-94a5-698cb7db20c8){: width="1400px"}
>
> ë”°ë¼ì„œ í•©ì„±ëœ ê°ì²´ì˜ ìœ„ì¹˜ì™€ í¬ê¸°ê°€ box conditionì— ì¶©ì¡±í•˜ê²Œ í•˜ê¸° ìœ„í•´, latent $z_t$ë¥¼ ì ì§„ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì—ì„œ cross-attention mapì— ëŒ€í•´ ì„¸ ê°€ì§€ spatial constraintë¥¼ ì œì•ˆí•œë‹¤.
> 
> **1. Inner-Box Constraint**: objectê°€ box ìœ„ì¹˜ì— ìƒì„±ë˜ë„ë¡, cross-attentionì˜ ë†’ì€ responseê°€ ë§ˆìŠ¤í¬ ì˜ì—­ì—ë§Œ ìˆë„ë¡ ìƒì ë‚´ì˜ responseë¥¼ ìµœëŒ€í™”í•˜ëŠ” ì¡°ê±´.<br/>
> **2. Outer-Box Constraint**: objectê°€ box ì˜ì—­ ë°–ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´, cross-attentionì˜ ë†’ì€ responseê°€ ë§ˆìŠ¤í¬ ì˜ì—­ ë°–ì— ìƒì„±ë˜ëŠ” ê²ƒì„ ìµœì†Œí™”í•˜ëŠ” ì¡°ê±´(1-Mask).<br/>
> **3. Corner Constraint**: objectì˜ ê²½ê³„ í”½ì…€ì„ ì¢€ ë” ëª…í™•í•˜ê²Œ ì œí•œí•˜ê¸° ìœ„í•œ ì¡°ê±´.
> <br/>
> 
> LMDì—ì„œëŠ” ë§ˆì°¬ê°€ì§€ë¡œ In-Contextë¡œ ìƒì„±ëœ box ì•ˆì— ê°ì²´ê°€ ìƒì„±ë˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•˜ë¯€ë¡œ, Box Diffì˜ Inner-Box Constraintì™€ Outer-Box Constraintë¥¼ í™œìš©í•œë‹¤.
> 

<br/><br/><br/>

ì´ì œ Layout-grounded image generation stageë¥¼ ì‚´í´ë³´ì. ì´ ë‹¨ê³„ì—ì„œëŠ” LLMì—ì„œ ìƒì„±ëœ ë ˆì´ì•„ì›ƒì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ êµ¬ì¶•í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ì†Œê°œí•œë‹¤. 

Diffusion ëª¨ë¸ì€ instance-level êµ¬ë¶„ì„ ìœ„í•œ ì„¸ë°€í•œ control ëŠ¥ë ¥ì€ ë¶€ì¡±í•˜ì§€ë§Œ, í•˜ë‚˜ì˜ instanceì— ëŒ€í•œ ìƒì„±ì— ìœ ë¦¬í•˜ë‹¤. ë”°ë¼ì„œ ë…¼ë¬¸ì—ì„œëŠ” instance-level groundingì„ ìœ„í•´ í•œ ë²ˆì— í•˜ë‚˜ì˜ foreground boxë¥¼ ì²˜ë¦¬í•œë‹¤. Generation stage ê° stepë³„ë¡œ ìì„¸í•œ ê³¼ì •ì„ ì‚´í´ë³´ì.
<br/><br/>

![LMD_11.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/34fc4651-9b42-457f-bd18-425206f3ce89){: width="1000px"}

1. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´, ê°ê°ì˜ foreground object $i$ ì— ëŒ€í•´, noise image $\mathbf{z}^{(i)}_T$ì—ì„œ $\mathbf{z}^{(i)}_0$ë¡œ noiseë¥¼ ì œê±°í•˜ì—¬ í•˜ë‚˜ì˜ instanceì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” denoising processë¥¼ ì§„í–‰í•œë‹¤. ì´ë¥¼ ìœ„í•´ ë¨¼ì € **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Gaussian noise $\mathbf{z}^{(i)}_T$ë¥¼ ìƒì„±</span></mark>**í•œë‹¤.<br/>
ì´ ë•Œ ìƒì„±í•œ initial noiseëŠ” ëª¨ë“  foreground object ì´ë¯¸ì§€ ìƒì„±(bbox)ì— ê³µìœ ë¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•œë‹¤.(ì¦‰, $z^{(i)}_T = z_T$)
<br/><br/>
2. Denoising processì˜ noise ì œê±°ë¥¼ ìœ„í•œ **caption**ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•œë‹¤.
â€*[background prompt] with [box caption]*"           (ì˜ˆ: â€œ*a realistic image of an indoor scene with a gray catâ€*)
<br/><br/>
3. ì•ì„œ ì–¸ê¸‰í•œ ê²ƒ ì²˜ëŸ¼ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Cross attetion map</span></mark>**ì„ ì‚¬ìš©í•˜ì—¬ bbox ì•ˆì— objectê°€ ìƒì„±ë˜ë„ë¡ í•˜ê¸° ìœ„í•´, cross attention mapì„ êµ¬í•œë‹¤. Spatial location $u$ì—ì„œì˜ image feature $\mathbf{q}_u$, token index $v$ì—ì„œ text feature $\mathbf{k}_v$ì— ëŒ€í•œ cross attention map $\mathbf{A}^{(i)}$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. ê°ê°ì˜ mapì€ pixelê³¼ text tokenì˜ ì¹œí™”ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
    
    $$
    \mathbf{A}^{(i)}_{uv} = \text{softmax}(\mathbf{q}^{T}_u \mathbf{k}_v)
    $$

    <br/>    
4. ìœ„ì—ì„œ ì–¸ê¸‰í•œ BoxDiffì˜ constraintë¥¼ ì‚¬ìš©í•˜ì—¬ bbox ì•ˆì˜ pixelì€ captionê³¼ ê´€ë ¨ëœ tokenìœ¼ë¡œ cross-attentionì„ ê°•í™”í•˜ê³ , bbox ë°–ì˜ pixelì—ì„œ cross-attentionì„ ì•½í™”í•˜ëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>energy function</span></mark>**ì„ ì‚¬ìš©í•œë‹¤. (Inner-Box, Outer-Box constraint)
($\text{Topk}_u$: average of top-k values across the spatial dimension $u$)
    
    $$
    E(\mathbf{A}^{(i)}, i, v) = - \text{Topk}_u(\mathbf{A}_{uv}\ \cdot \ \mathbf{b}^{(i)}) + w \ \text {Topk}_u(\mathbf{A}_{uv} \cdot (1-\mathbf{b}^{(i)}))
    $$

    <br/>    
5. ê°ê°ì˜ denoising step ì „ì— latentë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ energy functionì„ ìµœì†Œí™” í•œë‹¤.
($\eta$ëŠ” guidance strength; $\text{Denoise}(\cdot)$ì€ denoising step)
    
    $$
    \mathbf{z}^{(i)}_t \gets \mathbf{z}^{(i)}_t - \eta \nabla_{\mathbf{z}^{(i)}_t} \sum_{u\ \in V_i} E(\mathbf{A}^{(i)}, i, v ) \\
    \mathbf{z}^{(i)}_{t-1} \gets \text{Denoise}(\mathbf{z}^{(i)}_t)
    $$

    <br/>    
6. ìƒì„± ë‹¨ê³„ê°€ ëë‚˜ë©´, box captionì— í•´ë‹¹í•˜ëŠ” **cross-attention map**ì„ ì–»ëŠ”ë‹¤. ì´ mapì€ ê° objectì— í•´ë‹¹í•˜ëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>saliency mask ì—­í• </span></mark>**ì„ í•œë‹¤. ì—¬ê¸°ì„œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>SAM</span></mark>**(segmentation ëª¨ë¸, [SAM ë…¼ë¬¸ ë¦¬ë·°](https://lunaleee.github.io/posts/SAM/) ì°¸ì¡°)ì„ ì¶”ê°€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ mask í’ˆì§ˆì„ í–¥ìƒì‹œí‚¨ë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ Per-box cross-attention mapì„ SAMì— ë„£ìœ¼ë©´ ë†’ì€ saliencyë¥¼ ê°€ì§€ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ refineëœ maskë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ë§Œì•½ SAMì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ saliency maskì—ì„œ ë‹¨ìˆœ thresholdingìœ¼ë¡œ ëŒ€ì²´í•  ìˆ˜ë„ ìˆë‹¤. <br/>
í•˜ë‚˜ì˜ foreground instanceì— ëŒ€í•œ mask $\mathbf{m}^{(i)}$ê°€ ìƒì„±ë˜ë©´, ê° denoising stepì˜ latentì™€ maskë¥¼ element-wise multiplication í•˜ì—¬ *masked* instance latents $(\hat{\text{z}}^{(i)})^T_{t=0}$ë¥¼ ì–»ëŠ”ë‹¤. <br/>
**<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>masked instance latent</span></mark>**: ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ instanceì— í•´ë‹¹í•˜ëŠ” ì˜ì—­ì— ëŒ€í•œ latent image.
    
    $$
    \hat{\mathbf{z}}^{(i)}_t = \mathbf{z}^{(i)}_t âŠ— \mathbf{m^{(i)}}
    $$
    
    <br/>

   ![LMD_12.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/2673f654-4631-404b-9b37-a331b9cdd89f){: width="1200px"}

7. masked instance latents $(\hat{\text{z}}^{(i)})^T_{t=0}$ ëŠ” ì „ì²´ ì´ë¯¸ì§€ ìƒì„±ì— ì¼ì¢…ì˜ instance-level íŒíŠ¸ ì—­í• ì„ í•œë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´, ê°ê° instanceì˜ masked latentëŠ” instance ì´ë¯¸ì§€ ìƒì„±ì´ ì•„ë‹Œ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ì „ì²´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” denoising process ê³¼ì •ì— ì£¼ì…</span></mark>**ëœë‹¤. ê° denoising time stepì—ì„œì˜ latent $\mathbf{z}^{(\text{comp})}_t$ì— ëŒ€í•´, masked instance latents $\hat{\mathbf{z}}^{(i)}_t$ì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ëŠ” í•´ë‹¹ maskë¥¼ ë°°ì¹˜í•œë‹¤.<br/>
ì•ì„œ ì–¸ê¸‰í–ˆ ë“¯ í†µì¼ì„±ì„ ìœ„í•´ $\mathbf{z}^{(\text{comp})}_T$ëŠ” $\mathbf{z}_T$ë¡œ initializeëœë‹¤. <br/>
Diffusion ëª¨ë¸ì€ ì´ˆê¸° denoising stepì—ì„œ objectì˜ ìœ„ì¹˜ë¥¼ ìƒì„±í•˜ê³  ì´í›„ stepì—ì„œ ë””í…Œì¼í•œ ë¶€ë¶„ì„ ìƒì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë¯€ë¡œ, **ì´ˆê¸° ë‹¨ê³„ì—ë§Œ í•´ë‹¹ ê³¼ì •ì„ ì ìš©**í–ˆë‹¤.
    
    $$
    \mathbf{z}^{(\text{comp})}_t \gets \text{LatentCompose}(\mathbf{z}^{(\text{comp})}_t, \hat{\mathbf{z}}^{(i)}_t, \mathbf{m}^{(i)}) \quad \forall i
    $$
    
    <br/>
8. ì´ ë•Œ ê°€ì´ë“œë¥¼ ë”ìš± ê°•ë ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´, per-box generationì—ì„œ ìƒì„±ëœ cross-attention mapì„ energy functionì„ ì´ìš©í•˜ì—¬ í•´ë‹¹ ì˜ì—­ìœ¼ë¡œ ì¶”ê°€ë¡œ ì „ì†¡í•œë‹¤.
    
    $$
    E^{\text{(comp)}} = (\mathbf{A}^{(\text{comp})}, \mathbf{A}^{(i)}, i, v) = E(\mathbf{A}^{(\text{comp})}, i, v) + \lambda \sum_{u \in V^{'}_i } âˆ£\mathbf{A}^{(\text{comp})}_{uv} - \mathbf{A}^{(i)}_{uv}âˆ£
    $$

9. ë§ˆì§€ë§‰ìœ¼ë¡œ **diffusion image decoder**ë¥¼ ì‚¬ìš©í•˜ì—¬ latent $\mathbf{z}^{(\text{comp})}_0$ë¥¼ pixel $\mathbf{x}_0$ë¡œ ë””ì½”ë”©í•œë‹¤.

<br/><br/><br/>
ë…¼ë¬¸ì— ì œì•ˆëœ training-free ë°©ë²•ì€ instance-annotated external datasetì„ í™œìš©í•˜ê¸° ìœ„í•´ GLIGENê³¼ ê°™ì€ training-based methodì— ì ìš©í•  ìˆ˜ë„ ìˆë‹¤. 
<br/><br/><br/><br/><br/>

## 3. Additional Capabilities of LMD

LMD pipelineì€ ì¶”ê°€ì ì¸ í•™ìŠµê³¼ì • ì—†ì´ë„ ë‘ ê°€ì§€ ì¶”ê°€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
<br/><br/>

#### 1. Instruction-based scene specification

![LMD_13.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/e983d39e-0167-4289-a83d-1ab3b3376300){: width="800px"}

Multi-round dialogë¥¼ ì§€ì›í•˜ëŠ” LLM(e.g. GPT-3.5/4)ì„ í™œìš©í•˜ì—¬ LMDëŠ” ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì´ˆê¸° prompt ì´í›„ì— ì—¬ëŸ¬ ëª…ë ¹ì–´ë¡œ ì¶”ê°€ì ì¸ ì´ë¯¸ì§€ í•©ì„±ì´ ê°€ëŠ¥í•˜ë‹¤. ì´ˆê¸° ì´ë¯¸ì§€ ìƒì„± ì´í›„ ì‚¬ìš©ìê°€ LLMì— ì„¤ëª…ì´ë‚˜ ì¶”ê°€ì ì¸ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´, ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ ìƒˆë¡œìš´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. í•´ë‹¹ ê¸°ëŠ¥ì„ í†µí•´ ì‚¬ìš©ìê°€ ì „ì²´ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼, ë ˆì´ì•„ì›ƒì„ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ ì„¸ë¶€ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
<br/><br/><br/>

#### 2. Supporting more languages

![LMD_14.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/53b3da22-2d53-4012-bf4d-fa6bfd6c3188){: width="800px"}

ì˜ì–´ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì˜ì–´ layout outputì„ ì œê³µí•œë‹¤. ì´ë¥¼ í†µí•´ LLM layout generatorëŠ” non-English ìœ ì €ì˜ promptë¥¼ ì´í•´í•˜ê³  ì˜ì–´ captionê³¼ í•¨ê»˜ layoutì„ ì¶œë ¥í•œë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Experiments

---

### 1. Qualitative Comparison

![LMD_15.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/e64bcbdc-17f9-4fa1-b57c-4a64df20cc67){: width="1200px"}

ë…¼ë¬¸ì—ì„œëŠ” LMDë¥¼ Stable Diffusionê³¼ ì§ˆì ìœ¼ë¡œ ë¹„êµí–ˆë‹¤. LDMì€ ì¶”ê°€ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ diffusion ëª¨ë¸ì— ì ìš©ê°€ëŠ¥í•˜ë¯€ë¡œ ê°€ì¥ í° Stable Diffusion ëª¨ë¸ì¸ SDXLì„ LMDì˜ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì˜€ê³ , SDXL baselineê³¼ ë¹„êµí•˜ì˜€ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ 2ë‹¨ê³„ text-to-image generation ë°©ì‹ì´ LLMì˜ layoutê³¼ ì¼ì¹˜í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨ìœ¼ë¡œì¨ baseline ëª¨ë¸ì— ë¹„í•´ promptì— ì¶©ì‹¤í•œ ê²ƒì„ ê´€ì°°í–ˆë‹¤.
<br/><br/><br/>

![LMD_16.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/f460a499-39da-4c74-bd42-7c88630ede49){: width="1200px"}

ë‹¤ë¥¸ LLM-based image generatorì™€ ë¹„êµë¥¼ ìˆ˜í–‰í–ˆë‹¤. VisualChatGPT, GILL ëª¨ë¸ë„ LLMì„ í™œìš©í•˜ê³  Stable Diffusion ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. ë‘ ë°©ë²•ì€ ì—¬ì „íˆ ê¸°ë³¸ SD ëª¨ë¸ì—ì„œ text embeddingì— ëŒ€í•œ ì œì–´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ë¬¸ì œê°€ ìˆë‹¤. ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ë‘ ë°©ë²• ëª¨ë‘ LMDì— ë¹„í•´ text promptë¥¼ ì •í™•í•˜ê²Œ ë”°ë¥´ì§€ ì•ŠëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/>

### 2. Quantitative evaluation

ì €ìëŠ” ë‹¤ìŒ 4ê°€ì§€ taskë¥¼ í¬í•¨í•˜ëŠ” text-to-image evaluation benchmarkë¥¼ ì œì•ˆí–ˆë‹¤. 

- Negation / generative numeracy: íŠ¹ì • ê°œìˆ˜ì˜ objectë¥¼ ìƒì„±í•˜ê±°ë‚˜ íŠ¹ì • ê°ì²´ë¥¼ ìƒì„±í•˜ì§€ ì•ŠëŠ” ê²ƒ
- Attribute binding: promptì— ì—¬ëŸ¬ objectê°€ ìˆì„ ë•Œ ì˜¬ë°”ë¥¸ objectì— ì˜¬ë°”ë¥¸ ì†ì„±(attribute)ì„ í• ë‹¹í•˜ëŠ” ì‘ì—…
- Spatial reasoning: objectì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ì„¤ëª…í•˜ëŠ” ë‹¨ì–´ë¥¼ ì´í•´í•˜ëŠ” ê²ƒ
<br/><br/><br/>

#### Detection-based evaluation.

ì €ìëŠ” ê´€ì‹¬ ìˆëŠ” objectì— ëŒ€í•œ bounding boxë¥¼ ì–»ê¸° ìœ„í•´ open-vocabulary object detector, OWL-ViTë¥¼ í™œìš©í–ˆë‹¤. ê·¸ ë‹¤ìŒ ìƒì„±ëœ ê° ì´ë¯¸ì§€ê°€ promptì˜ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í–ˆë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ í‘œì™€ ê°™ì´ 4ê°œ taskì—ì„œ SDì— ë¹„í•´ 1.3ë°°ì—ì„œ 3.6ë°°ê¹Œì§€ ìƒì„± ì •í™•ë„ê°€ í¬ê²Œ í–¥ìƒë˜ê³  í‰ê·  ì •í™•ë„ê°€ ë‘ ë°° ì¦ê°€í–ˆë‹¤.

ë˜í•œ in-domain instance-annotated ë°ì´í„°ë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ GLIGENì„ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€ë¡œ í†µí•©í•˜ë©´(LMD+) ì¶”ê°€ ê°œì„ ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![LMD_17.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/cd439948-c573-4b92-8168-0401bebf85bf){: width="1100px"}
<br/><br/><br/><br/>

### 3. Ablation Study

#### Layout-to-image stage.

![LMD_18.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/30d395ca-66d9-44c8-9abe-7542573c0561){: width="900px"}

ë‹¤ë¥¸ layout-to-image methodì™€ ë¹„êµë¥¼ ìˆ˜í–‰í–ˆë‹¤. Semantic-level groundingì„ ìˆ˜í–‰í•˜ëŠ” training-free layout-to-image generation ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ì œì•ˆëœ LMDëŠ” í›¨ì”¬ ë” ë‚˜ì€ instance-level grounding ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
<br/><br/><br/>

![LMD_19.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/c5323bdb-4e4e-4241-afdd-98dc40763d1f){: width="350px"}

ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë“¯ SAMì„ ì‚¬ìš©í•˜ì—¬ maskë¥¼ ì–»ëŠ” ëŒ€ì‹  ì¶”ê°€ segmentation ëª¨ë“ˆì´ í•„ìš”í•˜ì§€ ì•Šì€ ì ‘ê·¼ ë°©ì‹ì— ëŒ€í•œ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤. Attention ê°’ì´ ê°€ì¥ ë†’ì€ ìƒìœ„ 75% í”½ì…€ì„ ê° bboxì˜ maskë¡œ ì„ íƒí–ˆë‹¤. ê²°ê³¼ëŠ” ìœ„ í‘œì™€ ê°™ë‹¤.
<br/><br/><br/><br/>
