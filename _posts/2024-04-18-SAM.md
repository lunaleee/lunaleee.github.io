---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Segment Anything (SAM)"
author: lunalee
date: 2024-04-18 19:39:21 +0900
categories: [AI, Paper Review]
tags: [Image, Segmentation, Zero-shot]
pin: false
math: true
---

<br/><br/>
`Meta AI Research, FAIR` `arXiv 2023`

- Paper: [https://arxiv.org/abs/2304.02643](https://arxiv.org/abs/2304.02643)
- Git: [https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)
- Page: [https://segment-anything.com](https://segment-anything.com/)
<br/><br/><br/><br/><br/>

# Introduction

---

NLPì—ì„œëŠ” web-scale ë°ì´í„°ì…‹ì— ëŒ€í•´ í•™ìŠµëœ Large language modelì´ ê°•ë ¥í•œ zero-shot/few-shot generalization ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ì´ëŸ¬í•œ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Foundation model</span></mark>**ì€ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” task/dataë¥¼ ë„˜ì–´ì„œëŠ” generalizationì´ ê°€ëŠ¥í•˜ë‹¤. 

Computer visionì—ì„œë„ Foundation modelì— ëŒ€í•œ ì—°êµ¬ê°€ ì§„í–‰ë˜ì—ˆë‹¤. Text-image pairë¥¼ alignmentí•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•œ CLIP ë° ALIGNê³¼ ê°™ì€ ì—°êµ¬ëŠ” contrastive learningì„ ì‚¬ìš©í•˜ì—¬ text ë° image encoderë¥¼ í•™ìŠµì‹œì¼°ë‹¤. ì´ëŸ¬í•œ encoderëŠ” Image Generationê³¼ ê°™ì€ down-stream taskë¥¼ ìœ„í•´ ë‹¤ë¥¸ ëª¨ë“ˆê³¼ í•¨ê»˜ ì‚¬ìš©ëœë‹¤. Vision, language encoderì— ëŒ€í•œ ë§ì€ ì§„ì „ì´ ìˆì—ˆì§€ë§Œ computer visionì—ëŠ” ì´ë¥¼ ë„˜ì–´ì„œëŠ” ê´‘ë²”ìœ„í•œ ë¬¸ì œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, í’ë¶€í•œ ë°ì´í„°ì…‹ ë˜í•œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
<br/><br/>

![SAM_1.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/b742efe5-3fc2-4296-b89c-d12721560f0e){: width="1200px"}

ë³¸ ë…¼ë¬¸ì˜ ëª©í‘œëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Image Segmentationì„ ìœ„í•œ Foundation modelì„ êµ¬ì¶•</span></mark>**í•˜ëŠ” ê²ƒì´ë‹¤. ì €ìëŠ” ê°•ë ¥í•œ generalizationì„ ìœ„í•œ promptable modelì„ ê°œë°œí•˜ê³  ê´‘ë²”ìœ„í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì´ ëª¨ë¸ì„ pre-trainí•œë‹¤. ì´ ëª¨ë¸ì„ í†µí•´ prompt engineeringì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ë°ì´í„° ë¶„í¬ì— ëŒ€í•œ ë¬¸ì œ(segmentation)ë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
<br/><br/>

ì´ë¥¼ ìœ„í•´ ì €ìëŠ” ë¬¸ì œë¥¼ ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†Œë¡œ êµ¬ë¶„í•˜ì˜€ë‹¤. Image Segmentationì— ëŒ€í•œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

1. What **task** will enable zero-shot generalization?
2. What is the corresponding **model** architecture?
3. What **data** can power this task and model?
<br/><br/><br/>

ì´ëŸ¬í•œ ì§ˆë¬¸ì€ ì„œë¡œ ì—°ê´€ë˜ì–´ìˆìœ¼ë¯€ë¡œ í¬ê´„ì ì¸ ì†”ë£¨ì…˜ì´ í•„ìš”í•˜ë‹¤. ê°•ë ¥í•œ pre-training objectiveë¥¼ ì œê³µí•˜ê³  ë„“ì€ ë²”ìœ„ì˜ downstream applicationì´ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” promptable segmentation **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>task</span></mark>**ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒ ë¶€í„° ì‹œì‘í•œë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” flexible promptingì„ ì§€ì›í•˜ê³  promptë¥¼ ì‚¬ìš©í•˜ì—¬ interactiveí•˜ê²Œ real-timeìœ¼ë¡œ sementation outputì„ ì¶œë ¥í•  ìˆ˜ ìˆëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>model</span></mark>**ì´ í•„ìš”í•˜ë‹¤. ì´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë ¤ë©´ ë‹¤ì–‘í•˜ê³  ëŒ€ê·œëª¨ì˜ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>data</span></mark>** sourceê°€ í•„ìš”í•˜ë‹¤.

í•˜ì§€ë§Œ segmentaionì„ ìœ„í•œ web-scale data sourceëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì €ìëŠ” íš¨ìœ¨ì ì¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì„ ì§€ì›í•˜ê³  ìƒˆë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ê°œì„ í•˜ëŠ” **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>â€œdata engineâ€</span></mark>**ì„ êµ¬ì¶•í–ˆë‹¤.
<br/><br/><br/><br/><br/><br/>

# Segment Anything Task

---

### Task.

ë¨¼ì € Taskë¥¼ ì •ì˜í•˜ê¸° ìœ„í•´ Promptë¥¼ NLPì—ì„œ Segmetationì— ë§ê²Œ ë³€í™˜ì´ í•„ìš”í•˜ë‹¤. ì €ìëŠ” points(foreground / background point ì§‘í•©), boxes, mask, textë“±ì„ promptë¡œ ì‚¬ìš©í–ˆë‹¤.  Promptable segmentation taskëŠ” ì´ëŸ¬í•œ ë‹¤ì–‘í•œ í˜•ì‹ì˜ promptì— ëŒ€í•´ ìœ íš¨í•œ segmentation maskë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
<br/><br/>

![SAM_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/546dd2b8-c47a-41e8-8d11-d2d4f5b4d2d3){: width="450px"}

â€œìœ íš¨í•œâ€ maskë€ promtê°€ ëª¨í˜¸í•˜ê³  ì—¬ëŸ¬ ê°ì²´ë¥¼ ì˜ë¯¸í•  ìˆ˜ ìˆëŠ” ê²½ìš°ì—ë„ ì¶œë ¥ì´ í•©ë¦¬ì ì´ì•¼í•¨ì„ ì˜ë¯¸í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìœ„ì˜ ê·¸ë¦¼ì—ì„œ pointëŠ” í•˜ì–€ ë²½ë©´ ìì²´ë¥¼ ì˜ë¯¸í•  ìˆ˜ ë„ ìˆê³ ,  â€˜ZURICHâ€™ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ë¯¸í•  ìˆ˜ë„ ìˆë‹¤. í˜¹ì€ â€˜Zâ€™ ì•ŒíŒŒë²³ í•˜ë‚˜ë¥¼ ì˜ë¯¸í•  ìˆ˜ë„ ìˆë‹¤. ì´ë ‡ê²Œ ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ì˜ë¯¸í•  ìˆ˜ ìˆëŠ” ê²½ìš°ì—ë„ ì¶œë ¥ì´ í•©ë¦¬ì ì´ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. 
<br/><br/><br/><br/><br/>

### Pre-training.

Training sampleì— ëŒ€í•œ prompt(e.g. points, boxes, masks) sequenceê°€ ì£¼ì–´ì§€ë©´ ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ maskë¥¼ ì˜ˆì¸¡í•˜ê³ , ground truthì™€ ë¹„êµí•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **interactive segmentation** ë°©ë²•ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. 
<br/><br/>

ì°¨ì´ì ì€ Interactive segmentation ë°©ë²•ê³¼ ë‹¬ë¦¬ promptê°€ ëª¨í˜¸í•œ ê²½ìš°ì—ë„ í•­ìƒ ëª¨ë“  promptì— ëŒ€í•´ ìœ íš¨í•œ maskë¥¼ ì˜ˆì¸¡í•˜ë„ë¡í•œë‹¤.
<br/><br/><br/><br/><br/><br/>

# Segment Anything Model

---

![SAM_3.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/7cc3ce18-9b38-4017-965d-6830c0d48d95){: width="1300px"}

ë‹¤ìŒìœ¼ë¡œëŠ” promptable segmentationì„ ìœ„í•œ Segment Anything Model (SAM)ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤. SAMì€ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Image Encoder, Prompt Encoder, Mask Decoder</span></mark>** ì„¸ ê°€ì§€ ìš”ì†Œë¡œ êµ¬ì„±ëœë‹¤.
<br/><br/><br/>

### Image encoder.

High-resolution ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ **Masked AutoEncoder(MAE)ë¡œ pre-trainëœ ViT(Vision Transfomer)**ë¥¼ ì‚¬ìš©í•œë‹¤.
<br/><br/><br/>

### Prompt encoder.

Prompt encoderëŠ” flexibleí•˜ê²Œ ë‹¤ì–‘í•œ í˜•íƒœì˜ ì…ë ¥ì— ëŒ€í•´ ì²˜ë¦¬í•œë‹¤. í¬ê²Œ **sparse(points, boxes, text)ì™€ dense(masks)** ë‘ ê°€ì§€ promptë¥¼ ì²˜ë¦¬í•œë‹¤. ì…ë ¥ì€ ê°ê° ì•„ë˜ì˜ ë°©ë²•ìœ¼ë¡œ 256ì°¨ì› vectorial embeddingìœ¼ë¡œ ë³€í™˜ëœë‹¤.

- **points:** pointì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>positional encoding</span></mark>**ê³¼ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>í•™ìŠµëœ embdding</span></mark>**ì˜ í•©ìœ¼ë¡œ í‘œí˜„ëœë‹¤. ì—¬ê¸°ì„œ **positional encoding**ì€ coordinate spaceì—ì„œ frequency spaceë¡œembeddingì„ ì§„í–‰í•˜ëŠ” positional encodingì„ ì˜ë¯¸í•œë‹¤([ë…¼ë¬¸: ğŸ“„](https://arxiv.org/abs/2006.10739)). **í•™ìŠµëœ embedding**ì€ pointê°€ foreground ì¸ì§€, background ì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€ì— ëŒ€í•´ í•™ìŠµëœ embeddingì´ë‹¤.
- **boxes**: embedding pairë¡œ í‘œí˜„ë¨. (1) **boxì˜ top-left corner**ì— í•´ë‹¹í•˜ëŠ” positional encoding + â€œtop-leftâ€ë¥¼ ì˜ë¯¸í•˜ëŠ” í•™ìŠµëœ embedding(pointì™€ ìœ ì‚¬í•˜ë‹¤ê³  ë³´ë©´ ë¨), (2) **boxì˜ bottom-left corner**ì— í•´ë‹¹í•˜ëŠ” positional encoding + â€œbottom-leftâ€ë¥¼ ì˜ë¯¸í•˜ëŠ” í•™ìŠµëœ embedding
- **free-form text**: CLIPì˜ text encoderë¥¼ ì‚¬ìš©í•˜ì—¬ embedding ëœë‹¤.
- **masks**: maskëŠ” ì´ë¯¸ì§€ì™€ spatially ë™ì¼. convolutionì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ë˜ê³  image ì„ë² ë”©ê³¼ element-wiseë¡œ ë”í•´ì§„ë‹¤.
<br/><br/><br/>

### Mask decoder.

Mask decoderëŠ” image ì„ë² ë”©ê³¼ prompt ì„ë² ë”©ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ output maskë¥¼ ìƒì„±í•œë‹¤. Decoderë¥¼ ì ìš©í•˜ê¸° ì „ì—, ViTì˜ [cls] tokenê³¼ ìœ ì‚¬í•˜ê²Œ learned output token embeddingì„ prompt embeddingì— ì¶”ê°€í•œë‹¤(í•©ì³ì„œ token).
<br/><br/>

Decoder êµ¬ì¡°ëŠ” í‘œì¤€ Transformer decoderë¥¼ ìˆ˜ì •í–ˆìœ¼ë©°, 4ê°œì˜ ë‹¨ê³„ë¡œ êµ¬ì„±ëœë‹¤.

![SAM_4.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/0197828d-aa08-4214-8a8c-ffdad860676b){: width="700px"}

1. tokenì— ëŒ€í•´ self-attention
2. Tokenì„ queryë¡œ, Image embeddingê³¼ cross-attention
3. point-wise MLP ì ìš©
4. Image embeddingì„ queryë¡œ, Tokenê³¼ cross-attention
<br/><br/>

2ê°œì˜ decoder layerë¥¼ ì ìš©í•˜ëŠ”ë° ê° decoder block ì „ì—ëŠ” image embeddingì— positional encodingì„ ë”í•´ì¤€ë‹¤. ë‹¤ìŒ decoder layerì—ëŠ” ì—…ë°ì´íŠ¸ ëœ image embeddingê³¼ token(ì •í™•íˆëŠ” ì—…ë°ì´íŠ¸ëœ token + original prompt token)ì„ ì‚¬ìš©í•œë‹¤.
<br/><br/>

Decoder ì‹¤í–‰ í›„ 2ê°œì˜ Transposed convolutional layerë¥¼ ì‚¬ìš©í•˜ì—¬ image embeddingì„ 4ë°°ë¡œ upsampleí•œë‹¤. ì¶”ê°€ë¡œ ì—…ë°ì´íŠ¸ ëœ tokenì— ëŒ€í•´, tokenì„ queryë¡œ image embeddingê³¼ cross-attentionì„ í•œë²ˆ ìˆ˜í–‰í•œë‹¤. ê·¸ë¦¬ê³  3ê°œì˜ MLP layerë¥¼ ê±°ì³ì„œ upscaleëœ image embeddingê³¼ spatially point-wise productë¥¼ ìˆ˜í–‰í•˜ì—¬ maskë¥¼ ì˜ˆì¸¡í•œë‹¤.
<br/><br/><br/>

### Resolving ambiguity.

ëª¨í˜¸í•œ promptê°€ ì£¼ì–´ì§€ë©´ ëª¨ë¸ì€ ì—¬ëŸ¬ ê°œì˜ ìœ íš¨í•œ maskì˜ í‰ê· ì„ ì¶œë ¥í•œë‹¤. ì´ëŸ¬í•œ ëª¨í˜¸í•¨ì„ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ í•˜ë‚˜ì˜ promptì— ëŒ€í•´ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>3ê°œì˜ ì¶œë ¥ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±</span></mark>**í•˜ë„ë¡ í–ˆë‹¤. í•™ìŠµ ì¤‘ì—ëŠ” ê°ê°ì˜ maskì— ëŒ€í•´ **minimum lossì— ëŒ€í•´ì„œë§Œ backprop**í•œë‹¤. Maskì— ëŒ€í•œ ìˆœìœ„ë¥¼ ë§¤ê¸°ê¸° ìœ„í•´ ëª¨ë¸ì€ ê° maskì— ëŒ€í•œ confidence score(estimated IoU)ë¥¼ ê³„ì‚°í•œë‹¤.
<br/><br/><br/>

### Losses and training.

Focal lossì™€ Dice lossë¥¼ 20:1 ë¡œ ì¡°í•©í•˜ì—¬ mask predictionì„ ìˆ˜í–‰í•œë‹¤.
<br/><br/><br/><br/><br/><br/>

# Segment Anything Data Engine

---

Segmentation mask dataëŠ” ì¸í„°ë„·ì— ì¶©ë¶„íˆ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ë°ì´í„° ì—”ì§„ì„ êµ¬ì¶•í•˜ì—¬ 1.1B ê·œëª¨ì˜ mask dataset SA-1Bë¥¼ ìˆ˜ì§‘í–ˆë‹¤. ë°ì´í„° ì—”ì§„ì€ í¬ê²Œ 4 ë‹¨ê³„ë¡œ êµ¬ì„±ëœë‹¤.
<br/><br/><br/>

## 1. Assisted-manual stage.

ì²« ë²ˆì§¸ ë‹¨ê³„ë¡œ, ê¸°ì¡´ interactive segmentationê³¼ ìœ ì‚¬í•˜ê²Œ **model-assisted annotation**ì„ ìˆ˜í–‰í•œë‹¤. ì „ë¬¸ annotatorë“¤ì€  **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>interactive segmentation toolì„ ì‚¬ìš©í•˜ì—¬ foreground / backgroundë¥¼ ì§€ì •í•˜ê³ , SAM modelì´ ëŒ€ëµì ì¸ maskë¥¼ ì œê³µ</span></mark>**í•œë‹¤. 

ì´ ë•Œ ì´ˆê¸°ì˜ SAMì€ ê³µê°œëœ segmentation ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ ìƒíƒœì´ë‹¤. Annotationì´ ì–´ëŠì •ë„ ì§„í–‰ë˜ì–´ ë°ì´í„°ê°€ ì¶”ê°€ë˜ë©´, ì¶”ê°€ëœ mask ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ SAMì„ ë‹¤ì‹œ í•™ìŠµí•œë‹¤. ë” ë§ì€ mask ë°ì´í„°ê°€ ìˆ˜ì§‘ë¨ì— ë”°ë¼ ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ViT-Bì—ì„œ ViT-Hë¡œ í™•ì¥í•˜ì˜€ìœ¼ë©°, ì´ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ì„ ì´ 6ë²ˆ ì¬í•™ìŠµí–ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì´ ë‹¨ê³„ì—ì„œ 120K ì´ë¯¸ì§€ì—ì„œ 4.3M maskë¥¼ ìƒì„±í•˜ì˜€ë‹¤.
<br/><br/><br/>

## 2. Semi-automatic stage.

ë‹¤ìŒ ë‹¨ê³„ë¡œëŠ” **â€œSegment Anythingâ€ ëŠ¥ë ¥**ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ **maskì˜ ë‹¤ì–‘ì„±**ì„ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í–ˆë‹¤. ì´ë¥¼ ìœ„í•´ ëª¨ë¸ì—ì„œ Confidentê°€ ë†’ì€ maskë¥¼ ì œì™¸í•˜ê³ , **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>confidentê°€ ë‚®ì€ ëˆˆì— ì˜ ë„ì§€ ì•ŠëŠ” mask objectì— ëŒ€í•´ annotation</span></mark>**ì„ ì§€ì‹œí–ˆë‹¤.

Confident maskë¥¼ detectí•˜ê¸° ìœ„í•´ì„œ ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘í•œ maskë¥¼ ì‚¬ìš©í•˜ì—¬ bounding box detectorë¥¼ í•™ìŠµí–ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œ ì €ìëŠ” 180K ì´ë¯¸ì§€ì— ëŒ€í•´ 5.9M maskë¥¼ ì¶”ê°€ë¡œ ìˆ˜ì§‘í–ˆë‹¤(ì´ 10.2M mask). ì²« ë²ˆì§¸ ë‹¨ê³„ì™€ ë§ˆì°¬ê°€ì§€ë¡œ 5íšŒì— ê±¸ì³ ëª¨ë¸ì„ ì¬í•™ìŠµí–ˆë‹¤.
<br/><br/><br/>

## 3. Fully automatic stage.

ì•ì„œ 2ë‹¨ê³„ë¥¼ í†µí•´ ì¶©ë¶„í•œ maskë¥¼ ìˆ˜ì§‘í–ˆê³ , ëª¨í˜¸í•œ ê²½ìš°ì— ëŒ€í•´ì„œë„ validí•œ maskë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìœ¼ë¯€ë¡œ(ambiguity-aware model) ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” ì™„ì „ ìë™í™”ëœ ë°©ì‹ìœ¼ë¡œ annotationì„ ìƒì„±í–ˆë‹¤. ì•„ë˜ ê³¼ì •ì„ í†µí•´ 11M ì´ë¯¸ì§€ì— ëŒ€í•´ 1.1B high-quality maskë¥¼ ìƒì„±í–ˆë‹¤.

1. 32Ã—32 regular gridì— ëŒ€í•œ point ì§‘í•©ì„ promptë¡œ ì…ë ¥í•˜ê³ , ê°ê° pointì— ëŒ€í•´ valid objectì— ëŒ€í•œ maskë¥¼ ì˜ˆì¸¡í•œë‹¤. 
2. ambiguity-aware modelì„ ì‚¬ìš©í•˜ë©´ pointì— ëŒ€í•´ objectì˜ subpart, part, whole objectë¥¼ ë°˜í™˜í•œë‹¤. 
3. ëª¨ë¸ì˜ IoU prediction moduleì€ confident maskë¥¼ ì„ íƒí•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. 
4. ì´ë ‡ê²Œ ì„ íƒëœ maskì¤‘ì—ì„œ stable maskë§Œ ì„ íƒí•˜ì˜€ëŠ”ë°, í•´ë‹¹ maskì˜ probability mapì—ì„œ 0.5 âˆ’ Î´, 0.5 + Î´ë¡œ thresholdë¥¼ ì„¤ì •í–ˆì„ ë•Œë„ maskì˜ ëª¨ì–‘ì´ ìœ ì‚¬í•˜ë©´ stableí•˜ê³  íŒë‹¨í•˜ì˜€ë‹¤ê³  í•œë‹¤. 
5. ë§ˆì§€ë§‰ìœ¼ë¡œ NMS(Non-Maximal Suppression)ë¥¼ ì ìš©í•˜ì—¬ ì¤‘ë³µ í•­ëª©ì„ filteringí–ˆë‹¤. 
<br/><br/>

++ ì¶”ê°€ë¡œ, ë” ì‘ì€ maskì˜ qualityë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì´ë¯¸ì§€ cropì„ í™•ëŒ€í•˜ì—¬ multiple overlappingì„ ìˆ˜í–‰í•˜ê¸°ë„ í–ˆë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Segment Anything Dataset

---

ë°ì´í„° ì—”ì§„ì„ í†µí•´ ìƒì„±í•œ ë°ì´í„°ì…‹ **SA-1B**ëŠ” 11Mê°œì˜ ë‹¤ì–‘í•œ ì´ë¯¸ì§€, 1.1Bì˜ high-quality segmentation maskë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. 

ì‚¬ì§„ì‘ê°€ì™€ í˜‘ë ¥í•˜ëŠ” ì—…ì²´ë¡œë¶€í„° ìƒˆë¡œìš´ 11Mê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ì´ì„¼ìŠ¤ë¥¼ ë°›ì•˜ìœ¼ë©°, ê³ í•´ìƒë„ì— ì´ë¯¸ì§€ì— ëŒ€í•´ downsamplingì„ ìˆ˜í–‰í•˜ì˜€ì§€ë§Œ ê¸°ì¡´ì˜ ë°ì´í„°ì…‹ë³´ë‹¤ëŠ” ë†’ì€ í•´ìƒë„ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ë°ì´í„° ì—”ì§„ìœ¼ë¡œ ìƒì„±ëœ ë§ˆìŠ¤í¬ í’ˆì§ˆì€ ì „ì²´ mask ë°ì´í„°ì˜ 94%ê°€ IoU 90%ì´ìƒì„ ë‹¬ì„±í•  ë§Œí¼ ìš°ìˆ˜í•œ í’ˆì§ˆì„ ê°€ì§€ê³  ìˆë‹¤(ì „ë¬¸ annotatorë“¤ì´ mask í’ˆì§ˆì„ ê°œì„ í•œ í›„ IoU ë¹„êµ ê²°ê³¼).
<br/><br/><br/>

![SAM_5.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/58802f65-1d21-4967-bf7d-bfd94f33e6fb){: width="700px"}

ìœ„ì˜ ê·¸ë¦¼ì€ SA-1Bì˜ Mask ì†ì„±ì— ëŒ€í•œ ì¡°ì‚¬ë¥¼ ìœ„í•´ maskì—ì„œ object centerì˜ spatial distributionì„ ê¸°ì¡´ì˜ ë°ì´í„°ì…‹ê³¼ ë¹„êµí•œ ê²ƒì´ë‹¤. SA-1BëŠ” ë‹¤ë¥¸ ë°ì´í„°ì…‹ê³¼ ë¹„êµí•˜ì—¬ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ë„“ê²Œ ë¶„í¬ë˜ì–´ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
<br/><br/><br/>

![SAM_6.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/15288871-94a8-4720-aff1-231b79a1f2ec){: width="1300px"}

ìœ„ì˜ ê·¸ë˜í”„ëŠ” ë°ì´í„°ì…‹ í¬ê¸°ë³„ë¡œ ë¹„êµë¥¼ ìˆ˜í–‰í•œ ê²°ê³¼ì´ë‹¤. ê°ê° mask-image ë¶„í¬, mage-relative mask size(mask ì˜ì—­ì„ ì´ë¯¸ì§€ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆˆ ì œê³±ê·¼), shape complexity ë¶„ì„ì„ ìœ„í•œ mask concavity([1 - mask area]ë¥¼ maskì˜ convex hull ë©´ì ìœ¼ë¡œ ë‚˜ëˆˆ ê°’)ì— ëŒ€í•œ ê·¸ë˜í”„ì´ë‹¤. 

SA-1BëŠ” ë‹¤ë¥¸ ë°ì´í„°ì…‹ê³¼ ë¹„êµí•˜ì—¬ ë§ì€ ì´ë¯¸ì§€ì™€ maskë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ í¬ê¸°ì˜ maskë¥¼ ë§ì´ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒì„ ì‚´í´ë³¼ ìˆ˜ ìˆë‹¤. ë˜í•œ maskì˜ concavity ë˜í•œ ë‹¤ë¥¸ ë°ì´í„°ì…‹ê³¼ ìœ ì‚¬í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/><br/><br/>

# Segment Anything RAI Analysis

---

SA-1B ë°ì´í„°ì…‹ê³¼ SAMì— ëŒ€í•´ ê³µì •ì„±ê³¼ í¸ê²¬ì— ëŒ€í•´ ì¡°ì‚¬í•˜ëŠ” RAI(Responsible AI) ë¶„ì„ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. 

![SAM_7.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/c0190edb-98e0-4a01-8f85-de83ac1af5d6){: width="1300px"}

![SAM_8.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/203faf5f-e301-4fdf-8913-3e129d95ad86){: width="1100px"}

ìœ„ ê·¸ë¦¼ì€ êµ­ê°€ë³„ ì´ë¯¸ì§€ ìˆ˜ì— ëŒ€í•œ ì‹œê°í™”ì´ë‹¤. ìƒìœ„ 3ê°œ êµ­ê°€ê°€ ì„œë¡œ ë‹¤ë¥¸ ëŒ€ë¥™ì´ë¼ëŠ” ì ì—ì„œ ë‹¤ì–‘í•œ êµ­ê°€ì—ì„œ ì´ë¯¸ì§€ê°€ ìˆ˜ì§‘ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë˜í•œ í‘œ1, 2ë¥¼ í†µí•´ SAMì´ êµ­ê°€, ì§€ì—­ ë° ì†Œë“, ì„±ë³„, ì—°ë ¹ ë° ì¸ì¢…ì— ëŒ€í•´ ê³µì •í•˜ê³  ì¼ê´€ë¨ì„ ë‚˜íƒ€ë‚´ê³  ìˆë‹¤. 
<br/><br/><br/><br/><br/><br/>

# Experiments (Zero-Shot Transfer Experiments)

---

SAMì„ ì‚¬ìš©í•œ zero-shot transfer ì‹¤í—˜ì„ ì§„í–‰í—€ë‹¤. 5ê°€ì§€ì˜ down stream taskì— ëŒ€í•´ ë¹„êµí–ˆë‹¤. mIoU í‰ê°€ë¥¼ ìœ„í•´ 23ê°œì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©ëœ ë°ì´í„°ì…‹ ì˜ˆì‹œì´ë‹¤.

![SAM_9.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/64b25451-1ec3-4367-a716-9115d055185f){: width="1100px"}
<br/><br/><br/><br/>

## 1. Zero-Shot Single Point Valid Mask Evaluation

ë¨¼ì € single foreground pointë¡œ objectë¥¼ segmentationí•˜ëŠ” taskì— ëŒ€í•´ í‰ê°€ë¥¼ ì§„í–‰í—€ë‹¤. ì €ìëŠ” í‘œì¤€ mIoU metric(ì˜ˆ: ì˜ˆì¸¡ ë§ˆìŠ¤í¬ì™€ ì‹¤ì œ ë§ˆìŠ¤í¬ ì‚¬ì´ì˜ ëª¨ë“  IoUì˜ í‰ê· ) ë¿ë§Œ ì•„ë‹ˆë¼ annotatorê°€ mask qualityë¥¼ 1(nonsense)ì—ì„œ 10(pixel-perfect)ê¹Œì§€ í‰ê°€í•˜ëŠ” human studyë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ìˆ˜í–‰í–ˆë‹¤. ì €ìëŠ” interactive segmentation ëª¨ë¸ì¸ RITMê³¼ ë¹„êµí•˜ì˜€ë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

![SAM_10.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/f6195573-495d-43a4-88b2-df57eaed6197){: width="1100px"}
<br/><br/><br/><br/><br/>

## 2. Zero-Shot Edge Detection

BSDS500 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ edge detection ì‘ì—…ì„ í‰ê°€í–ˆë‹¤. 16Ã—16 regular gridì˜ foreground pointë¡œ êµ¬ì„±ëœ promptì—ì„œ, 768 predicted maskë¥¼ ìƒì„±í•œë‹¤(point ë‹¹ 3ê°œ). ì¤‘ë³µ maskëŠ” NMSì— ì˜í•´ ì œê±°ë˜ê³ , mask probability mapì— Sobel filteringê³¼ edge NMSë“±ì˜ postprocessingì„ ì ìš©í•˜ì—¬ edge mapì„ ìƒì„±í–ˆë‹¤.

ëŒ€í‘œ edge mapì— ëŒ€í•œ ì‹œê°í™”ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. ì €ìëŠ” SAMì´ edge detectionì„ ìœ„í•´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  í•©ë¦¬ì ì¸ edge mapì„ ìƒì„±í•œë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆë‹¤. ì •ëŸ‰ì ì¸ ë¹„êµëŠ” ì•„ë˜ í‘œì™€ ê°™ë‹¤. 

![SAM_11.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/c2d43e09-b5d8-413c-ab68-1a290022d7c0){: width="450px"}
<br/><br/><br/><br/><br/>

## 3. Zero-Shot Object Proposals

ë‹¤ìŒìœ¼ë¡œëŠ” object proposal generationì˜ ì¤‘ê°„ ìˆ˜ì¤€ taskì—ì„œ SAMì„ í‰ê°€í–ˆë‹¤. object proposalì„ ìƒì„±í•˜ê¸° ìœ„í•´ automatic mask generation pipelineì˜ ìˆ˜ì •ëœ ë²„ì „ì„ ì‚¬ìš©í•˜ì—¬ proposalì„ mask outputìœ¼ë¡œ ì¶œë ¥í–ˆë‹¤. ì¹´í…Œê³ ë¦¬ê°€ ë§ì€ LVIS v1 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ average recall (AR) metricì— ëŒ€í•´ ê³„ì‚°í•˜ì˜€ê³  ViTDet detectorì™€ ë¹„êµí•˜ì˜€ë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

![SAM_12.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/b599f62f-81fc-4187-a82c-c08f7dfc20ee){: width="500px"}
<br/><br/><br/><br/><br/>

## 4. Zero-Shot Instance Segmentation

ë” ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ SAMì„ instance segmenterì˜ segmentation moduleë¡œ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë¥¼ ìˆ˜í–‰í–ˆë‹¤. COCO ë° LVISì— ëŒ€í•´ SAM ë° ViTDetì´ ì˜ˆì¸¡í•œ maskë¥¼ ë¹„êµí–ˆë‹¤. ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”ì—ì„œ SAM ë§ˆìŠ¤í¬ê°€ ê²½ê³„ê°€ ë” ëª…í™•í•˜ê³  ViTDetì˜ ë§ˆìŠ¤í¬ë³´ë‹¤ ì§ˆì ìœ¼ë¡œ ë” ë‚˜ì€ ê²½ìš°ê°€ ë§ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤.

![SAM_13.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/40744a2e-49d9-4766-b344-4c422f7006e5){: width="450px"}
<br/><br/><br/><br/><br/>

## 5. Zero-Shot Text-to-Mask

ë” ë†’ì€ ìˆ˜ì¤€ì˜ taskë¡œ free-form textì— ëŒ€í•´ object segmentationì„ ìˆ˜í–‰í–ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì€ ì •ì„±ì  ê²°ê³¼ì´ë‹¤. SAMì€ "a wheel"ê³¼ ê°™ì€ ê°„ë‹¨í•œ text promptì™€ "beaver tooth grille"ê³¼ ê°™ì€ ë¬¸êµ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ë¥¼ ë¶„í• í•  ìˆ˜ ìˆë‹¤.

![SAM_14.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/9e60e0a2-020d-4fd7-8ddf-1a151efeeaed){: width="500px"}

<br/><br/><br/><br/><br/>
