---
title: "[ë…¼ë¬¸ ë¦¬ë·°] Rich Human Feedback for Text-to-Image Generation"
author: lunalee
date: 2024-07-17 20:30:18 +0900
categories: [AI, Paper Review]
tags: [Text-to-Image, Generative, Dataset]
pin: false
math: true
---

<br/><br/>
`Google Research` `CVPR 2024` `Best paper`

- Paper: [https://arxiv.org/abs/2312.10240](https://arxiv.org/abs/2312.10240)
- Git: [https://github.com/google-research/google-research/tree/master/richhf_18k](https://github.com/google-research/google-research/tree/master/richhf_18k)
<br/><br/><br/>

#### ğŸ“– í•µì‹¬ í›‘ì–´ë³´ê¸° !!

- T2I Generation ëª¨ë¸ì—ì„œ artifact, misalignmentë“±ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **ë°ì´í„°ì…‹**ê³¼ **human annotationì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸** ì œì•ˆ
- **RichHF-18K**: 18K ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ Rich Human Feedback ë°ì´í„°ì…‹ ìˆ˜ì§‘, ì´ë¯¸ì§€ì˜ ë¹„í˜„ì‹¤ì„±/ê²°í•¨ ë° text-image ì •ë ¬ ì˜¤ë¥˜ë¥¼ ê°•ì¡°í•˜ëŠ” annotation í¬í•¨
- **RAHF ëª¨ë¸**: ë©€í‹°ëª¨ë‹¬ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ ê´€ë ¨ëœ text promptì— ëŒ€í•œ human annotationì„ ì˜ˆì¸¡
<br/><br/><br/><br/>

# Introduction

---

Text-to-Image(T2I) Generation ëª¨ë¸ì€ ìµœê·¼ ìƒë‹¹í•œ ë°œì „ì„ ì´ë£¨ì—ˆê³ , ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ì—¬ì „íˆ artifacts/implausibility(ë¹„í˜„ì‹¤ì„±), textì™€ì˜ misalignment(ì •ë ¬ ì˜¤ë¥˜)ì™€ ê°™ì€ ë¬¸ì œë¥¼ ê²ªê³  ìˆë‹¤. ì‹¤ì œë¡œ Pick-a-Pic ë°ì´í„°ì…‹ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì•½ 10%ë§Œì´ artifactì™€ implausibilityê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤ê³  í•œë‹¤.
<br/><br/>

ê·¸ë ‡ë‹¤ë©´ ê¸°ì¡´ì— ì‚¬ìš©í•œ ë°©ë²•ë“¤ì€ ì–´ë• ì„ê¹Œ?

- ê¸°ì¡´ì˜ IS, FIDì™€ ê°™ì€ metric â†’ ì´ë¯¸ì§€ì˜ ì „ì²´ ë¶„í¬ì— ë”°ë¼ ê³„ì‚°ë˜ë©° ê°œë³„ ì´ë¯¸ì§€ì˜ ë¬¸ì œë¥¼ ë°˜ì˜í•˜ê¸° ì‰½ì§€ì•ŠìŒ
- ì¸ê°„ ì„ í˜¸ë„/í‰ê°€ ë°˜ì˜ â†’ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ë‹¨ì¼ ìˆ«ì ì ìˆ˜ë¡œ ìš”ì•½í•¨
- CLIPScoreì™€ ê°™ì€ prompt-image alignment â†’ ì´ë¯¸ì§€ì˜ misalignment ì˜ì—­ì„ localizeí•˜ì§€ ëª»í•¨, ëª¨ë¸ì´ ë³µì¡í•¨
<br/><br/>

![RAHF_1.png](https://github.com/user-attachments/assets/1c2bb2a5-417b-4ba4-b088-d7595a00ab83){: width="500px"}
_ë¹¨ê°„ ì : artifact/implausibility region, íŒŒë€ ì : misaligned region_
<br/><br/>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ë©´ì  í‰ê°€ê°€ ê°€ëŠ¥í•˜ê³  í•´ì„ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ì œì•ˆí•œë‹¤. 

- **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>RichHF-18K</span></mark>**: 18K ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ Rich Human Feedback ë°ì´í„°ì…‹ ìˆ˜ì§‘
    1. ì´ë¯¸ì§€ ë‚´ì˜ implausibility/artifact ë° text-image misalignment ì˜ì—­ì„ ê°•ì¡°í•˜ëŠ” point annotation í¬í•¨
    2. ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ì˜ëª» í‘œí˜„ëœ ê°œë…ì„ ì§€ì¹­í•˜ëŠ” ë¶€ë¶„(ë‹¨ì–´)ì— ëŒ€í•´ promptì— ë¼ë²¨ë§ ë¨
    3. ì´ë¯¸ì§€ íƒ€ë‹¹ì„±, text-image alignment, aesthetics(ë¯¸í•™) ë° ì „ë°˜ì ì¸ í‰ê°€ì— ëŒ€í•œ 4ê°€ì§€ ìœ í˜•ì˜ ì„¸ë¶„í™”ëœ ì ìˆ˜ í¬í•¨
- **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>Rich Automatic Human Feedback (RAHF)</span></mark>**: multimodal transformer ëª¨ë¸, ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ê´€ë ¨ text promptì— ëŒ€í•œ human annotationì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµ.
<br/><br/><br/>

ë…¼ë¬¸ì˜ ì €ìëŠ” RAHFì— ì˜í•œ human feedbackì´ ì´ë¯¸ì§€ ìƒì„±ì„ ê°œì„ í•˜ëŠ” ë° ìœ ìš©í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì˜ˆì¸¡ëœ heatmapì„ ë§ˆìŠ¤í¬ë¡œ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œê°€ ìˆëŠ” ì´ë¯¸ì§€ ì˜ì—­ì„ ë‹¤ì‹œ ì¹ í•˜ê±°ë‚˜, ì˜ˆì¸¡ëœ ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„± ëª¨ë¸ì„ fine-tuningí•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤ê³  í•œë‹¤. 
<br/><br/><br/><br/><br/><br/><br/>

# Collecting rich human feedback

---

## 1. Data collection process

ë¨¼ì €, ë°ì´í„°ì…‹ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì´ í¬í•¨ëœë‹¤.

1. 2ê°œì˜ heatmap: artifact/implausibility, misalignment
2. 4ê°œì˜ ì„¸ë¶„í™”ëœ ì ìˆ˜: plausibility(íƒ€ë‹¹ì„±), alignment(ì •ë ¬), aesthetics(ë¯¸í•™), ì „ì²´ ì ìˆ˜
3. 1ê°œì˜ text sequence: misaligned keywords
<br/><br/><br/>

ë°ì´í„°ì…‹ ìˆ˜ì§‘ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

1. ê° ìƒì„±ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ ë¨¼ì € annotatorëŠ” ì´ë¯¸ì§€ë¥¼ ê²€ì‚¬í•˜ê³  ì´ë¥¼ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©ëœ promptë¥¼ ì½ëŠ”ë‹¤.
2. Text promptì™€ ê´€ë ¨í•˜ì—¬ implausibility/artifact ë˜ëŠ” misalignmentì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ **ì´ë¯¸ì§€ì— í¬ì¸íŠ¸ë¥¼ í‘œì‹œ**í•œë‹¤.
3. í‘œì‹œëœ ê° í¬ì¸íŠ¸ì—ëŠ” **â€œeffective radiusâ€**(ìœ íš¨ ë°˜ê²½, ì´ë¯¸ì§€ Hì˜ 1/20)ê°€ ìˆì–´ì„œ, í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ íŠ¹ì • ê³µê°„(ë””ìŠ¤í¬)ë§Œí¼ ìœ íš¨í•¨. ì´ëŸ°ì‹ìœ¼ë¡œ ë¹„êµì  ì ì€ í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°í•¨ì´ ìˆëŠ” ì´ë¯¸ì§€ ì˜ì—­ì„ ì»¤ë²„í•  ìˆ˜ ìˆìŒ.
4. ë§ˆì§€ë§‰ìœ¼ë¡œ annotatorëŠ” **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>misaligned keyword</span></mark>**ì™€ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>4ê°€ì§€ ì ìˆ˜</span></mark>**(plausibility, image-text alignment, aesthetic, ì „ì²´ì ì¸quality) ëŒ€í•´ **5-point Likert scaleë¡œ í‰ê°€**ë¥¼ ì§„í–‰
<br/><br/><br/><br/><br/>

## 2. Human feedback consolidation

Human feedbackì˜ ì‹ ë¢°ì„±ì„ ìœ„í•´ ê° image-text pairì— ëŒ€í•´ 3ëª…ì˜ annotatorê°€ ì£¼ì„ì„ ë‹¬ì•˜ë‹¤. 3ëª…ì˜ annotationì„ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í†µí•©í–ˆë‹¤.
<br/><br/>

- ì ìˆ˜ëŠ” **í‰ê· **í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¡œ ì‚¬ìš©
- misaligned keyword annotationì˜ ê²½ìš° **ë‹¤ìˆ˜ê²° íˆ¬í‘œ**ë¥¼ í†µí•´ aligned/misalignedë¥¼ ì •í•¨
- point annotationì˜ ê²½ìš°, ê° í¬ì¸íŠ¸ì— ëŒ€í•´ **heatmap ë””ìŠ¤í¬ ì˜ì—­ìœ¼ë¡œ ë³€í™˜**í•œ ë‹¤ìŒ, **í‰ê·  heatmap**ì„ ê³„ì‚°<br/>
<span style='color: var(--txt-gray)'>~~(ëª…ë°±íˆ ë¹„í˜„ì‹¤ì ì¸ ì˜ì—­ì€ ëª¨ë“  annotatorê°€ í‘œì‹œí•  ê°€ëŠ¥ì„±ì´ ë†’ê³ , ìµœì¢… heatmapì—ì„œ ë†’ì€ ê°’ì„ ê°€ì§)~~</span>

<br/><br/><br/><br/><br/>

## 3. RichHF-18K: a dataset of rich human feedback

Pick-a-Pic ë°ì´í„°ì…‹ì—ì„œ data annotationì„ ìœ„í•´ image-text pairì˜ subsetì„ ì¶”ì¶œí–ˆë‹¤. ê¸°ì¤€ì€ ì•„ë˜ì™€ ê°™ë‹¤. Pick-a-Picì—ì„œ ì´ 18,000ê°œì˜ image-text pairì— ëŒ€í•œ rich human feedbackì„ ìˆ˜ì§‘í–ˆë‹¤.
<br/><br/>

- ê´‘ë²”ìœ„í•œ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ìœ„í•´ ëŒ€ë¶€ë¶„ì„ **ì‚¬ì‹¤ì ì¸ ì´ë¯¸ì§€**(photo-realistic)ë¡œ ì„ íƒ
- balanced categoryë¥¼ ìœ„í•´ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>PaLI visual question answering (VQA) ëª¨ë¸</span></mark>**ì„ ì‚¬ìš©í•˜ì—¬ basic featureë¥¼ ì¶”ì¶œ
    - ê° image-text pairì— ëŒ€í•´ 1) ì´ë¯¸ì§€ê°€ ì‚¬ì‹¤ì ì¸ì§€, 2) ì´ë¯¸ì§€ì˜ categoryê°€ ë¬´ì—‡ì¸ì§€('ì¸ê°„', 'ë™ë¬¼', 'ì‚¬ë¬¼', 'ì‹¤ë‚´ ì¥ë©´', 'ì‹¤ì™¸ ì¥ë©´' ì¤‘ í•˜ë‚˜)ë¥¼ ì¶”ì¶œ
<br/><br/><br/><br/><br/>

## 4. Data statistics of RichHF-18K

![RAHF_2.png](https://github.com/user-attachments/assets/0cda374e-9fe1-4d96-87df-f864a8186f8a){: width="1100px"}

ë°ì´í„°ì…‹ì˜ ì ìˆ˜ì— ëŒ€í•œ í†µê³„ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í–ˆë‹¤. ì ìˆ˜ì˜ histogramì€ ìœ„ì™€ ê°™ë‹¤. ì ìˆ˜ëŠ” Gaussian ë¶„í¬ì™€ ìœ ì‚¬í•˜ë‹¤. 
<br/><br/><br/>

![RAHF_3.png](https://github.com/user-attachments/assets/8e75e036-e120-4615-b0f4-aad777f2b436){: width="550px"}

ì¶”ê°€ë¡œ image-text pairì— ëŒ€í•œ annotatorë“¤ì˜ í‰ê°€ ì¼ì¹˜ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ ì ìˆ˜ ê°„ì˜ ìµœëŒ€ ì°¨ì´ë¥¼ ê³„ì‚°í–ˆë‹¤. ìœ„ì˜ ê·¸ë¦¼ì€ ì°¨ì´ì— ëŒ€í•œ histogramì´ë‹¤. ì•½ 25%ì˜ ìƒ˜í”Œì´ ì™„ë²½í•œ ì¼ì¹˜ë¥¼ ë³´ì´ê³  ì•½ 85%ì˜ ìƒ˜í”Œì´ ì–‘í˜¸í•œ ì¼ì¹˜ë¥¼ ë³´ì´ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
<br/><br/><br/><br/><br/><br/><br/>

# Predicting rich human feedback

---

## 1. Model

#### Architecture.

ViTì™€ T5X ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ, Spotlight ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ì„œ ì˜ê°ì„ ë°›ì•„ ìˆ˜ì •í•œ í˜•íƒœì˜ êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤. 

![RAHF_4.png](https://github.com/user-attachments/assets/9e8ad0cf-c2fb-4a35-8819-9f45aef2abe3){: width="1100px"}

- **ViT**
    - ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ high-level representation ì¶œë ¥ token ìƒì„±
<br/><br/>

- **Text Embed**
    - text prompt tokenì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ dense vectorë¡œ embed
<br/><br/>

- **Self-attention module (T5X self-attention encoder)**
    - ì´ë¯¸ì§€ tokenê³¼ text tokenì„ concatí•˜ì—¬ self-attention moduleì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
    - ì´ë¯¸ì§€ tokenì€ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>score prediction</span></mark>** ë° **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>heatmap prediction</span></mark>**ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ”ë°(ê·¸ë¦¼ì˜ êµ¬ì¡°, output ì°¸ê³ ), ì´ ë•Œ self attention moduleì„ í†µí•´ text informationì„ ì „ë‹¬ë°›ì•„ ì‚¬ìš©í•¨. ë°˜ëŒ€ë¡œ, Text tokenì€ **<mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>text misalignment keyword</span></mark>**ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ”ë°, self-attention moduleì„ í†µí•´ vision informationì„ ì „ë‹¬ë°›ì•„ vision-aware text encodingì´ ê°€ëŠ¥í•˜ê²Œ ëœë‹¤.
    - self-attention moduleì„ í†µí•´ ì¸ì½”ë”©ëœ fused text and image tokenì€ ì„¸ ì¢…ë¥˜ì˜ predictorë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ê° ë‹¤ë¥¸ output(Heatmap, Score, Text)ì„ ì˜ˆì¸¡
<br/><br/>

- **Predictor**
    1. Heatmap prediction: ì´ë¯¸ì§€ tokenì€ reshapeë˜ê³  convolution, deconvolution layer, sigmoidë¥¼ ê±°ì³  implausibility(ë¹„í˜„ì‹¤ì„±) ë° heatmapì„ ì¶œë ¥í•¨
    2. Score prediction: convolution, linear layer, sigmoidë¥¼ ê±°ì³ ì„¸ë¶„í™”ëœ ì ìˆ˜ë¥¼ ì¶œë ¥
    3. Keyword misalignment sequence(Text) prediction: ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ ì‚¬ìš©ëœ promptë¥¼ ëª¨ë¸ì— ëŒ€í•œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ìˆ˜ì •ëœ promptëŠ” T5X Decoderì˜ prediction targetì´ ëœë‹¤. ìˆ˜ì •ëœ promptì—ì„œ misaligned tokenì— ëŒ€í•´ íŠ¹ìˆ˜ ì ‘ë¯¸ì‚¬ (â€™_0â€™)ë¥¼ ë¶™ì—¬ í‘œì‹œí•œë‹¤.

<br/><br/><br/><br/>

#### Model variants.

Heatmap, Score prediction headì— ëŒ€í•œ ë‘ ê°€ì§€ model variantì— ëŒ€í•´ ì¡°ì‚¬í–ˆë‹¤.

1. **Multi-head:** ì—¬ëŸ¬ ê°œì˜ heatmapê³¼ scoreë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´, multiple prediction headë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ê° scoreì™€ heatmap typeì— ëŒ€í•´ ê°ê°ì˜ headë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼ í•˜ë¯€ë¡œ ì´ 7ê°œì˜ headê°€ í•„ìš”í•˜ë‹¤.
2. **Augmented prompt:** ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œëŠ” ê° prediction ìœ í˜•ì— ëŒ€í•´ í•˜ë‚˜ì˜ headë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰, heatmap, score, misalignment sequenceì— ëŒ€í•´ í•˜ë‚˜ì”©, ì´ 3ê°œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì„¸ë¶€ì ì¸ type ë¶„ë¥˜ë¥¼ ìœ„í•´ì„œëŠ” promptì— ê° task stringì„ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ augmentationì„ ìˆ˜í–‰í•œë‹¤.(e.g. â€˜implausibility heatmapâ€™)
<br/><br/><br/><br/>

#### Model optimization

- Heatmap prediction: pixel-wise mean squared error (MSE) loss
- Score prediction: MSE loss
- Keyword misalignment sequence(Text) prediction:  teacher-forcing cross-entropy loss
<br/><br/>

ê° prediction moduleì— ëŒ€í•œ loss functionì€ ìœ„ì™€ ê°™ë‹¤. ì „ì²´ lossëŠ” ìœ„ì˜ ì„¸ ê°€ì§€ loss functionì— ëŒ€í•œ weighted combinationì´ë‹¤.
<br/><br/><br/><br/><br/>

## 2. Experiments

#### Evaluation metrics

- Score prediction task: Score predictionì„ ìœ„í•œ ì¼ë°˜ì ì¸ í‰ê°€ ì§€í‘œì¸ Pearson linear correlation coefficient (PLCC)ì™€ Spearman rank correlation coefficient (SRCC)ì‚¬ìš©
- Heatmap prediction task: Empty ground truthê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ MSEë¥¼ ì¸¡ì •í•˜ê³ , non-empty ground truth ìƒ˜í”Œì— ëŒ€í•´ì„œëŠ” NSS/KLD/AUC-Judd/SIM/CC ì§€í‘œë¥¼ ì‚¬ìš©
- Misaligned keyword sequence prediction task: Token-level precision, recall, and F1-score
<br/><br/><br/><br/>

#### Prediction result on RichHF-18K test set

**[Quantitative analysis]**<br/>
![RAHF_5.png](https://github.com/user-attachments/assets/4b4a1546-a64b-46bf-8f10-e83c568d8543){: width="900px"}

RichHF-18K í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë„¤ ê°€ì§€ ì„¸ë¶„í™”ëœ Scoreì™€ implausibility(ë¹„í˜„ì‹¤ì ) heatmap, misalignment heatmap, and misalignment keyword sequenceì— ëŒ€í•œ ì˜ˆì¸¡ ì‹¤í—˜ ê²°ê³¼ëŠ” ìœ„ í‘œì™€ ê°™ë‹¤.
<br/><br/><br/><br/><br/>

**[Qualitative examples]**<br/>
![RAHF_6.png](https://github.com/user-attachments/assets/8616a5da-dc90-4146-85b5-2d0d4e228497){: width="500px"}

ê·¸ë¦¼ 5,6ì˜ ê²°ê³¼ëŠ” implausibility(ë¹„í˜„ì‹¤ì ) heatmap prediction ì˜ˆì œë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì—¬ê¸°ì„œ ë…¼ë¬¸ì˜ ëª¨ë¸ì€ artifact/implausibilityê°€ ìˆëŠ” ì˜ì—­ì„ ì‹ë³„í•˜ê³ , misalignment heatmapì— ëŒ€í•œ ëª¨ë¸ì—ì„œ prediction ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ promptì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê°ì²´ë¥¼ ì‹ë³„í•œë‹¤.
<br/><br/><br/><br/>

![RAHF_7.png](https://github.com/user-attachments/assets/a331e5a1-d548-424d-8b07-6520b8c65d60){: width="1100px"}

ê·¸ë¦¼ 7ì€ ëª‡ ê°€ì§€ ì´ë¯¸ì§€ ì˜ˆì™€ ì‹¤ì œ score ë° prediction scoreë¥¼ ë³´ì—¬ì¤€ë‹¤.
<br/><br/><br/><br/><br/><br/><br/>

# Learning from rich human feedback

---

ë‹¤ìŒìœ¼ë¡œëŠ” human feedbackì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€ ì¡°ì‚¬í–ˆë‹¤. RAHF ëª¨ë¸ë¡œ ìƒì„±ëœ ë°ì´í„°ì…‹ì— ëŒ€í•´ fine-tuning í•˜ê¸° ìœ„í•´ masked transformer êµ¬ì¡° ê¸°ë°˜ [Muse]([https://arxiv.org/abs/2301.00704](https://arxiv.org/abs/2301.00704)) ëª¨ë¸ì„ ëŒ€ìƒ ëª¨ë¸ë¡œ ì‚¬ìš©í–ˆë‹¤. 
<br/><br/><br/>

#### Finetuning generative models with predicted scores

ë¨¼ì € pretrainëœ Muse ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 12,564ê°œì˜ promptì— ëŒ€í•´ ê°ê° 8ê°œì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆë‹¤. ê° ì´ë¯¸ì§€ì— ëŒ€í•œ RAHF scoreë¥¼ ì˜ˆì¸¡í•˜ê³  ê° promptì˜ ì´ë¯¸ì§€ê°€ thresholdë¥¼ ë„˜ìœ¼ë©´ finetuning ë°ì´í„°ì…‹ìœ¼ë¡œ ì„ ì •í•œë‹¤. ê·¸ ë‹¤ìŒ ì´ ë°ì´í„°ì…‹ìœ¼ë¡œ Museë¥¼ finetuningí•œë‹¤.
<br/><br/>

![RAHF_8.png](https://github.com/user-attachments/assets/c04f0f79-50ec-4f61-b14f-9a06c49d300a){: width="1300px"}

ìœ„ ê·¸ë¦¼ì—ì„œ ì˜ˆì¸¡ëœ plausibility scoreë¡œ Museë¥¼ finetuningí•˜ëŠ” ì˜ˆì‹œë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. Muse finetuningì˜ ì´ë“ì„ ì •ëŸ‰í™”í•˜ê¸° ìœ„í•´ 100ê°œì˜ ìƒˆë¡œìš´ promptë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  6ëª…ì˜ annotatorì—ê²Œ ì›ë˜ Museì™€ finetuningëœ Museì˜ ë‘ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë¹„êµ(for plausibility, íƒ€ë‹¹ì„±)í•˜ë„ë¡ ìš”ì²­í–ˆë‹¤. AnnotatorëŠ” ì´ë¯¸ì§€ A/Bë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ëœ ëª¨ë¸ì„ ì•Œì§€ ëª»í•œ ì±„, ë‹¤ì„¯ ê°€ì§€ ì‘ë‹µ(ì´ë¯¸ì§€ AëŠ” ì´ë¯¸ì§€ Bë³´ë‹¤ ìƒë‹¹íˆ/ì•½ê°„ ë” ì¢‹ìŒ, ê±°ì˜ ë™ì¼, ì´ë¯¸ì§€ BëŠ” ì´ë¯¸ì§€ Aë³´ë‹¤ ì•½ê°„/ìƒë‹¹íˆ ì¢‹ìŒ) ì¤‘ì—ì„œ ì„ íƒí•œë‹¤. 
<br/><br/>

![RAHF_9.png](https://github.com/user-attachments/assets/a22483cb-c684-4d53-b617-563f5509157b){: width="500px"}

í‘œ 5ì˜ ê²°ê³¼ëŠ” RAHF plausibility scoreê°€ ìˆëŠ” finetuningëœ Museê°€ ì›ë˜ Museë³´ë‹¤ í›¨ì”¬ ì ì€  artifacts/implausibilityì„ ê°€ì§€ê³  ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.
<br/><br/><br/>

ë˜í•œ ê·¸ë¦¼ 8(c)-(d)ì—ì„œ RAHF aesthetic scoreë¥¼ Latent Diffusion ëª¨ë¸ì— ëŒ€í•œ Classifier Guidanceìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì˜ˆë¥¼ ë³´ì—¬ì¤€ë‹¤. ì´ëŠ” ê° ì„¸ë¶„í™”ëœ scoreê°€ ìƒì„± ëª¨ë¸/ê²°ê³¼ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ê°œì„ í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.
<br/><br/><br/><br/><br/>

#### Region inpainting with predicted heatmaps and scores

ë‹¤ìŒìœ¼ë¡œëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ëœ heatmapê³¼ scoreë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•œ region inpaintingì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ê°ê°ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ ë¨¼ì € implausibility(ë¹„í˜„ì‹¤ì ) heatmapì„ ì˜ˆì¸¡í•œ ë‹¤ìŒ, threshold ì„¤ì • ë° dilatingì„ ì‚¬ìš©í•˜ì—¬ heatmapì„ ì²˜ë¦¬í•˜ì—¬ maskë¥¼ ë§Œë“ ë‹¤. Maskëœ ì˜ì—­ ë‚´ì—ì„œ Muse inpatingì„ ì ìš©í•˜ì—¬ text promptì™€ ì¼ì¹˜í•˜ëŠ” ìƒˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. ì—¬ëŸ¬ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ê³ , ìµœì¢… ì´ë¯¸ì§€ëŠ” RAHFì—ì„œ ì˜ˆì¸¡ëœ ê°€ì¥ ë†’ì€ plausibility scoreë¡œ ì„ íƒëœë‹¤. 
<br/><br/><br/>
![RAHF_10.png](https://github.com/user-attachments/assets/df8a8e5e-0689-4a48-9bd1-44ed779c1afd){: width="1300px"}

ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ì´ëŸ¬í•œ inpainting ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ì„ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯, inpainting ì‘ì—… í›„ artifactê°€ ì ì€ ê·¸ëŸ´ë“¯í•œ ì´ë¯¸ì§€ê°€ ìƒì„±ëœë‹¤. ì´ëŠ” ë‹¤ì‹œ ë§í•´, RAHFê°€ RAHFë¥¼ í•™ìŠµí•˜ëŠ” ë° ì‚¬ìš©ëœ ì´ë¯¸ì§€ì™€ëŠ” ë§¤ìš° ë‹¤ë¥¸ ìƒì„± ëª¨ë¸ì˜ ì´ë¯¸ì§€ì— ì˜ ì¼ë°˜í™”ë¨ì„ ë³´ì—¬ì¤€ë‹¤.
<br/><br/><br/><br/>
