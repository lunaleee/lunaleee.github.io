---
title: "[ë…¼ë¬¸ ë¦¬ë·°] DINOv2: Learning Robust Visual Features without Supervision"
author: lunalee
date: 2024-03-05 22:54:23 +0800
categories: [AI, Paper Review]
tags: [Multi-modal, Knowledge Distillation, Self-supervised]
pin: false
math: true
---

<br/><br/>
`Meta AI Research` `arXiv 2023`

- Paper: [https://arxiv.org/abs/2304.07193](https://arxiv.org/abs/2304.07193)
- Git: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)
- Page: [https://dinov2.metademolab.com](https://dinov2.metademolab.com/)
<br/><br/><br/><br/><br/>

# Introduction

---

<span style='color: var(--txt-gray)'>[ê¸°ì¡´ì˜ ë°©ë²•, ë¬¸ì œ ì œê¸°]</span>

Task-agnosticí•œ pre-train representationì€ ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ í‘œì¤€ì´ ë˜ì—ˆë‹¤. NLPì—ì„œì˜ ì˜í–¥ìœ¼ë¡œ computer visionì—ì„œë„ ì´ëŸ¬í•œ â€œfoundationâ€ ëª¨ë¸ì´ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤. ê°€ì¥ ìœ ë§í•œ ë°©ë²•ì€ text-guided pre-training, ì¦‰ featureë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ textual supervisionì„ ì´ìš©í•˜ëŠ” ë°©ì‹ì— ì¤‘ì ì„ ë‘ê³  ìˆë‹¤.

í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë°©ì‹ì˜ í•™ìŠµì€ captionì´ ì´ë¯¸ì§€ì˜ í’ë¶€í•œ ì •ë³´ë¥¼ ê·¼ì‚¬í•  ë¿, ë³µì¡í•œ pixel-levelì˜ ì •ë³´ëŠ” í‘œí˜„í•˜ê¸° ì–´ë µë‹¤. ë˜í•œ ì´ë ‡ê²Œ í•™ìŠµëœ ì´ë¯¸ì§€ Encoderì—ëŠ” text-image pairê°€ í•­ìƒ í•„ìš”í•˜ë¯€ë¡œ ì´ë¯¸ì§€ë§Œì„ ì‚¬ìš©í•˜ëŠ” ìœ ì—°ì„±ì´ ì—†ë‹¤.
<br/><br/>

Text-guided pretrainingì˜ ëŒ€ì•ˆì€ imageë§Œìœ¼ë¡œ featureë¥¼ í•™ìŠµí•˜ëŠ” self-supervised learningì´ë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì€ ê°œë…ì ìœ¼ë¡œë„ pretext taskì— ê°€ê¹Œìš¸ ë¿ ì•„ë‹ˆë¼ imageë¥¼ pixel-levelì—ì„œ ì •ë³´ë¥¼ íšë“í•  ìˆ˜ ìˆê³  ë‹¤ì–‘í•œ ì‘ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. 

í•˜ì§€ë§Œ ì´ëŸ¬í•œ ì ì¬ë ¥ì—ë„ ë¶ˆêµ¬í•˜ê³  ì´ì „ì˜ ì‘ì—…ë“¤ì€ ë„ˆë¬´ ì‘ì€ ë°ì´í„°ì…‹ì— ëŒ€í•´ í•™ìŠµí–ˆê±°ë‚˜(ImageNet-1k), í’ˆì§ˆì´ ì €í•˜ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. 
<br/><br/>

![DINOv2_1.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/d81b98de-7b1b-476e-958f-4740b558d117){: width="1000px"}

<span style='color: var(--txt-gray)'>[ë…¼ë¬¸ì˜ ë°©ë²•]</span>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” self-supervised learningì´ ëŒ€ëŸ‰ì˜ ì„ ë³„ëœ ë°ì´í„°ì— ëŒ€í•´ì„œ pre-trainëœ ê²½ìš° ë²”ìš©ì ì¸ visual featureë¥¼ í•™ìŠµí•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ íƒêµ¬í–ˆë‹¤. ê¸°ì¡´ì— **iBOT**ê³¼ ê°™ì´ image ì™€ patch level ëª¨ë‘ì—ì„œ featureë¥¼ í•™ìŠµí•˜ëŠ” self-supervised ë°©ë²•ë“¤ì„ ì¬ê²€í† í•˜ê³ , ë” í° ë°ì´í„°ì…‹ì— ëŒ€í•´ ëª¨ë¸ì˜ ì¼ë¶€ ì„¤ê³„ì— ëŒ€í•´ ê²€í† í•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œ ê¸°ì—¬í•˜ê³ ìí•˜ëŠ” ë°”ì˜ ëŒ€ë¶€ë¶„ì€ **ëª¨ë¸ ë° ë°ì´í„°ì˜ í¬ê¸°ê°€ í™•ì¥ëœ ìƒí™©ì—ì„œ discriminative self-supervised learningì„ ì•ˆì •í™”í•˜ê³  ê°€ì†í™”í•˜ëŠ” ê²ƒ**ì´ë¼ê³  í•œë‹¤. 
<br/><br/>

Pre-trainingì„ ìœ„í•´ ê´‘ë²”ìœ„í•œ ì´ë¯¸ì§€ ì»¬ë ‰ì…˜ì—ì„œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  ì¬ì¡°ì •í•˜ëŠ” **ìë™ pipeline**ì„ êµ¬ì¶•í–ˆë‹¤. ì´ ë°©ë²•ì€ ë°ì´í„° similarityë¥¼ ì´ìš©í•˜ì—¬ manual annotationì´ í•„ìš”í•˜ì§€ ì•Šì€ NLP íŒŒì´í”„ë¼ì¸ì—ì„œ ì˜í–¥ì„ ë°›ì•˜ë‹¤ê³  í•œë‹¤. 
<br/><br/>

ë§ˆì§€ë§‰ìœ¼ë¡œ **ë‹¤ì–‘í•œ ViT êµ¬ì¡°ë¡œ pre-trainëœ visual model DINOv2ë¥¼ ì œì•ˆ**í•œë‹¤. ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ìš”ì•½ëœ ëŒ€ë¡œ image, pixel levelì—ì„œ ë‹¤ì–‘í•œ computer vision benchmarkì— ëŒ€í•´ DINOv2ì˜ ì„±ëŠ¥ì„ ê²€ì¦í—€ë‹¤.

![DINOv2_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/ce34772c-f886-447c-9e64-189137b74bec){: width="900px"}

<br/><br/><br/><br/><br/><br/>

# Method

---

## Data Processing

ì„ ë³„ë˜ì§€ ì•Šì€(Uncurated) ëŒ€ê·œëª¨ ë°ì´í„° í’€ì—ì„œ ê¸°ì¡´ì— ì„ ë³„ëœ(Curated) ë°ì´í„°ì…‹ì˜ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ì—¬ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>LVD-142M</span></mark>** ë°ì´í„°ì…‹ì„ ë§Œë“¤ì—ˆë‹¤. ì´ ê³¼ì •ì€ meta ë°ì´í„°ë‚˜ textê°€ í•„ìš” ì—†ì´ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš©ëœë‹¤.  ë°ì´í„° pipelineì€ ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤.
<br/><br/>

- ì‚¬ìš©ëœ Curated dataset: ImageNet-22k, ImageNet-1kì˜ train, Google Landmarks ë“±ì˜ ë°ì´í„°ì…‹
- ìˆ˜ì§‘í•œ Uncurated data source: 1.2B ê·œëª¨ì˜ í¬ë¡¤ë§í•œ web ì´ë¯¸ì§€
<br/><br/>

![DINOv2_3.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/9ec0326f-016a-4a83-b7b8-32b16a672314){: width="1300px"}


1. **Data source**: ì¸í„°ë„·ì—ì„œ ëŒ€ê·œëª¨ì˜ ì›¹ ì´ë¯¸ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ uncurated ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì•ˆì „í•˜ì§€ ì•Šê±°ë‚˜ ì œí•œëœ URLì€ ì‚­ì œí–ˆë‹¤. ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ í›„ì²˜ë¦¬(PCA hash ì¤‘ë³µ ì œê±° ë“±)ë¥¼ ì§„í–‰í–ˆë‹¤.
2. **Deduplication:** [SSCD](https://arxiv.org/pdf/2202.10261.pdf) paperì˜ copy detection pipelineì„ ì´ìš©í•˜ì—¬ uncurated ë°ì´í„°ì—ì„œ ì¤‘ë³µì— ê°€ê¹Œìš´ ë°ì´í„°ë¥¼ ì‚­ì œí•œë‹¤. 
3. **Self-supervised image retrieval:** uncurated dataì—ì„œ curated datasetì˜ ì´ë¯¸ì§€ì™€ ê°€ê¹Œìš´ ì´ë¯¸ì§€ë¥¼ ì„ ë³„í•˜ì—¬ ë°ì´í„°ë¥¼ êµ¬ì¶•í•œë‹¤. ì´ë¥¼ ìœ„í•´ ImageNet-22kì— pre-trainëœ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ViT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ image embeddingì„ ê³„ì‚°</span></mark>**í•˜ê³  **cosine-similarity**ë¥¼ ì´ë¯¸ì§€ ê°„ì˜ ê±°ë¦¬ ì¸¡ì •ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ê·¸ ë‹¤ìŒ uncurated ë°ì´í„°ì…‹ì— ëŒ€í•´ **k-means clustering**ì„ ìˆ˜í–‰í•œë‹¤. 
<br/>ì—¬ê¸°ì„œ curated datasetì´ ì¶©ë¶„íˆ í¬ë‹¤ë©´ ê°ê°ì˜ query ì´ë¯¸ì§€(=curated dataë¥¼ ì˜ë¯¸)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ Nê°œì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ê°€ê¹Œìš´ clusterë¡œë¶€í„° Mê°œë¥¼ ìƒ˜í”Œë§í•œë‹¤.
<br/><br/><br/><br/><br/>

## Discriminative Self-supervised Pre-training

SwAVë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, DINOì™€ iBOT lossì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ discriminative self-supervised ë°©ë²•ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•œë‹¤. Knowledge distillation í•™ìŠµ ë°©ë²•ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ë˜í•œ regularizerì™€ ì§§ì€ high-resolution í•™ìŠµ ë‹¨ê³„ë¥¼ ì¶”ê°€í–ˆë‹¤. 
<details>
  <summary><mark style='background-color: var(--hl-green)'><span style='color: var(--text-color)'>Knowledge Distillation(Teacher-Student Learning)</span></mark></summary>
  <div markdown="1">
  Knowledge Distillationì´ë€ ë§ ê·¸ëŒ€ë¡œ â€œì§€ì‹(Knowledge) + ì¦ë¥˜(Distillation)â€ ì˜ í•©ì„±ì–´ë¡œ, í•™ìŠµëœ í° ë„¤íŠ¸ì›Œí¬(T)ì˜ ì§€ì‹ì„ ì¶”ì¶œí•˜ì—¬ ì‘ì€ ëª¨ë¸(S)ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
    
  ![DINOv2_4.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/50499429-fe3b-4f36-bab0-031d1070c01c){: width="600px"}
    
  í¬ê¸°ê°€ í¬ê³  ì œí•œëœ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° í˜ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµì  ì‘ê³  ë°°í¬ì— ë§ëŠ” ì‘ì€ ëª¨ë¸ì—ì„œ ë¹„ìŠ·í•˜ê²Œ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ëœë‹¤.
    
  í•™ìŠµ ìˆœì„œëŠ” ë¨¼ì €, Teacher Networkë¥¼ í•™ìŠµì‹œí‚¨ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ Student Netwotkë¥¼ Teacher Networkë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•˜ê²Œ ë˜ëŠ”ë°, ì´ ë•Œ Teacher NetworkëŠ” frození•œë‹¤. Loss functionì€ ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±ëœë‹¤.
    
  ![DINOv2_5.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/341a8a78-6bbf-4fa0-9537-80b9ab40a93a){: width="600px"}
    
  LossëŠ” (1) Student Networkì˜ output $f_{\theta_S}(x)$ê°€ ì •ë‹µ yì™€ ê°™ì•„ì ¸ì•¼í•œë‹¤ëŠ” Cross Entropy Loss, (2) Student ëª¨ë¸ì˜ ë¶„í¬ $f_{\theta_S}$ê°€ Teacher ëª¨ë¸ì˜ ë¶„í¬ $f_{\theta_T}$ ì™€ ê°™ì•„ì§€ê¸° ìœ„í•œ KL Divergence Lossë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. 
  <br/><br/>
  <hr style="border: solid 0.5px lightgrey;">
  </div>
</details>
<br/><br/>

#### Image-level objective (â†’[DINOğŸ“„](https://arxiv.org/abs/2104.14294))

Student networkì™€ Teacher networkì—ì„œ ì¶”ì¶œëœ featureê°„ì˜ Cross-entropy lossë¥¼ ì‚¬ìš©í•œë‹¤. ë‘ feature ëª¨ë‘ ë™ì¼í•œ ì´ë¯¸ì§€ì—ì„œ, ì„œë¡œ ë‹¤ë¥¸ ë¶€ë¶„ì„ cropí•˜ì—¬ ì–»ì€ ViTì˜ class tokenì—ì„œ êµ¬í•œë‹¤. DINO Student head(MLPë¡œ êµ¬í˜„)ë¥¼ í†µê³¼í•œ ê²°ê³¼(score vector)ì—ëŠ” softmaxë¥¼ ì ìš©í•˜ì—¬ $p_s$ë¥¼ ì–»ê³  Lossì— ëŒ€í•œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ì§„í–‰í•œë‹¤. DINO Teacher headë¥¼ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ëŠ” softmaxë¥¼ ì ìš©í•œ ë’¤ exponential moving average(EMA)ë¥¼ ì ìš©í•˜ì—¬ $p_t$ë¥¼ ì–»ê³  teacher headë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤(ê¸°ì¡´ DINO ë…¼ë¬¸ê³¼ ë™ì¼).
<br/><br/><br/>

#### Patch-level objective (â†’[iBOTğŸ“„](https://arxiv.org/abs/2111.07832))

Student modelì˜ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>ì…ë ¥ ì´ë¯¸ì§€ patch ì¤‘ ì¼ë¶€ë¥¼ ëœë¤í•˜ê²Œ making</span></mark>**í•œë‹¤(Teacher modelì— ëŒ€í•´ì„œëŠ” masking ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ).  ê·¸ë¦¬ê³  ê° masking patch ìœ„ì¹˜ì— ëŒ€í•´ student, teacher model featureë¥¼ êµ¬í•˜ê³ (patch-level) cross-entropyë¥¼ êµ¬í•œë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ Lossë¥¼ ì´ìš© student í•™ìŠµ, teacher headëŠ” EMAë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.
<br/><br/><br/>

#### Untying head weights between both objectives

DINO(Image-level)ì™€ iBOT(Patch-level)ì˜ head ê°„ì— parameter sharing(ê°™ì€ headì‚¬ìš©)ì„ í–ˆì„ ë•Œ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ì´ì „ì˜ ì—°êµ¬ê°€ ìˆì—ˆì§€ë§Œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ **image-levelì—ì„œ overfitting**ë˜ê³  **patch-levelì—ì„œ underfitting**ë˜ëŠ” ë¬¸ì œë¥¼ ë°œê²¬í–ˆë‹¤. ë”°ë¼ì„œ ë‘ headë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤.
<br/><br/><br/>

#### Sinkhorn-Knopp centering (â†’ [SwAVğŸ“„](https://arxiv.org/pdf/2006.09882.pdfhttps://arxiv.org/pdf/2006.09882.pdf))

ì•ì„œ EMA(softmax-centering)ë¥¼ ìˆ˜í–‰í–ˆë˜ Teacher ëª¨ë¸ì˜ ì—…ë°ì´íŠ¸ ë°©ë²•ì„ **<mark style='background-color: var(--hl-yellow)'><span style='color: var(--text-color)'>SwAV ë…¼ë¬¸ì˜ Sinkhorn-Knopp (SK) batch normalizationìœ¼ë¡œ ëŒ€ì²´</span></mark>**í•œë‹¤.  Sinkhorn-Knopp ì•Œê³ ë¦¬ì¦˜ì„ 3 iteration ë°˜ë³µí•˜ê³ , Studentì—ëŠ” softmax normalizationì„ ì ìš©í•œë‹¤.
<br/><br/>

> **SwAV(Unsupervised Learning of Visual Features by Contrasting Cluster Assignments)** <br/>
> SwAVëŠ” Clustering ê¸°ë°˜ Self-supervised learning ë°©ë²•ì„ ì œì•ˆí•œ ë…¼ë¬¸ì´ë‹¤.<br/>
> ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ë¯¸ì§€ $x$ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ Augmentationì„ ì ìš©í•˜ê³  ê°ê° Encoderë¥¼ í†µí•´ featureë¥¼ ì¶”ì¶œí•œë‹¤. ë‘ ê°œì˜ ì´ë¯¸ì§€ feature $z_t, z_s$ê°€ ì£¼ì–´ì§€ë©´ ë‘ featureì— ëŒ€í•œ code $q_t, q_s$ë¥¼ ê³„ì‚°í•˜ëŠ”ë°, ì´ ë•Œ $K$ê°œì˜ prototype {}(ì¼ì¢…ì˜ codebookê³¼ ìœ ì‚¬í•œ ê°œë…)ì—ì„œ ì´ featureë¥¼ ë§¤ì¹­í•œë‹¤. ì´ ë•Œ, LossëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. <br/>
> 
> $$ L (\mathbf{z}_t, \mathbf{z}_s) = \ell(\mathbf{z}_t, \mathbf{q}_s) + \ell(\mathbf{z}_s, \mathbf{q}_t)
> $$
>
> ![DINOv2_5_2.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/23f559d3-572e-456f-9d80-941932d3e34a){: width="700px"}<br/>
> ì´ ë•Œ ë‘ codeëŠ” Augmentationì„ ë‹¤ë¥´ê²Œ ì ìš©í–ˆì§€ë§Œ ë™ì¼í•œ ì´ë¯¸ì§€ì—ì„œ ìƒì„±ëœ ê²ƒì´ê¸° ë•Œë¬¸ì—, ê°™ì€ ì •ë³´ë¥¼ ìº¡ì³í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ ë³¸ë¬¸ì˜ ì•„ì´ë””ì–´ì´ë‹¤. <br/>
> ì—¬ê¸°ì„œ codeë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ prototypeì„ onlineìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•œë‹¤. ì´ ë•Œ batchë‚´ì˜ ëª¨ë“  featureê°€ ë™ì¼í•œ ì½”ë“œë¡œ ë§¤í•‘ë˜ëŠ” trivial solutionì„ ë§‰ê¸° ìœ„í•´, **batch ë‚´ì—ì„œ ë§¤í•‘ë˜ëŠ” codeê°€ êµ¬ë³„**ë˜ë„ë¡ í•˜ëŠ” constraintë¥¼ ë„£ì–´ì£¼ê²Œ ëœë‹¤. ì´ ë°©ë²•ì´ **Sinkhorn-Knopp centering**ì´ë‹¤.

<br/><br/><br/>

#### KoLeo regularizer
KoLeo regularizerëŠ” batchë‚´ì˜ featureë“¤ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ìµœëŒ€í•œ ê· ë“±í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. nê°œì˜ vector ì§‘í•©(x_1, â€¦ , x_n)ì´ ì£¼ì–´ì§€ë©´ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤. KoLeo regularizerë¥¼ ìˆ˜í–‰í•˜ê¸° ì „  l2-normalizeëŠ” ì ìš©ëœë‹¤.

$$
\mathcal{L}_{koleo} = -\dfrac1n \sum_{i=1}^n \log (d_{n, i})
$$

#### Adapting the resolution

Low-resolutionì—ì„œëŠ” ì‘ì€ ë¬¼ì²´ë“¤ì€ ì‚¬ë¼ì§€ê²Œ ë˜ë¯€ë¡œ, ì´ë¯¸ì§€ resolutionì„ ë†’ì´ëŠ” ê²ƒì€ downstream taskë¥¼ ìœ„í•´ì„œë„ ì¤‘ìš”í•œ ë¬¸ì œì´ë‹¤. í•˜ì§€ë§Œ high-resolution í•™ìŠµì€ ë§ì€ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ë¯€ë¡œ ë…¼ë¬¸ì—ì„  pretrainingì˜ ë§ˆì§€ë§‰ì— ì§§ê²Œ  518Ã—518 ì´ë¯¸ì§€ì— ëŒ€í•œ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤.
<br/><br/><br/><br/><br/>

## Efficient implementation

ì €ìëŠ” ëª¨ë¸ì„ ë” í° ê·œëª¨ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•œ ëª‡ê°€ì§€ ê°œì„ ì‚¬í•­ì„ ê³ ë ¤í–ˆë‹¤. ì´ ë¶€ë¶„ì€ í•µì‹¬ë§Œ ê°„ë‹¨í•˜ê²Œ ìš”ì•½í–ˆë‹¤. 
<br/><br/>

- **Fast and memory-efficient attention**: Self-Attention ë ˆì´ì–´ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì†ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ìì²´ ë²„ì „ì˜ **FlashAttention**ì„ êµ¬í˜„í–ˆë‹¤.<br/><br/>
- **Sequence packing**: DINO ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì´ë¯¸ì§€ resolutionì´ ë‹¤ë¥¸ ê²½ìš° ì„œë¡œ ë‹¤ë¥¸ patch ê°œìˆ˜ê°€ ìƒì„±ë˜ê³ , token sequences ê¸¸ì´ê°€ ë‹¤ë¥´ë‹¤. ì´ëŸ¬í•œ ê²½ìš°ì—ë„ forward í•  ìˆ˜ ìˆë„ë¡, transformerë¥¼ í†µí•´ ì „ë‹¬í•´ì•¼ í•˜ëŠ” ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ê¸´ ì‹œí€€ìŠ¤ë¡œ ì—°ê²°í•˜ëŠ” trickì„ ì ìš©í–ˆë‹¤.<br/><br/>
- **Efficient stochastic depth**: ì €ìëŠ” ê²°ê³¼ë¥¼ maskingí•˜ëŠ” ê¸°ì¡´ì˜ ë°©ë²• ëŒ€ì‹  ì¼ë¶€ residual pathì˜ ê³„ì‚°ì„ dropí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ stochastic depthë¥¼ ê°œì„ í•œ ë²„ì „ì„ ì ìš©í–ˆë‹¤. 40% ì •ë„ì˜ ë†’ì€ ì‚­ì œìœ¨ì„ ì ìš©í•˜ë©´ ì»´í“¨íŒ… íš¨ìœ¨ì„±ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê²Œ í–¥ìƒëœë‹¤ê³  í•œë‹¤.<br/><br/>
- **Fully-Sharded Data Parallel (FSDP)**: AdamWë¡œ ëª¨ë¸ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ì„œëŠ” Student, teacher, optimizer 1/2 moments ì´ 4ê°œì˜ ëª¨ë¸ ë³µì œë³¸ì´ í•„ìš”í•˜ë‹¤. ì´ëŸ¬í•œ í° ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ FSDPì˜ PyTorch êµ¬í˜„ì„ ì´ìš©í•˜ì—¬ GPU ë¶„í• ì„ ì‚¬ìš©í–ˆë‹¤(data parallel). ì´ ë°©ë²•ì€ ê¸°ì¡´ì˜ DDP(DistributedDataParallel) ë°©ì‹ê³¼ ë¹„êµí•˜ì—¬ í†µì‹  ë¹„ìš©ì´ ì•½ 50% ê°ì†Œí•œë‹¤.<br/><br/>
- **Model distillation**: ì•ì„œ ì–¸ê¸‰í–ˆë“¯ ë…¼ë¬¸ì—ì„œëŠ” distillation ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ í° ëª¨ë¸ì˜ ì§€ì‹ì„ ì‘ì€ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤. ì‘ì€ ëª¨ë¸ì€ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ì§€ ì•Šê³  í° ëª¨ë¸ì¸ ViT-gì—ì„œ distill í•œë‹¤. ë…¼ë¬¸ì€ ëª‡ê°€ì§€ ì˜ˆì™¸ë¥¼ ì œì™¸í•˜ê³  ê¸°ì¡´ì˜ distillation í•™ìŠµê³¼ ë™ì¼í•œ í•™ìŠµ ë£¨í”„ë¥¼ ì‚¬ìš©í–ˆë‹¤.
<br/><br/><br/><br/><br/>

*<span style='color: var(--txt-gray)'>~~< ablation study ë¶€ë¶„ì€ ë‹¤ì–‘í•œ componentì— ëŒ€í•œ ì„±ëŠ¥ ê²€ì¦ë¶€ë¶„ì´ë¼ ìƒëµí–ˆë‹¤. ìì„¸í•œ ë¶€ë¶„ì€ ë…¼ë¬¸ì„ ì°¸ì¡°í•´ë³´ì >~~</span>*
<br/><br/>

# Results

---

### 1. ImageNet Classification

ì²« ë²ˆì§¸ í‰ê°€ë¡œ ImageNet-1k classification ë°ì´í„°ì…‹ì— ëŒ€í•´ ëª¨ë¸ì˜ ì´ë¯¸ì§€ representationì— ëŒ€í•´ ì¡°ì‚¬í–ˆë‹¤. Frozen backboneì— ëŒ€í•´ ê°„ë‹¨í•œ classifierë¥¼ í•™ìŠµí•˜ì—¬ í‰ê°€ë¥¼ ì§„í–‰í–ˆë‹¤. 

ë˜í•œ SOTA open-source weakly supervised modelê³¼ ë¹„êµë¥¼ ìœ„í•œ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤. 

![DINOv2_6.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/8f15ae79-d9a6-4602-83bb-e29427a2ee9a){: width="800px"}
<br/><br/><br/><br/>

High quality frozen featureë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì´ íŠ¹ì • ë°ì´í„°ì…‹ì— ëŒ€í•´ supervised í•™ìŠµì„ í†µí•´ fine-tuning ë  ë•Œ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì¡°ì‚¬í–ˆë‹¤. 

![DINOv2_7.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/a65f54a6-0957-40f5-ad16-db7ca32c01ee){: width="1000px"}
<br/><br/><br/><br/>

ìƒì„±ëœ featureì˜ generalization ì„±ëŠ¥ì„ ì¡°ì‚¬í•˜ê¸° ìœ„í•´ domain generalization benchmarkì—ì„œ linear classification headë¡œ í•™ìŠµëœ ImageNet-1k ëª¨ë¸ì„ í‰ê°€í–ˆë‹¤. SOTA SSL ë°©ë²•ê³¼ ë¹„êµí•  ë•Œ DINOv2 ëª¨ë¸ì€ í›¨ì”¬ ë” ë‚˜ì€ robustnessë¥¼ ë³´ì—¬ì¤€ë‹¤.

![DINOv2_8.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/1908fda4-9dc8-4d88-b9b1-24ee843e511e){: width="1100px"}
<br/><br/><br/><br/>

### 2. Additional Image and Video classification Benchmarks

ë‹¤ìŒìœ¼ë¡œëŠ” downstream classification benchmarkì— ëŒ€í•œ featureì˜ generalization ì„±ëŠ¥ì„ ì—°êµ¬í•œë‹¤. ë¨¼ì €  iNaturalist, Places205ì™€ ê°™ì€ í¬ê³  ì„¸ë¶„í™”ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ SimCLRì—ì„œ 12ê°€ì§€ ì´ë¯¸ì§€ classification taskë¥¼ ìˆ˜í–‰í•œë‹¤.

![DINOv2_9.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/d1295a47-7408-4bb7-943b-50ee2ce9ab5e){: width="1000px"}
<br/><br/><br/><br/>

 12 transfer classification benchmarkì—ì„œ ì„ íƒëœ frozen featureë¥¼ ë¹„êµí–ˆë‹¤.

![DINOv2_10.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/883cfd75-a6af-4c68-9f87-d4d89ffff8d7){: width="900px"}
<br/><br/><br/><br/>

### 3. Instance Recognition

Non-parametric approachë¥¼ ì‚¬ìš©í•˜ì—¬ instance-level recognitionì— ëŒ€í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¡°ì‚¬í–ˆë‹¤.

![DINOv2_11.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/7cea2140-94fe-44f7-8e75-f050b28382e0){: width="900px"}
<br/><br/><br/><br/>

### 4. Dense Recognition Tasks

Dense downstream taskì— ëŒ€í•´ í•™ìŠµëœ networkì—ì„œ ì¶”ì¶œëœ patch-level featureì˜ í’ˆì§ˆì„ ì¡°ì‚¬í–ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ Semantic image segmentationê³¼ Monocular depth estimationì— ëŒ€í•œ í‰ê°€ë¥¼ ìˆ˜í–‰í–ˆë‹¤.

![DINOv2_12.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/2acb3c26-4a21-447a-b6a9-2aa25e251c05){: width="900px"}

ìœ„ì˜ ê²°ê³¼ëŠ” segmentationì„ mIoUë¡œ ì¸¡ì •í•œ ê²°ê³¼ì´ë‹¤. Semantic segmention í‰ê°€ë¥¼ ìœ„í•´ ë‘ê°€ì§€ ì„¤ì •ì„ ê³ ë ¤í–ˆë‹¤.

- **Linear**: Patch tokenì— ëŒ€í•œ class logitì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ ëœë‹¤. low-resolution logit mapì„ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©ë˜ë©°, ê·¸ ë‹¤ìŒìœ¼ë¡œ segmentation mapì„ ì–»ê¸° ìœ„í•´ ì „ì²´ í•´ìƒë„ë¡œ upsamplingëœë‹¤. ì´ ì ˆì°¨ëŠ” ê°„ë‹¨í•˜ì§€ë§Œ high-resolution segmentationì„ ì‰½ê²Œ ìƒì„±í•˜ê¸°ëŠ” ì–´ë µë‹¤.
- **+ms**: Linear ì„¤ì •ì˜ í–¥ìƒëœ ë²„ì „. ë§ˆì§€ë§‰ 4ê°œ layerì˜ patch tokenì„ concatí•˜ê³ , ë” í° ì´ë¯¸ì§€ resolutionì„ ì‚¬ìš©í•˜ê³ , multiscale test-time augmentationì„ ì‚¬ìš©í•œë‹¤.
<br/><br/><br/><br/>

![DINOv2_13.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/a8d7041d-bb01-4b41-8ea2-dd5d37b48de0){: width="900px"}

ì´ ì‹¤í—˜ì—ì„œëŠ” NYUd, KITTI, NYUdì—ì„œ SUN3dë¡œì˜ zero-shot transfer ì´ë ‡ê²Œ ì„¸ ê°€ì§€ monocular depth estimation benchmarkì—ì„œ patch-level featureë¥¼ í‰ê°€í•œ ê²°ê³¼ì´ë‹¤.

ë§ˆì°¬ê°€ì§€ë¡œ depth estimation í‰ê°€ë¥¼ ìœ„í•œ ì„¸ê°€ì§€ ë‹¤ë¥¸ ì„¤ì •ì„ ê³ ë ¤í–ˆë‹¤.

- **lin. 1**: transformer â†’ bi-linearly upsample(x4ë°°) â†’ simple linear layer(256 depth prediction range, 256 binìœ¼ë¡œ ë‚˜ëˆ”), linear normalization
- **lin. 4**: lin 1ê³¼ ë™ì¼í•˜ë‚˜, transformerë¥¼ í•˜ë‚˜ì—ì„œ 4ê°œë¡œ ëŠ˜ë¦¼.
- **DPT**: frozen ëª¨ë¸ ìœ„ì— DPT decoder ì‚¬ìš©
<br/><br/><br/><br/>

### 5. Qualitative Results

ë§ˆì§€ë§‰ìœ¼ë¡œ featureì— ëŒ€í•œ ì •ì„±í‰ê°€ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ì´ë‹¤.

![DINOv2_14.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/77db268a-9db8-4524-acaa-f2cc370b1115){: width="900px"}

ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ADE20K ë°ì´í„°ì…‹ì— ëŒ€í•œ segmentationê³¼ KITTI, SUN RGB-D, NYUdë°ì´í„°ì…‹ì— ëŒ€í•œ depth estimationì— ëŒ€í•œ ëª‡ ê°€ì§€ ì •ì„±ì  ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. DINOv2 backboneì„ ì‚¬ìš©í•˜ëŠ” linear segmentation ëª¨ë¸ì€ ì¢‹ì€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ë™ì¼í•œ í‰ê°€ ì„¤ì •ì—ì„œ OpenCLIP ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ë” ì˜ ë™ì‘í•œë‹¤. 
<br/><br/><br/><br/>

![DINOv2_15.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/3979fb53-5f2d-44ee-9c4e-e7d5f508b5e7){: width="900px"}

DINOv2 ëª¨ë¸ì— ì˜í•´ ì¶”ì¶œëœ patch featureì— ëŒ€í•´ ìˆ˜í–‰ëœ principal component analysis(ì£¼ì„±ë¶„ ë¶„ì„, PCA) ê²°ê³¼ì´ë‹¤. ì´ ê³¼ì •ì€ ì´ë¯¸ì§€ì˜ ì£¼ìš”í•œ ê°œì²´ë¥¼ ë°°ê²½ì—ì„œ ì˜ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚´ê³  ìˆë‹¤. 
<br/><br/><br/><br/>

![DINOv2_16.png](https://github.com/cotes2020/jekyll-theme-chirpy/assets/34572874/6e5905ca-660f-4c1a-9076-21b3ff87d0e5){: width="900px"}

ë§ˆì§€ë§‰ìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ì—ì„œ patch-level featureì˜ matchingì„ í™•ì¸í•˜ì—¬ ì–´ë–¤ ìœ í˜•ì˜ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ íƒìƒ‰í•œë‹¤. ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ì €ìëŠ” íŠ¹ì§•ì´ ë‹¤ë¥¸ ë¬¼ì²´ë‚˜ ë™ë¬¼ì—ì„œ ìœ ì‚¬í•œ ëª©ì ì„ ê°€ì§€ê³  ìˆëŠ” semantic regionì— ëŒ€í•œ ì •ë³´ë¥¼ í¬ì°©í•œë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤(ë¹„í–‰ê¸°ì˜ ë‚ ê°œ-ìƒˆì˜ ë‚ ê°œ).
<br/><br/><br/><br/>
